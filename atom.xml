<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>gzj-blogs</title>
  
  
  <link href="https://zzugzj.github.io/atom.xml" rel="self"/>
  
  <link href="https://zzugzj.github.io/"/>
  <updated>2023-11-05T06:12:54.259Z</updated>
  <id>https://zzugzj.github.io/</id>
  
  <author>
    <name>gzj</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>凤凰架构-事务</title>
    <link href="https://zzugzj.github.io/posts/7a7ff038/"/>
    <id>https://zzugzj.github.io/posts/7a7ff038/</id>
    <published>2023-11-11T01:14:09.000Z</published>
    <updated>2023-11-05T06:12:54.259Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><h2 id="本地事务"><a href="#本地事务" class="headerlink" title="本地事务"></a>本地事务</h2><h3 id="实现原子性和持久性"><a href="#实现原子性和持久性" class="headerlink" title="实现原子性和持久性"></a>实现原子性和持久性</h3><h4 id="commit-logging"><a href="#commit-logging" class="headerlink" title="commit logging"></a>commit logging</h4><p>日志写入commit record，整个事务就是成功的，重启后根据已经写入磁盘的日志信息恢复现场。</p><p>缺陷是所有对数据的真实修改都必须发生在事务提交之后，即日志写入了commit record之后。</p><h4 id="write-ahead-logging"><a href="#write-ahead-logging" class="headerlink" title="write-ahead logging"></a>write-ahead logging</h4><p>按事务提交的时间点，将何时写入变动数据划分为FORCE和STEAL两个阶段</p><p><strong>FORCE</strong> ：当事务提交后，要求变动的数据必须同时完成写入成为FORCE，如果不强制变动数据必须同时完成写入则成为NO-FORCE。</p><p><strong>STEAL</strong> ：在事务提交前，允许变动数据提前写入成为STEAL，不允许则成为NO-STEAL。允许提前写入利于利用空闲I/O。</p><p>commit logging允许NO-FORCE，但不允许STEAL。write-ahead logging允许NO-FORCE，也允许STEAL，解决办法是增加了Undo log。</p><p><strong>崩溃恢复</strong>：</p><ul><li>分析阶段：从最后一次检查点开始扫描日志，找到没有End Record的事务，组成待恢复的事务集合。</li><li>重做阶段：该阶段依据分析阶段中产生的待恢复的事务集合来进行恢复，具体是找到所有包含commit record的日志，将这些日志修改的数据写入磁盘。</li><li>回滚阶段：经过分析、重做后剩余的待恢复事务集合，就是需要回滚的事务，根据Undo log，将已经写入磁盘的信息重新改回去。</li></ul><blockquote><p>我理解write-ahead logging相比commit logging的优点是可以将一个大事务的每一次操作都慢慢写到磁盘，因为commit logging必须把所有的修改都写到commit record后，具体的改动才能一股脑写进去。</p></blockquote><h3 id="实现隔离性"><a href="#实现隔离性" class="headerlink" title="实现隔离性"></a>实现隔离性</h3><p>隔离性保证了每个事务各自的读、写的数据相互独立，不会彼此影响。</p><p>现代数据库均提供了以下三种锁：</p><ul><li><strong>写锁</strong>：数据有加写锁，只有持有写锁的事务才能对数据进行写入操作，数据加持着写锁时，其他事务不能写入数据，也不能加读锁。</li><li><strong>读锁</strong>：多个事务可以加多个读锁，数据加读锁后不能加写锁。对于持有读锁的事务，如果该数据只有他自己的一个事务加了读锁，允许升级为写锁。</li><li><strong>范围锁</strong>：对某个范围直接加排它锁，在这个范围内的数据不能被写入。</li></ul><h4 id="串行化访问"><a href="#串行化访问" class="headerlink" title="串行化访问"></a>串行化访问</h4><p>提供了最高强度的隔离性，分为加锁和解锁两阶段去处理读锁、写锁和数据之间的关系，称为两阶段锁。</p><h4 id="可重复读"><a href="#可重复读" class="headerlink" title="可重复读"></a>可重复读</h4><p>可重复读比可串行化弱化的地方在于幻读问题（在事务执行过程中，两个完全相同的范围查询得到不同的结果集）。可重复读对事务所涉及的数据加读锁和写锁，且一直持有至事务结束，但不再加范围锁。</p><p>具体的数据库不一定完全遵照ARIES理论去实现。MySQL/InnoDB的默认隔离级别是可重复读，但它在只读事务（一个事务中只有查询语句）中可完全避免幻读问题。</p><h4 id="读已提交"><a href="#读已提交" class="headerlink" title="读已提交"></a>读已提交</h4><p>读已提交对事务涉及的数据加的写锁会一直持续到事务结束，但加的读锁会在查询操作完成后马上释放。读已提交比可重复读弱化的地方在于不可重复读问题（事务执行时，对同一数据的两次查询得到不同的结果）。</p><h4 id="读未提交"><a href="#读未提交" class="headerlink" title="读未提交"></a>读未提交</h4><p>读未提交指挥对事务设计的数据加写锁，且一直持续到事务结束，完全不加读锁。读未提交比读已提交弱化的地方在于脏读问题。</p><blockquote><p>不同隔离级别以及幻读、不可重复读、脏读等问题都只是表面现象，是各种锁在不同加锁时间上的组合应用所产生的结果，以锁为手段来实现隔离性才是数据库表现出不同隔离级别的根本原因。</p></blockquote><h4 id="MVCC"><a href="#MVCC" class="headerlink" title="MVCC"></a>MVCC</h4><p>除了都以锁来实现外，以上四种隔离级别还有另外一个共同特点，就是幻读、不可重复读、脏读等问题都是由于一个事务在读数据的过程中，受另外一个写数据的事务影响而破坏了隔离性。针对“一个事务读+另一个事务写”的隔离问题，MVCC的无锁优化方案被主流的数据库广泛采用。</p><p>MVCC是一种读取优化策略，它的“无锁”特指读取时不需要加锁。</p><p>MVCC的基本思路是对数据库的任何修改都不会直接覆盖之前的数据，而是产生一个新版本与老版本共存。版本可以理解为数据库中每一行记录都存在两个看不见的字段：CREATE_VERSION和DELETE_VERSION，这两个字段记录的值都是事务ID。事务ID是一个全局严格递增的值，根据以下规则写入数据：</p><ul><li>插入数据：CREATE_VERSION记录插入数据的事务ID，DELETE_VERSION为空。</li><li>删除数据：DELETE_VERSION记录删除数据的事务ID，CREATE_VERSION为空。</li><li>修改数据：即“删除旧数据，插入新数据”的组合，将原有数据复制一份，原有数据的DELETE_VERSION记录修改数据的事务ID，CREATE_VERSION为空。复制后的新数据CREATE_VERSION记录修改数据的事务ID，DELETE_VERSION为空。</li></ul><p>另一个事务读取这些发生变化的数据，根据隔离级别决定读取哪个版本的数据。</p><ul><li>可重复读：总是读取CREATE_VERSION小于等于当前事务ID的记录，数据有多个版本取最新的。</li><li>读已提交：总是读最新的版本即可。</li></ul><h2 id="全局事务"><a href="#全局事务" class="headerlink" title="全局事务"></a>全局事务</h2><p>全局事务指的是单个服务使用多个数据源场景的事务解决方案。</p><h4 id="两阶段提交"><a href="#两阶段提交" class="headerlink" title="两阶段提交"></a>两阶段提交</h4><p><strong>准备阶段</strong>：协调者询问事务的所有参与者是否准备好提交，参与者如果已经准备好提交则回复Prepared，否则回复Non-Prepared。准备好的意思是在重做日志中记录全部事务提交操作所要作的内容，它与本地事务中真正提交的区别只是暂不写入最后一条commit record而已。当前状态仍继续持有锁。</p><p><strong>提交阶段</strong>：如果协调者收到所有事务参与者回复的Prepared消息，则自己先在本地持久化事务的完成状态置为commit，然后向所有参与者发送commit指令。如果任意一个参与者回复了Non-Prepared消息，或者超时未回复，协调者将自己完成事务状态置为abort，再向所有参与者发送abort指令，让参与者进行回滚。</p><blockquote><p>两阶段提交能够成功保证一致性还需要其他的前提条件：</p><p>必须假设网络在提交阶段的短时间内是可靠的，提交阶段不会丢消息。</p><p>必须假设因为网络分区，机器崩溃等原因导致失联的节点最终能够恢复，不会永久处于失联状态。</p><p>且上述的协调者、参与者通常都是数据库自己扮演，不需要应用程序介入。协调者一般是选举产生。</p></blockquote><p><strong>缺点</strong>：</p><ul><li>单点问题：协调者宕机的话，所有参与者都必须一直等待。</li><li>性能问题：所有参与者都被绑定为一个统一调度的整体，期间要两次远程调用，三次数据持久化（准备阶段写重做日志，协调者做状态持久化，提交阶段在日志写提交记录）</li><li>一致性风险：前提条件不成立时，仍会有一致性问题。</li></ul><blockquote><p>FLP不可能原理：</p><p>如果宕机最后不能恢复，那就不存在任何一种分布式协议可以正确地达成一致性结果。</p></blockquote><h4 id="三阶段提交"><a href="#三阶段提交" class="headerlink" title="三阶段提交"></a>三阶段提交</h4><p>由于两阶段提交存在协调者的单点问题和准备阶段的性能问题，发展出了三阶段提交。</p><p>三阶段提交把原来的两阶段提交的准备阶段再细分为两个阶段，即CanCommit、PreCommit，把提交阶段改为DoCommit。CanCommit是询问阶段，协调者让每个参与的数据库根据自身状态，评估该事务是否有可能顺利完成。</p><p>在事务需要回滚的场景中，三阶段提交比两阶段提交的性能好很多，但正常情况下，两者的性能都很差，三阶段提交多一次询问，性能还要稍微更差。</p><p>事务失败回滚的概率变小，三阶段提交如果PreCommit后协调者宕机，参与者默认是提交事务，避免了协调者单点问题。</p><h2 id="分布式事务"><a href="#分布式事务" class="headerlink" title="分布式事务"></a>分布式事务</h2><p>分布式事务指的是多个服务同时访问多个数据源的事务处理机制。</p><h4 id="CAP和ACID"><a href="#CAP和ACID" class="headerlink" title="CAP和ACID"></a>CAP和ACID</h4><p>CAP指的是一个分布式系统，在涉及共享数据问题时，以下三个特性最多只能同时满足两个：</p><ul><li>一致性 C：数据在任何时刻，任何分布式节点所看到的都是符合预期的。</li><li>可用性 A：代表系统不间断的提供服务的能力。</li><li>分区容忍性 P：分布式环境中部分节点因网络原因而彼此失联后，系统扔能正确提供服务的能力。</li></ul><h4 id="可靠事件队列"><a href="#可靠事件队列" class="headerlink" title="可靠事件队列"></a>可靠事件队列</h4><p>BASE理论是由eBay工程师提出，是对可用性和一致性的权衡。BASE是由 Basically Available(基本可用)，Soft state（软状态）,和 Eventually consistent（最终一致性）三个短语的缩写。</p><p>**Basically Available(基本可用)**：通过延迟响应，流量削峰等手段来保障系统的核心功能的正常，从而实现基本可用。</p><p><strong>Eventually consistent(最终一致性)</strong> ：我们不能随时都保障数据的一致，所以我们有了数据的中间状态，即软状态，经过一定时间后，数据最终回归于最终一致。</p><p><strong>Soft state(软状态)</strong> ：软状态故名思意就是可以变动的状态，强调的是数据状态处于一种中间状态。</p><p>可靠事件队列是依靠不断重试的方案来保证可靠性。</p><h4 id="TCC事务"><a href="#TCC事务" class="headerlink" title="TCC事务"></a>TCC事务</h4><p>TCC是一种业务侵入式的事务方案。分为三阶段：</p><ol><li>Try：尝试执行阶段，完成所有业务可执行性的检查，并预留好全部业务需要用到的业务资源（锁资源）。</li><li>Confirm：确认执行阶段，不进行任何业务检查，直接使用Try阶段准备的资源完成业务处理。可能会重复执行，需要保证幂等。</li><li>Cancel：取消执行阶段，释放Try阶段预留的资源。</li></ol><h4 id="SAGA事务"><a href="#SAGA事务" class="headerlink" title="SAGA事务"></a>SAGA事务</h4><p>TCC事务有个缺点，是业务侵入性很强，必须预先锁好资源，假如无法锁定资源，就无法实现了。</p><p>SAGA事务是一种将大事务拆分成若干小事务的设计模式。</p><p>SAGA 由两部分操作组成。</p><ul><li>大事务拆分若干个小事务，将整个分布式事务 T 分解为 n 个子事务，命名为 T1，T2，…，Ti，…，Tn。每个子事务都应该是或者能被视为是原子行为。如果分布式事务能够正常提交，其对数据的影响（最终一致性）应与连续按顺序成功提交 Ti等价。</li><li>为每一个子事务设计对应的补偿动作，命名为 C1，C2，…，Ci，…，Cn。Ti与 Ci必须满足以下条件：<ul><li>Ti与 Ci都具备幂等性。</li><li>Ti与 Ci满足交换律（Commutative），即先执行 Ti还是先执行 Ci，其效果都是一样的。</li><li>Ci必须能成功提交，即不考虑 Ci本身提交失败被回滚的情形，如出现就必须持续重试直至成功，或者要人工介入。</li></ul></li></ul><p>如果 T1到 Tn均成功提交，那事务顺利完成，否则，要采取以下两种恢复策略之一：</p><ul><li><strong>正向恢复</strong>（Forward Recovery）：如果 Ti事务提交失败，则一直对 Ti进行重试，直至成功为止（最大努力交付）。这种恢复方式不需要补偿，适用于事务最终都要成功的场景，譬如在别人的银行账号中扣了款，就一定要给别人发货。正向恢复的执行模式为：T1，T2，…，Ti（失败），Ti（重试）…，Ti+1，…，Tn。</li><li><strong>反向恢复</strong>（Backward Recovery）：如果 Ti事务提交失败，则一直执行 Ci对 Ti进行补偿，直至成功为止（最大努力交付）。这里要求 Ci必须（在持续重试后）执行成功。反向恢复的执行模式为：T1，T2，…，Ti（失败），Ci（补偿），…，C2，C1。</li></ul>]]></content>
    
    
    <summary type="html">日志写入commit record，整个事务就是成功的，重启后根据已经写入磁盘的日志信息恢复现场。缺陷是所有对数据的真实修改都必须发生在事务提交之后，即日志写入了commit record之后。。</summary>
    
    
    
    <category term="凤凰架构" scheme="https://zzugzj.github.io/categories/%E5%87%A4%E5%87%B0%E6%9E%B6%E6%9E%84/"/>
    
    
    <category term="学习笔记" scheme="https://zzugzj.github.io/tags/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    
    <category term="凤凰架构" scheme="https://zzugzj.github.io/tags/%E5%87%A4%E5%87%B0%E6%9E%B6%E6%9E%84/"/>
    
  </entry>
  
  <entry>
    <title>批处理系统</title>
    <link href="https://zzugzj.github.io/posts/4d278c8b/"/>
    <id>https://zzugzj.github.io/posts/4d278c8b/</id>
    <published>2022-01-16T06:37:13.888Z</published>
    <updated>2023-11-05T05:53:36.745Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>许多现有数据系统中都采用这种数据处理方式：你发送请求指令，一段时间后(我们期望)系统会给出一个结果。</p><p>三种不同类型的系统：</p><p> <strong><em>服务（在线系统）</em></strong></p><p>服务等待客户的请求或指令到达。<strong>每收到一个，服务会试图尽快处理它，并发回一个响应。</strong>响应时间通常是服务性能的主要衡量指标，可用性通常非常重要（如果客户端无法访问服务，用户可能会收到错误消息）。</p><p><strong><em>批处理系统（离线系统）</em></strong></p><p>一个批处理系统有大量的输入数据，跑一个<strong>作业（job）</strong>来处理它，并生成一些输出数据，这往往需要一段时间（从几分钟到几天），所以通常不会有用户等待作业完成。相反，批量作业通常会定期运行（例如，每天一次）。批处理作业的主要性能衡量标准通常是吞吐量（处理特定大小的输入所需的时间）。</p><p><strong><em>流处理系统（准实时系统）</em></strong></p><p>流处理介于在线和离线（批处理）之间，所以有时候被称为<strong>准实时（near-real-time）</strong>或<strong>准在线（nearline）</strong>处理。像批处理系统一样，<strong>流处理消费输入并产生输出（并不需要响应请求）</strong>。但是，流式作业在事件发生后不久就会对事件进行操作，而批处理作业则需等待固定的一组输入数据。这种差异使流处理系统比起批处理系统具有更低的延迟。</p><h3 id="UNIX设计哲学"><a href="#UNIX设计哲学" class="headerlink" title="UNIX设计哲学"></a>UNIX设计哲学</h3><ol><li>每个程序做好一件事。如果要做新的工作，则建立一个全新的程序，而不是通过增加新 “特征” 使旧程序变得更加复杂。</li><li>期待每个程序的输出成为另一个尚未确定的程序的输入。不要将输出与无关信息混淆在一起。避免使用严格的表格状或二进制输入格式。不要使用交互式输入。</li><li>尽早尝试设计和构建软件，甚至是操作系统，最好在几周内完成。需要扔掉那些笨拙的部分时不要犹豫，并立即进行重建。</li><li>优先使用工具来减轻编程任务，即使不得不额外花费时间去构建工具，并且预期在使用完成后将其中的一些工具扔掉。</li></ol><h2 id="MapReduce与分布式文件系统"><a href="#MapReduce与分布式文件系统" class="headerlink" title="MapReduce与分布式文件系统"></a>MapReduce与分布式文件系统</h2><p>类似UNIX工具，MapReduce需要一个或多个输入，并产生一个或多个输出。在Hadoop的MapReduce实现中，该文件系统称为HDFS，一个Google文件系统的开源实现版本。</p><p>HDFS包含一个在每台机器上运行的守护进程，并会开放一个网络服务以允许其他节点访问存储在该机器上的文件。名为NameNode的中央服务器会跟踪哪个文件块存储在那台机器上。考虑到容错，文件块会被复制到多台机器上。</p><h3 id="MapReduce作业执行"><a href="#MapReduce作业执行" class="headerlink" title="MapReduce作业执行"></a>MapReduce作业执行</h3><ol><li>首先读入一组文件，将其分解成记录（records）。</li><li>调用mapper函数从每个输入记录中提取一个键值对。</li><li>按关键字将所有的键值对排序。</li><li>调用reducer函数遍历排序后的所有键值对。如果一个键出现多次，排序会使它们在列表相邻，所以会很容易组合这些值，不用在内存保留很多状态。</li></ol><p><strong><em>mapper</em></strong></p><p>每个输入记录都会调用一次mapper，其任务是从输入记录中提取关键字和值。对每个输入记录，它可以生成任意数量的键值对。</p><p><strong><em>reducer</em></strong></p><p>MapReduce框架使用由mapper生成的键值对，收集属于同一个关键字的所有值，并使用迭代器调用reducer以使用该值的集合。Reducer可以输出记录（算出来的结果）。</p><h4 id="MapReduce的分布式执行"><a href="#MapReduce的分布式执行" class="headerlink" title="MapReduce的分布式执行"></a>MapReduce的分布式执行</h4><p>MapReduce可以跨多台机器进行分布式并行计算，而且不用编写代码来指示如何并行化。在分布式计算中可以使用标准的UNIX工具作为mapper和reducer，但更长见的是编写代码，比如Hadoop的mapper和reducer都是实现特定接口的Java类。</p><p><img src="https://raw.githubusercontent.com/zzugzj/blogImg/master/img/fig10-1.png" alt="img" loading="lazy"></p><center>具有三个Mapper和三个Reducer的MapReduce任务</center><p>上图是MapReduce作业中的数据流，并行化基于分区实现：作业的输入通常是HDFS中的一个目录，且输入目录中的每个文件或文件块都被视为一个单独的分区，可以由一个单独的map任务来处理。</p><p>一个输入文件通常比较大（几百M），只要有足够的空闲内存和CPU资源，MapReduce调度器会尝试在输入文件副本的某台机器运行mapper任务，这个原则被称为计算就近数据：它避免了输入文件通过网络复制，减少网络负载，提高了访问局部性。</p><p>由于map任务运行的应用程序代码在分配运行任务的节点并不存在，所以MapReduce框架首先要复制代码到该节点。Reduce任务中的计算也被分割成块，Map任务的数量由输入文件块的数量决定，而reduce任务的数量则是由作业的作者配置的。为了确保具有相同关键字的所有键值对都在相同的reducer任务中处理，框架使用关键字的hash值来确定哪个reduce任务接受特定的键值对。</p><p>键值对必须排序，如果数据集太大，可能也无法在单机进行常规的排序算法。事实上，排序是分阶段进行的。首先，每个map任务根据关键字hash值，按照reducer对输出进行分区。每个分区都被写入mapper程序的本地磁盘上的已排序文件。</p><p>当mapper完成读取输入文件并写入经过排序后的输出文件，MapReduce调度器就会通知reducer开始从mapper中获取输出文件。reducer与每个mapper相连，并按照其分区从mapper中下载排序后的键值对文件。按照reducer分区，排序，和将数据分区从mapper复制到reducer，这样一个过程称为shuffle。</p><p>reduce任务从mapper获取文件并将它们合并在一起，同时保持数据的顺序。</p><p>reducer通过关键字和迭代器为参数来调用，迭代器扫描所有具有相同关键字的记录，并用任意逻辑处理这些记录，然后生成任意数量的输出记录。这些输出记录被写入分布式文件系统中的文件。（通常是在跑Reducer的机器本地磁盘上留一份，并在其他机器上留几份副本）。</p><h4 id="MapReduce工作流"><a href="#MapReduce工作流" class="headerlink" title="MapReduce工作流"></a>MapReduce工作流</h4><p>单个MapReduce作业可以解决的问题范围有限。类似的，UNIX工具，单个工具只能完成部分操作。</p><p>因此，将MapReduce作业链接到工作流是很普遍的，这样，一个作业的输出会称为下一个作业的输入。Hadoop MapReduce框架对工作流并没有任何特殊的支持，所以链接方式是通过目录名隐式完成的：第一个作业必须配置为将其输出写入HDFS的指定目录，而第二个作业必须配置为读取相同的目录名作为输入。而MapReduce框架角度来看，它们是两个独立的作业。</p><p>所以，链接方式的MapReduce不像UNIX命令流水线（直接将进程的输出作为输入传给下一个进程，只需要很小的内存缓冲区），而是更像一系列命令，其中每个命令的输出被写入临时文件，下个命令从临时文件读取。</p><p>只有当作业成功完成时，批处理作业的输出才会被视为有效。因此，作业只有当前面的作业成功完成时才开始。</p><h3 id="Reduce端的join与分组"><a href="#Reduce端的join与分组" class="headerlink" title="Reduce端的join与分组"></a>Reduce端的join与分组</h3>]]></content>
    
    
    <summary type="html">批处理系统，又名批处理操作系统。批处理是指用户将一批作业提交给操作系统后就不再干预，由操作系统控制它们自动运行。</summary>
    
    
    
    <category term="分布式" scheme="https://zzugzj.github.io/categories/%E5%88%86%E5%B8%83%E5%BC%8F/"/>
    
    
    <category term="分布式" scheme="https://zzugzj.github.io/tags/%E5%88%86%E5%B8%83%E5%BC%8F/"/>
    
    <category term="数据库" scheme="https://zzugzj.github.io/tags/%E6%95%B0%E6%8D%AE%E5%BA%93/"/>
    
  </entry>
  
  <entry>
    <title>一致性与共识</title>
    <link href="https://zzugzj.github.io/posts/6f7dffae/"/>
    <id>https://zzugzj.github.io/posts/6f7dffae/</id>
    <published>2021-08-26T14:44:10.002Z</published>
    <updated>2023-11-05T05:53:43.365Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>接下来是一些分布式系统的相关算法和协议。为了构建容错系统，最好先建立一套通用的抽象机制和与之对应的技术保证，这样只需一次，上面的应用层都可以安全的信赖底层的保证。<strong>分布式系统最重要的抽象之一是共识：所有的节点就某一项提议达成一致。</strong></p><h2 id="一致性保证"><a href="#一致性保证" class="headerlink" title="一致性保证"></a>一致性保证</h2><p>大多数多副本数据库都至少提供了最终的一致性，但这是一个非常弱的保证，不知道系统什么时候达到一致。这让我们开发起应用来非常麻烦。因此需要更强的一致性模型，也意味着更多的代价，如性能降低或容错性差等。但这样可以使上层逻辑简单，更不容易出错。</p><h2 id="可线性化（强一致性）"><a href="#可线性化（强一致性）" class="headerlink" title="可线性化（强一致性）"></a>可线性化（强一致性）</h2><p>如果数据库能对上提供之一单个副本的假象，那查询起来就会很方便。这就是<strong>可线性化（也叫原子一致性，强一致性）</strong>的思想。基本的想法是让一个系统看起来好像只有一个副本，所有操作都是原子的。</p><p>在一个可线性化的系统中，一个客户端成功提交写请求，所有客户端的读请求一定能看到刚刚写入的值。</p><p>这是一个非线性化系统的例子：</p><p><img src="https://raw.githubusercontent.com/zzugzj/blogImg/master/img/fig9-1.png" loading="lazy"></p><h3 id="如何达到线性化？"><a href="#如何达到线性化？" class="headerlink" title="如何达到线性化？"></a>如何达到线性化？</h3><p>下图是三个客户端在线性一致数据库中同时读写相同的键 x。分布式语义下，x 称为寄存器，可能是键值存储的一个键，关系数据库的一行。</p><p><img src="https://raw.githubusercontent.com/zzugzj/blogImg/master/img/fig9-2.png" loading="lazy"></p><p>每条线代表一个客户端请求，网络延迟不确定，客户端不知道数据库具体什么时候处理。</p><p>A 和 B 可能会读到的值：</p><ul><li>客户端A的第一个读操作，完成于写操作开始之前，因此必须返回旧值 <code>0</code>。</li><li>客户端A的最后一个读操作，开始于写操作完成之后。如果数据库是线性一致性的，它必然返回新值 1。</li><li>与写操作在时间上重叠的任何读操作，可能会返回 <code>0</code> 或 <code>1</code> ，因为我们不知道读取时，写操作是否已经生效。这些操作是<strong>并发（concurrent）</strong>的。</li></ul><p>如果与写并发的读操作可能返回旧值或新值，那么不同客户端会看到旧值和新值之间来回变的情况。这不符合 ”单一数据副本“ 。</p><p>为了让系统可线性化，需要添加一个重要的约束：</p><p><img src="https://raw.githubusercontent.com/zzugzj/blogImg/master/img/fig9-3.png" loading="lazy"></p><p>在一个可线性化的系统中，写操作的开始和结束间必定存在一个时间点，x 值从 0 到 1 改变。如果某个客户端读到了新值 1，即使写操作没提交，后续的读取也要返回新值。</p><blockquote><p><strong>可线性化与可串行化</strong></p><p>两个词似乎都在表达类似 ”可以按顺序排列“ 的意思，但它们完全不同。</p><p><em>可串行化</em></p><p>是事务的隔离属性，确保事务的执行结果与串行执行的结果完全相同。</p><p><em>可线性化</em></p><p>可线性化是读写寄存器（单个对象）的最新值保证。不要求将操作组合到事务中，因此无法避免写倾斜等问题，除非采取额外措施（如实现实体化冲突）。</p><p>数据库可同时支持可串行化和线性化，这种组合又被称为严格的可串行化或者强的单副本可串行化。基于两阶段加锁或实际以串行执行都是典型的可线性化。但可串行化的快照隔离不是线性化的：按照涉及，从一致性快照读取，避免读写竞争。一致性快照的要点在于里面不包括创建快照时刻后的写入数据，所以不满足线性化。</p></blockquote><h3 id="线性化的依赖条件"><a href="#线性化的依赖条件" class="headerlink" title="线性化的依赖条件"></a>线性化的依赖条件</h3><p>什么情况下使用线性化呢？有时存在几秒的延迟不会有很大的伤害，但有时线性化很重要。</p><h4 id="加锁与主节点选举"><a href="#加锁与主节点选举" class="headerlink" title="加锁与主节点选举"></a>加锁与主节点选举</h4><p>主从复制要确保只有一个主节点，否则会产生脑裂。选举新的主节点经常使用锁。在这种方式中，不管锁具体如何实现，它必须满足可线性化：所有节点都必须同意哪个节点持有锁，否则就会出现问题。</p><p>如 ZooKeeper 和 etcd 经常使用分布式锁和主节点选举。它们都使用了支持容错的共识算法确保可线性化。</p><p>在一些分布式数据库如 Oracle Real Application Clusters（RAC），分布式锁有更细粒度的实现：RAC 为每个磁盘页面均设置了一把锁，多个节点可以并发地共享访问存储系统。这些可线性化的锁处于事务执行的关键路径上，出于性能考虑，RAC 部署时通常都要求专用的集群互联网络来连接数据库节点。</p><h4 id="约束与唯一性保证"><a href="#约束与唯一性保证" class="headerlink" title="约束与唯一性保证"></a>约束与唯一性保证</h4><p>唯一性约束在数据库中很常见。在写入时强制执行这些约束，也需要线性化。</p><p>硬性的唯一性约束，如主键，需要线性化保证，其他如外键和属性约束，不要求一定线性化。</p><h4 id="跨通道的时间依赖"><a href="#跨通道的时间依赖" class="headerlink" title="跨通道的时间依赖"></a>跨通道的时间依赖</h4><p>可能存在如下情况：</p><p><img src="https://raw.githubusercontent.com/zzugzj/blogImg/master/img/fig9-5.png" loading="lazy"></p><p>如果文件存储是可线性化的，那么系统应该可以正常工作。否则就可能出现消息队列比存储服务内部的复制执行更快。那么可能在操作图片时，可能读到旧版本或根本读不到内容。</p><h3 id="实现线性化系统"><a href="#实现线性化系统" class="headerlink" title="实现线性化系统"></a>实现线性化系统</h3><p>线性化本质上意味着 ”表现得好像只有一个数据副本，且其上的所有操作都是原子的“。</p><p>系统容错最常见的是采用复制机制。复制中介绍了多种复制方案：</p><p><strong>主从复制（部分支持可线性化）</strong></p><p>单主复制中，如果数据都从主节点或同步的从节点读取，则满足线性化。但并非每个主从复制的具体数据库实例都是可线性化的，因为他们可能采用了快照隔离的设计。如果使用异步复制，故障切换可能丢失部分写入，违反持久性和线性化。</p><p><strong>共识算法（可线性化）</strong></p><p>与主从复制类似，不过共识协议通常内置一些措施防止脑裂和过期的副本。</p><p><strong>多主复制（不可线性化）</strong></p><p>多个主节点并发执行写入，异步复制到其他节点，可能产生冲突的写入，没办法线性化。</p><p><strong>无主复制（可能不可线性化）</strong></p><p>对于无主复制的系统，有人认为只有配置法定读取和写入满足（ w + r &gt; n ）就可以获得 ”强一致性“，但这取决于具体法定人数的配置，它可能并不保证线性化。</p><h4 id="线性化与法定人数"><a href="#线性化与法定人数" class="headerlink" title="线性化与法定人数"></a>线性化与法定人数</h4><p>对于规范的 Dynamo 风格复制模型，如果读写遵从了 严格 quorum，应该是可线性化的。如果遭遇不确定的网络延迟，就会出现竞争条件。</p><p><img src="https://raw.githubusercontent.com/zzugzj/blogImg/master/img/fig9-6.png" loading="lazy"></p><p>它虽然满足仲裁条件，但很明显不是线性化的。</p><p>使用 Dynamo 风格的复制系统以牺牲性能为代价来满足线性化：读操作在返回结果给应用前，必须同步执行读修复，而写操作在发送结果前，必须读取 quorum 节点来获取新值。这样显著降低性能。由于显著降低性能，Riak 不支持同步读修复，Cassandra 虽然等待读修复完成，但使用了 ”最后写入获胜“ 冲突解决方案，出现同一个主键并发写入，就会丧失线性化。</p><p>这种方式只能实现线性化读、写，不支持线性化的 cas 操作，cas 需要共识算法的支持。</p><p>所以，最安全的假定就是类似 Dynamo 风格的无主复制无法保证可线性化。</p><h3 id="线性化的代价"><a href="#线性化的代价" class="headerlink" title="线性化的代价"></a>线性化的代价</h3><p>多主复制中，如果两个数据中心发生网络中断，则数据中心内部可以正常运行，但数据中心间的交互复制就会出问题，从一个数据中心到另一个数据中心的复制是异步，期间的操作暂存在本地，等网络恢复后继续同步。</p><p>如果是主从复制，主节点肯定在某个数据中心，数据中心间的网络一旦中断，连接到从数据中心的客户端无法联系主节点，就无法完成数据的写入和线性化读取。从节点可以提供读服务，但内容可能是过期的。如果应用程序要求线性化读写，网络中断一定违背这样的要求。但客户端连接到主节点所在的数据中心，则可以避免此问题。</p><h4 id="CAP理论"><a href="#CAP理论" class="headerlink" title="CAP理论"></a>CAP理论</h4><p>只要有不可靠的网络，都会发生违背线性化的风险。所以做如下考虑：</p><ul><li>应用要求线性化，但网络出问题，就必须等待网络恢复，或直接返回错误。无论哪种方式，结果就是服务不可用。</li><li>如果应用不要求线性化，那么网络出问题后，每个副本可独立处理请求。此时服务可用，但不满足线性化。</li></ul><p>不要求线性化的应用容忍网络故障，这个思路称为CAP定理。</p><p>CAP代表一致性、可用性、分区容错性。在网络正常时，一致性（线性化）和可用性都可以保证。而发生网络故障，要不现在一致性，要么可用性。所以 CAP 也是 <strong>“网络分区情况下，选择一致还是可用”</strong> 。</p><h4 id="可线性化与网络延迟"><a href="#可线性化与网络延迟" class="headerlink" title="可线性化与网络延迟"></a>可线性化与网络延迟</h4><p>虽然线性化是很有用的保证，但很少有系统真正满足线性化。现代多核 CPU 上的内存甚至是非线性化：某个 CPU 核上运行的线程修改了一个内存地址，另一个 CPU 核上的线程尝试读取，则系统无法保证可以读到刚刚写入的值，除非使用内存屏障或 fence 指令。</p><p>CAP 理论不适用多核-内存一致性模型：计算机内部通常假设通信可靠，不会假定 CPU 核和其他核断开后依然正常工作。放弃线性化的原因是性能。许多分布式数据库也类似。放弃线性化是提高性能。</p><p>考虑多数计算机网络高度不确定的网络延迟，线性化读写性能势必非常差。没有足够快的线性化算法，弱一致性模型性能则快得多。</p><h2 id="顺序保证"><a href="#顺序保证" class="headerlink" title="顺序保证"></a>顺序保证</h2><p>之前提到的，线性化寄存器对外呈现的好像只有一份数据拷贝，而且每一个操作似乎都是原子性生效。意味着操作是按某种顺序执行。</p><h3 id="顺序与因果关系"><a href="#顺序与因果关系" class="headerlink" title="顺序与因果关系"></a>顺序与因果关系</h3><p>顺序之所以如此重要，是因为它能保持因果关系。因果关系对所发生的事件施加了某种排序：发送消息先于收到消息；问题出现在答案之前等。</p><p>如果系统服从因果关系所规定的顺序，我们称为因果一致性。比如快照隔离提供了因果一致性：从数据库中读数据时，如果查询到某些数据，也一定能看到触发该数据的前序事件。</p><h4 id="因果顺序并非全序"><a href="#因果顺序并非全序" class="headerlink" title="因果顺序并非全序"></a>因果顺序并非全序</h4><p><strong>全序</strong>允许任意两个元素进行比较，如果有两个元素，你总是可以说出哪个更大，哪个更小。</p><p>全序和偏序的差异也会体现在不同的数据库一致性模型中：</p><ul><li><p><strong><em>可线性化</em></strong></p><p>在可线性化的系统中，操作是全序的：如果系统表现的就好像只有一个数据副本，并且所有操作都是原子性的，这意味着对任何两个操作，我们总是能判定哪个操作先发生。</p></li><li><p><strong><em>因果关系</em></strong></p><p>如果两个操作都没有发生在对方之前，那么这两个操作是并发关系。如果这两个事件是因果关系（一个发生在另一个之前），那么这两个事件可以被排序；而并发的事件则无法排序比较。这表明因果关系至少可以是偏序，而非全序。</p></li></ul><p>因此，可线性化数据存储中不存在并发操作，一定有一个时间线将所有操作都全序执行。</p><h4 id="可线性化强于因果一致性"><a href="#可线性化强于因果一致性" class="headerlink" title="可线性化强于因果一致性"></a>可线性化强于因果一致性</h4><p><strong>可线性化一定意味着因果关系：任何可线性化的系统都将正确的保证因果关系。</strong></p><p>可线性化可以确保因果性这一结论，使线性化系统更加简单易懂而富有吸引力。但线性化会显著降低性能和可用性。</p><p>但线性化也不是唯一保证因果关系的途径，还有其他办法使系统满足因果一致性，而免于线性化带来的性能问题。<strong>因果一致性可以认为是不会由于网络延迟而显著影响性能，又能对网络故障提供容错的最强的一致性模型。</strong></p><p>许多情况下，看似需要线性化的系统实际上需要的只是因果一致性，后者的实现可以高效许多。</p><h4 id="捕获因果依赖关系"><a href="#捕获因果依赖关系" class="headerlink" title="捕获因果依赖关系"></a>捕获因果依赖关系</h4><p>为了确定因果依赖，我们需要一些方法来描述系统中节点的 “知识” 。如果节点在写入Y 的请求时已经看到了 X 的值，则 X 和 Y 可能属于因果关系。确定请求的先后顺序与第五章 “检测并发写” 类似，因果一致性需要更进一步，跟踪整个数据库请求的因果关系，不仅仅是针对某个主键。版本向量技术可以推广为一种通用的解决方案。</p><h3 id="序列号排序"><a href="#序列号排序" class="headerlink" title="序列号排序"></a>序列号排序</h3><p>虽然因果关系很重要，但实际上跟踪所有因果关系不切实际。许多应用中，客户端写入前会先读取大量数据，系统无法了解之后的写入依赖那一部分。显示跟踪所有已读数据意味着巨大的运行开销。</p><p>有个更好的办法：使用序列号或时间戳来排序事件。时间戳不一定是墙上时钟，可以是一个逻辑时钟，比如算法产生一个数字递增序列。</p><p>也就是说，每个操作都有一个唯一的序列号，可以比较哪个大。</p><p>可以按照与因果关系一致的顺序来创建序列号：操作 A 如果发生在 B 前，A 一定在全序中出现在 B 之前（A 的序列号更小）。</p><p>在主从复制数据库中，复制日志定义了与因果关系一致的写操作全序关系。主节点可以简单地为每个操作递增某个计数器，从而为复制日志中的每个操作赋值一个单调递增的序列号。结果一定满足因果一致性，虽然可能落后于主节点。</p><h4 id="非因果序列发生器"><a href="#非因果序列发生器" class="headerlink" title="非因果序列发生器"></a>非因果序列发生器</h4><p>如果系统不存在这样唯一的主节点，如何产生序列号就不那么简单了，实践中一般采用如下方法：</p><ul><li>每个节点都可以生成自己独立的一组序列号。例如有两个节点，一个节点只能生成奇数，而另一个节点只能生成偶数。通常，可以在序列号的二进制表示中预留一些位，用于唯一的节点标识符，这样可以确保两个不同的节点永远不会生成相同的序列号。</li><li>可以将时钟（物理时钟）时间戳附加到每个操作上。这种时间戳并不连续，但是如果它具有足够高的分辨率，那也许足以区分操作。</li><li>可以预先分配序列号区块。例如，节点 A 可能要求从序列号 1 ~ 1,000 序列号的所有权，而节点 B 可能要求序列号 1,001 ~ 2,000 权。然后每个节点可以独立分配所属区间中的序列号，并在序列号告急时请求分配一个新的区间。</li></ul><p>这三个选项都比单主节点的自增计数器表现要好，并且更具可伸缩性。它们为每个操作生成一个唯一的，近似自增的序列号。然而它们都有同一个问题：生成的序列号与因果不一致：</p><ul><li>每个节点每秒可以处理不同数量的操作。因此，如果一个节点产生偶数序列号而另一个产生奇数序列号，则偶数计数器可能落后于奇数计数器，</li></ul><ul><li><p>来自物理时钟的时间戳会受到时钟偏移的影响，这可能会使其与因果不一致。</p></li><li><p>在分配区块的情况下，某个操作可能会被赋予一个范围在 1001 ~ 2000 内的某个序列号，然而一个后发生的操作可能路由到另一个节点，被赋予一个范围在 1 ~ 1000 之间的数字。这里序列号与因果关系也是不一致的。</p></li></ul><h4 id="lamport-时间戳"><a href="#lamport-时间戳" class="headerlink" title="lamport 时间戳"></a>lamport 时间戳</h4><p>为了解决以上问题， Leslie Lamport 在 1978 年提出了可以产生因果关系一致的序列号的方法，称为兰伯特时间戳。</p><p><img src="https://raw.githubusercontent.com/zzugzj/blogImg/master/img/fig9-8.png" loading="lazy"></p><p>如图，每个节点都有唯一标识符，且有一个计数器来记录各自处理的请求总数。 Lamport 时间戳是一个值对（计数器，节点 ID）。时间戳是唯一的。</p><p>Lamport 时间戳可以保证全序：给定两个 Lamport 时间戳，计数器较大的那个时间戳大；如计数器值一样，则节点 ID 越大，时间戳越大。</p><p>Lamport 的核心亮点在于使它们与因果性保存一致：每个节点以及每个客户端都跟踪迄今为止见到的最大计数器值，并在每个请求中附带该最大计数器值。当节点收到某个请求或回复时，如果发现请求内嵌的最大计数器值大于节点自身的计数器值，则它立即把自己的计数器值修改为该最大值。</p><p>只要把最大计数器值嵌入到每个请求中，该方案可以确保 Lamport 时间戳与因果关系一致，而请求的因果依赖性一定会保证后发生的请求得到更大的时间戳。</p><h4 id="时间戳排序依然不够"><a href="#时间戳排序依然不够" class="headerlink" title="时间戳排序依然不够"></a>时间戳排序依然不够</h4><p>如果，一个账户系统需要确保用户名唯一标识用户，两个用户使用相同用户名创建账户时，一定有一个失败。</p><p>如果有这样的操作，一般选取时间戳较低的那个作为获胜者即可，但这样有个前提，节点知道有另一个节点同时创建相同用户名。</p><p>为了得到这个信息，系统必须检查每个节点，如果网络出问题，系统则无法运转。</p><p>这个问题的关键是，只要收集所有请求的信息后，才知道这些请求间的全序关系。</p><p>为了解决这个问题，仅仅对操作进行全序排列是不够的，还需要知道操作是否发生，何时确定等。假如能够在创建用户名时，以及确定有没有其他节点执行相同用户名的创建，就可以直接返回操作成功还是失败。</p><p>想知道什么时候全序关系已经确定需要之后的 “全序关系广播”。</p><h3 id="全序关系广播"><a href="#全序关系广播" class="headerlink" title="全序关系广播"></a>全序关系广播</h3><p>全序关系广播通常指节点之间交互消息的某种协议。它要求满足两个基本安全属性：</p><ul><li><p>可靠发送</p><p>没有消息丢失，如果消息发送到了某个节点，则它一定要发送到所有节点。</p></li><li><p>严格有序</p><p>消息总是以相同顺序发送给每个节点。</p></li></ul><p>即节点或网络出故障，全序关系广播算法也要保证上述两条。网络中断是不可能发送成功的，算法要继续重试，直到网络修复，消息发送成功并且以正确的顺序。</p><h4 id="使用全序关系广播"><a href="#使用全序关系广播" class="headerlink" title="使用全序关系广播"></a>使用全序关系广播</h4><p>ZooKeeper 和 etcd 这种共识服务实际上就实现了全序广播。</p><p>全序关系广播正是数据库复制需要的：如果每个消息都代表一次数据库的写入，且每个副本都按相同的顺序处理相同的写入，那么副本间将相互保持一致（可能有些滞后）。这个原理被称为<strong>状态机复制（state machine replication）</strong>。</p><p>全序关系广播的顺序在发送消息时就确定了，也可以将其视为日志，传递消息就像追加方式更新日志。它对于提供 fencing 令牌的锁服务也很有用。</p><h4 id="采用全序关系广播实现线性化存储"><a href="#采用全序关系广播实现线性化存储" class="headerlink" title="采用全序关系广播实现线性化存储"></a>采用全序关系广播实现线性化存储</h4><p>虽然在一个可线性化的系统中有全序操作集合，但并不是可线性化与全序关系广播相同。</p><p>全序广播是异步的：消息被保证以固定的顺序可靠地传送，但是不能保证消息<strong>何时</strong>被送达（所以一个接收者可能落后于其他接收者）。而可线性化则强调就近性：读取时保证能够看到最新的写入值。</p><p>如果有全序关系广播，就可以构建一个线性化的存储系统，如确保用户名唯一标识一个用户。</p><p>设置用户名时如果使用 cas 的方式，则可以通过全序关系广播以追加日志的方式来实现：</p><ol><li>在日志中追加一条消息，试探性地指明你要声明的用户名。</li><li>读日志，广播到所有节点，并等待回复。</li><li>检查是否有任何消息声称用户名以及被占用。如果这些消息中的第一条就你自己的消息，那么你就成功了：你可以提交并向客户端确认。如果所需用户名的第一条消息来自其他用户，则中止操作。</li></ol><p>这样虽然保证线性化写入，但无法确保线性化读取，异步日志更新时，可能读到旧值。它弱于线性化保证，这里只有顺序一致性，也叫时间线一致性。为了同时满足线性化读取，有几个方案：</p><ul><li>可以采用追加的方式把读请求排序、广播，然后各个节点获取该日志，本节点收到消息才真正执行读操作。消息在日志中的位置因此定义了读取发生的时间点。 </li><li>如果日志允许以线性一致的方式获取最新日志消息的位置，则可以查询该位置，等待直到该位置前的所有消息都传达到你，然后执行读取。 （这是Zookeeper <code>sync()</code> 操作背后的思想）。</li><li>你可以从同步更新的副本中进行读取，因此可以确保结果是最新的。</li></ul><h4 id="采用线性化存储实现全序关系广播"><a href="#采用线性化存储实现全序关系广播" class="headerlink" title="采用线性化存储实现全序关系广播"></a>采用线性化存储实现全序关系广播</h4><p>假设有一个线性化的寄存器储存一个计数，然后支持原子递增和原子 cas 操作。</p><p>每个要通过全序广播发送的消息首先对线性一致寄存器执行<strong>自增并返回</strong>操作。然后将从寄存器获得的值作为序列号附加到消息中。然后你可以将消息发送到所有节点（重新发送任何丢失的消息），而收件人将按序列号发送回复消息。</p><p>与 Lamport 时间戳不同，通过递增线性化寄存器获取的数字没有任何间隙，如果完成了消息 4 的发送，之间接受到 6 的消息，那就必须等待 5。</p><p>线性化的 cas 或自增寄存器与全序关系广播都等价于共识问题。也就是如果能解决其中一个问题，就可以把方案用于解决其他问题。</p><h2 id="分布式事务与共识"><a href="#分布式事务与共识" class="headerlink" title="分布式事务与共识"></a>分布式事务与共识</h2><p>共识问题是分布式计算中最重要也是最基本的问题之一。有很多场景需要集群节点达成某种一致，如：</p><ul><li><p>主节点选举</p><p>主从复制的数据库，选举主节点时，由于网络问题出现节点无法通信，就很容易出现争议。此时共识对于避免错误的故障切换很重要，后者会导致脑裂。</p></li><li><p>原子事务提交</p><p>对于跨节点或分区事务的数据库，会面临这样的问题：某个事务可能在一些节点上执行成功，但在其他节点上却不幸失败。但原子性要求在所有节点对事务结果达成一致，要么全部成功提交，要么回滚。</p></li></ul><blockquote><h3 id="共识的不可能性"><a href="#共识的不可能性" class="headerlink" title="共识的不可能性"></a>共识的不可能性</h3><p>FLP结论，作者Fischer，Lynch和Paterson。FLP表明如果节点存在可能崩溃的风险，则不存在总是能够达到共识的稳定算法。在分布式系统中，我们必须假设节点可能会崩溃，所以可靠的共识是不可能的。FLP结论在<strong>异步系统模型</strong>中得到了证明，这是一种限制性很强的模型，它假定确定性算法不能使用任何时钟或超时。如果允许算法使用<strong>超时</strong>或其他方法来识别可疑的崩溃节点（即使怀疑有时是错误的），则共识变为一个可解的问题。即使仅仅允许算法使用随机数，也足以绕过这个不可能的结果。</p></blockquote><h3 id="原子提交和两阶段提交"><a href="#原子提交和两阶段提交" class="headerlink" title="原子提交和两阶段提交"></a>原子提交和两阶段提交</h3><p>原子性可以防止失败的事务破坏系统。这对多对象事务和维护二级索引格外重要。原子性可以保证二级索引与主数据总是保持一致。</p><h4 id="从单节点到分布式的原子提交"><a href="#从单节点到分布式的原子提交" class="headerlink" title="从单节点到分布式的原子提交"></a>从单节点到分布式的原子提交</h4><p>单节点执行的事务一般由存储引擎负责。事务提交或中止的关键点在于磁盘完成日志记录的时刻：完成日志记录写之前如果发生崩溃，事务中止；日志写入完成后崩溃也会被安全提交。这是单节点原子提交的核心思路。</p><p>但在多节点数据库中的事务就复杂起来，可能在提交的时候部分节点网络超时，违反约束或有冲突，或发生崩溃，都会违反原子性保证。</p><p>如果部分节点提交事务，其他节点放弃事务就会变得不一致。某个节点一旦提交了事务，即使事后发现其他节点发生中止，它也无法撤销。所以如果部分节点提交事务，则所有节点都必须提交。</p><h4 id="两阶段提交"><a href="#两阶段提交" class="headerlink" title="两阶段提交"></a>两阶段提交</h4><p>两阶段提交（ two-phase commit, 2PC ）是一种在多节点之间实现事务原子提交的算法，用来确保所有节点要么全部提交，要么全部中止。是分布式数据库中经典算法之一。</p><p>2PC 中的提交/中止过程分为两个阶段：</p><p><img src="https://raw.githubusercontent.com/zzugzj/blogImg/master/img/fig9-9.png" loading="lazy"></p><blockquote><h4 id="2PC-和-2PL"><a href="#2PC-和-2PL" class="headerlink" title="2PC 和 2PL"></a>2PC 和 2PL</h4><p>两阶段提交和两阶段加锁是不同的事情。2PC 在分布式数据库中负责原子提交，而 2PL 则提供串行化的隔离。这是两个概念。</p></blockquote><p>2PC 引入了单节点事务中没有的一个新组件：协调者（事务管理器）。协调者通常实现为共享库，在请求事务的进程中，也可能是单独进程或服务。比如 Naraytana，JOTM。</p><p>2PC 的过程：当应用准备提交事务时，协调者开始执行阶段1：发送一个准备请求到所有节点，询问是否提交。然后跟踪参与者的回应：</p><ul><li>如果所有参与者回答 “是”，表示他们准备好提交，协调者就会在阶段2发出提交请求，然后开始实际执行。</li><li>如果任何参与者回答 “否”，则协调者在阶段2向所有节点发出放弃请求。</li></ul><h4 id="系统的承诺"><a href="#系统的承诺" class="headerlink" title="系统的承诺"></a>系统的承诺</h4><p><strong>2PC 的工作原理</strong>：</p><ol><li>应用启动分布式事务时，先向协调者请求事务 ID。该 ID 全局唯一。</li><li>应用在每个参与节点上执行单节点事务，并将全局事务 ID 附加到事务上。此时读写都在单节点内完成。这个阶段出问题，协调者和其他参与者都可以安全中止。</li><li>应用准备提交时，协调者向所有参与者发送准备请求，并附带全局事务 ID。准备请求有任何失败或超时，协调者会通知参与者放弃事务。</li><li>参与者收到准备请求后，确保任何情况下都可以提交事务，并检查是否有冲突或违背约束。一旦向协调者回答 “是” ，节点就会承诺提交事务。</li><li>协调者收到所有准备请求的答复时，就会做出决定。协调者把最后的决定写入到磁盘的事务日志中，防止稍后日志崩溃，可以恢复之前的决定。这个时刻叫提交点。</li><li>协调者把决定写入磁盘后，向所有参与者发送提交或放弃请求。如果请求出现失败或超时，协调者必须一直重试直到成功。即使参与者此时发生崩溃或任何问题，在恢复后，也必须继续执行。</li></ol><p>该协议有两个关键点：首先参与者投票 “是” 时，它做出了肯定提交的承诺。其次，协调者做出了提交或放弃的决定，这个决定不可撤销。正是这两个承诺保证了 2PC 的原子性。</p><h4 id="协调者发生故障"><a href="#协调者发生故障" class="headerlink" title="协调者发生故障"></a>协调者发生故障</h4><p>如果参与者或网络在 2PC 期间发生失败，如果在第一阶段，协调者就会中止交易；第二阶段请求失败，协调者将无限期重试。但如果协调者发生故障，接下来发生什么现在还不太清楚。</p><p>如下图，协调者在发送给数据库 2 后崩溃，数据库 1 就不知道该提交还是中止，没有协调者的消息，参与者无法直到下一步的行动。</p><p><img src="https://raw.githubusercontent.com/zzugzj/blogImg/master/img/fig9-10.png" loading="lazy"></p><p>2PC 能够顺利完成的唯一方法就是等待协调者的恢复。这就是协调者向参与者发送请求前将决定写入磁盘的事务日志的原因：协调者恢复后，通过读取其事务日志来确定所有未决事务的状态。任何在协调者日志中没有提交记录的事务都会中止。此时，2PC 的提交点现在归结为协调者在常规单节点上的原子提交。</p><h4 id="三阶段提交"><a href="#三阶段提交" class="headerlink" title="三阶段提交"></a>三阶段提交</h4><p>两阶段提交也叫阻塞式原子提交协议，因为 2PC 可能在等待协调者恢复时卡住。</p><p>作为 2PC 的替代方案，目前也有三阶段提交算法。然而，3PC 假定一个有界的网络延迟和阶段在规定时间内响应。考虑到大多数无线网络延迟和进程暂停，它无法保证原子性。所以大家普遍使用 2PC。</p><h3 id="实践中的分布式事务"><a href="#实践中的分布式事务" class="headerlink" title="实践中的分布式事务"></a>实践中的分布式事务</h3><p>两阶段提交虽然有较高的安全性保证，但也有操作的缺陷、性能的问题、承诺不可靠而遭受诟病。很多云服务厂商由于运维方面的问题不支持分布式事务。有报告称MySQL的分布式事务比单节点慢10倍以上。性能下降主要是网络开销和磁盘IO。</p><p>但我们不应该直接忽视分布式事务，而应当更加仔细地审视这些事务，因为从中可以汲取重要的经验教训。首先，我们应该精确地说明“<strong>分布式事务</strong>”的含义。两种截然不同的分布式事务类型经常被混淆：</p><ul><li><p>数据库内部的分布式事务</p><p>一些分布式数据库支持数据库节点间的内部事务。如 MySQL Cluster 的 NDB 存储引擎。这种情况下，所有参与事务的节点都运行相同的数据库软件。</p></li><li><p>异构分布式事务</p><p>在异构分布式事务中，存在两种或两种以上不同参与者实现技术。例如来自不同供应商的数据库，甚至非数据库系统（中间件）。跨系统的分布式事务也必须确保原子提交。</p></li></ul><p>数据库内部的分布式事务往往可行且工作不错，但异构环境的事务则充满挑战。</p><h4 id="Exactly-once-消息处理"><a href="#Exactly-once-消息处理" class="headerlink" title="Exactly-once 消息处理"></a>Exactly-once 消息处理</h4><p>异构的分布式事务旨在无缝集成多种不同的系统。例如：当且仅当数据库中处理消息的事务成功提交，消息队列才会标记该消息已处理完毕。这个过程是通过自动提交消息确认和数据库写入来实现的。数据库和消息队列在两个节点，采用分布式事务也能达成。</p><p>如果消息发送或数据库事务任何一个发生失败，两者必须中止，消息队列可以稍后再次重传消息。因此，通过自动提交消息和消息处理的结果，可以确保消息可以有效处理有且仅有一次。</p><h4 id="XA-交易"><a href="#XA-交易" class="headerlink" title="XA 交易"></a>XA 交易</h4><p>X/Open XA（扩展架构，eXtended Architecture）是异构环境下实施两阶段提交的异构工业标准，1991年推出。目前，许多数据库（PostgreSQL、MySQL、Oracle、SQL Server）和消息队列都支持 XA。</p><p>XA 不是异构网络协议，而是一个与事务协调者进行通信的C API。但也支持其他语言的 API 绑定。Java 中，XA 事务是使用<strong>Java事务API（JTA, Java Transaction API）</strong>实现的，而许多使用<strong>JDBC（Java Database Connectivity）</strong>的数据库驱动，以及许多使用<strong>Java消息服务（JMS）</strong>API的消息代理都支持<strong>Java事务API（JTA）</strong>。</p><p>XA 假定应用通过网络或客户端的库函数与参与者节点进行通信。如果驱动支持 XA，就可以调用 API 来确定操作是否是异构分布式事务的一部分。</p><p>事务协调者需要实现 XA API，这些 API 会跟踪事务中的所有参与者，协调节点进行准备（通过回调）工作，然后负责收集参与者的投票，并在本地磁盘的日志文件里记录事务最终的决定。</p><h4 id="停顿时仍持有锁"><a href="#停顿时仍持有锁" class="headerlink" title="停顿时仍持有锁"></a>停顿时仍持有锁</h4><p>为什么我们非常关注陷入停顿的参与者节点？（即不确定该提交还是中止）因为数据库事务通常持有待修改行的行级独占锁，防止脏写。事务结束前，数据库不会释放这些锁。所以就会阻塞很多其他事务，导致上层应用基本处于不可用的状态。所以必须解决这些停顿状态的节点。</p><h4 id="从协调者故障中恢复"><a href="#从协调者故障中恢复" class="headerlink" title="从协调者故障中恢复"></a>从协调者故障中恢复</h4><p>协调者崩溃后重新启动，应该可以从日志恢复那些停顿的事务。但在实践中，孤立的不确定事务确实会发生。比如软件 bug 导致交易日志丢失或损坏，最终协调者还是恢复失败。悬而未决的事务就会留在那里，还阻塞其他事务。</p><p>这种情况只能让管理员手动决定是执行提交还是回滚。管理员必须仔细检查每个有问题的参与者，确定是否有节点已经事实完成提交或中止。</p><p>许多 XA 实现都支持某种紧急避险措施称之为启发式决策：这样参与者节点可以在紧急情况下单方面做出决定，放弃或继续那些停顿的事务，不需要协调者的指令。这里的启发式是可能破坏原子性的委婉说法。只能应急。</p><h4 id="分布式事务的限制"><a href="#分布式事务的限制" class="headerlink" title="分布式事务的限制"></a>分布式事务的限制</h4><p>XA 事务解决了多个参与者之间如何达到一致的问题，但也引入了不少操作方面的限制。特别是，核心的事务协调者本身就是一种数据库（存储事务的投票结果），因此需要和其他重要的数据库一样格外消息：</p><ul><li>如果协调者不支持数据复制，而是单节点运行，那么它就是整个系统的单点故障。现实情况是许多协调者默认情况下并非高可用，或者只支持最基本的复制。</li><li>许多应用都倾向于无状态，所有持久状态都保存在数据库中，这样服务器可以轻松添加或删除实例。但协调者就是服务器的一部分时，部署方式就改变了。协调者日志称为可靠系统的重要组成部分，要求和数据库本身一样重要。应用服务器不再无状态。</li><li>由于 XA 需要与各种数据库系统保存兼容，最终可以是多系统可兼容的最低标准。例如它无法深入检测不同系统之间的死锁条件，不适用 SSI，后者要求一个复杂协议来识别不同系统的写冲突。</li><li>数据库内部的分布式事务（不是 XA），限制则少很多，SSI 的分布式版本是可行的。但 2PC 要成功提交事务还是存在潜在的限制，要求所有参与者都投票赞成。所以分布式事务有扩大事务失败的风险，与构建容错系统的目标有些背道而驰。</li></ul><h3 id="支持容错的共识"><a href="#支持容错的共识" class="headerlink" title="支持容错的共识"></a>支持容错的共识</h3><p>共识就是让几个节点就某项协议达成一致。共识问题通常如此描述：一个或多个节点可以提议某些值，由共识算法来决定最终值。</p><p>共识算法必须满足以下性质：</p><ul><li>协商一致性：所有的节点都接受相同协议。</li><li>诚实性：所有节点不能反悔，即对一项提议不能有两次决定。</li><li>合法性：如果决定了值 v，则 v 一定是由某个节点所提议的。</li><li>可终止性：由所有未崩溃的节点来决定最终值。</li></ul><p>协商一致性和诚实性属性定义了共识的核心思想：决定一致的结果，一旦决定，就不能改变。合法性主要是为了排除一些无意义的方案：比如，无论什么建议，都可以有一个总是为空的决定，虽然可以满足一致性和诚实性，但没有实际效果。</p><p>可终止性引入了容错的思想。它强调了一个共识算法不能原地空转，必须取得进展。即使某些节点故障，其他节点也能做出决定。可终止性属于一种活性，其他三种属于安全性方面的属性。</p><p>共识算法需要保证大部分节点都正确运行才能确保终止性。这个多数就可以安全地构成 quorum。所以，可终止性的前提就是发生故障或不可用的节点数必须小于半数节点。</p><p>大多数共识算法都假定系统不存在拜占庭式错误。</p><h4 id="共识算法与全序广播"><a href="#共识算法与全序广播" class="headerlink" title="共识算法与全序广播"></a>共识算法与全序广播</h4><p>最著名的容错式共识算法包括 VSR， Paxos， Raft 和 Zab。这些算法大部分其实不是直接使用上述的形式化模型（提议并决定某个值，并满足上面 4 个属性）。相反，他们是决定了一系列值，然后采用全序关系广播算法。</p><p>全序关系广播的要点是：消息按相同的顺序发送到所有节点，有且只有一次。这其实相当于进行了多轮的共识过程：每一轮，节点提出他们接下来要发送的消息，然后决定下一个消息的全局顺序。</p><p>全序关系广播相当于持续的多轮共识（每一轮共识决定对应于一条消息）：</p><ul><li>由于协商一致性，所有节点决定以相同的顺序发送相同的消息。</li><li>由于诚实性，消息不能重复。</li><li>由于合法性，消息不会被破坏，也不是凭空捏造的。</li><li>由于可终止性，消息不会丢失。</li></ul><p>VSR， Raft 和 Zab 都直接采用了全序关系广播，这比重复性的一轮共识只解决一个提议更加高效。而 Paxos 有对应的优化版本 Multi-Paxos。</p><h4 id="主从复制与共识"><a href="#主从复制与共识" class="headerlink" title="主从复制与共识"></a>主从复制与共识</h4><p>在主从复制中，如果主节点是由运营人员手动选择和配置的，那就是只允许一个节点接受写入，如果该节点发生故障，系统将无法写入，直到操作人员再手动配置新的节点成为主节点。它需要人为干预才能取得进展，不满足共识的可终止性。</p><p>一些数据库支持自动选举主节点和故障切换，通过选举吧某个从节点提升为新的主节点。这样更容易接近容错式全序关系广播，从而达成共识。</p><p>所有的节点都需要同意主节点，否则就会脑裂。所以需要共识算法选出一位主节点。但这里的共识算法实际上是全序关系广播，全序关系广播很像主从复制，主从复制现在又需要选举主节点。</p><h4 id="Epoch和Quorum"><a href="#Epoch和Quorum" class="headerlink" title="Epoch和Quorum"></a>Epoch和Quorum</h4><p>目前所讨论的共识协议都在其内部使用了某种形式的主节点，虽然主节点不是固定的。他们都采用了一种弱化的保证：协议定义了一个世代编号（epoch number，比如 Paxos 的 ballot number，VSP 的 view number，Raft 的 term number），保证在每个世代里，主节点是唯一确定的。</p><p>如果主节点失效，则节点开始投票选新的主节点。选举会赋予一个单调递增的 epoch 号。如果出现两个不同的主节点对应不同的 epoch 号，则具有更高 epoch 号的主节点获胜。</p><p>主节点做出任何决定前，都需要检查是否存在比他更高的 epoch 号，通过投票的方式来检查。从 quorum 节点中收集投票，等待 quorum 节点的响应。 quorum 节点通常由多数节点构成，只有没发现更高的 epoch 主节点时，节点才会对当前提议投票。</p><p>所以，实际上存在两轮投票：首先投票决定主节点，然后是对主节点的提议投票。关键的一点是，两轮的 quorum 必须有重叠。</p><h4 id="共识的局限性"><a href="#共识的局限性" class="headerlink" title="共识的局限性"></a>共识的局限性</h4><p>共识算法对于分布式系统来说是一个巨大的突破：它为其他充满不确定性的系统带来了基础的安全属性（一致性，完整性和有效性），然而它们还能保持容错（只要多数节点正常工作且可达，就能取得进展）。它们提供了全序广播，因此它们也可以以一种容错的方式实现线性一致的原子操作。</p><p>但好处都是有代价的：</p><ul><li><p>达成一致性前，节点投票是一个同步复制的过程。</p></li><li><p>共识体系需要严格的多数节点才能运行。</p></li><li><p>多数共识算法假定一组固定参与投票的节点集，不能动态添加或删除节点。</p></li><li><p>共识系统依靠超时机制检测节点失效，在网络延迟高度不确定的环境中，经常会误判。</p></li><li><p>有时共识算法对网络问题特别敏感。例如Raft已被证明存在不合理的边界条件处理：如果整个网络工作正常，但只有一条特定的网络连接一直不可靠，Raft可能会在两个节点间反复切换主节点。其他一致性算法也存在类似的问题，而设计能健壮应对不可靠网络的算法仍然是一个开放的研究问题。</p></li></ul><h3 id="成员与协调服务"><a href="#成员与协调服务" class="headerlink" title="成员与协调服务"></a>成员与协调服务</h3><p>zookeeper 和 etcd 主要针对少量，可完全载入内存的数据而设计，通常采用容错的全序广播算法在所有节点复制这些数据从而实现高可靠。全序关系广播主要用来实现数据库复制：每条消息代表数据库写请求，然后按相同顺序在多个节点应用写操作，达到多副本一致性。</p><p>zookeeper 的一些特性：</p><ul><li>线性化的原子操作：使用原子 cas 操作，可以实现加锁服务。</li><li>操作全序：zookeeper 在实现此功能时，采用了对所有操作执行全局排序，然后为每个操作都赋予一个单调递增的事务 ID 和版本号。</li><li>故障检测：客户端在ZooKeeper服务器上维护一个长期会话，客户端和服务器周期性地交换心跳包来检查节点是否还活着。即使连接暂时中断，或者ZooKeeper节点失效，会话仍保持在活跃状态。但如果心跳停止的持续时间超出会话超时，ZooKeeper会宣告该会话已死亡。当会话超时，会话持有的任何锁都可以配置为自动释放。</li><li>更改通知：客户端不仅可以读取其他客户端创建的锁和值，还可以监听它们的变更。因此，客户端可以知道另一个客户端何时加入集群（基于新客户端写入ZooKeeper的值），或发生故障（因其会话超时，而其临时节点消失）。通过订阅通知，客户端不用再通过频繁轮询的方式来找出变更。</li></ul><p>上面几个，只有线性化的原子操作需要共识。</p><h4 id="节点任务分配"><a href="#节点任务分配" class="headerlink" title="节点任务分配"></a>节点任务分配</h4><p>zookeeper 非常适合系统有多个流程或服务的实例。另外对一些分区资源的分配，当有新节点加入集群时，需要将某些现有分区从当前节点迁移到新节点，从而实现负载均衡。</p><p>应用可能在数千个节点运行，这样进行投票效率比较低，zookeeper 可以控制在固定数量节点（3-5个）投票，高效支持大量客户端。</p><h4 id="服务发现"><a href="#服务发现" class="headerlink" title="服务发现"></a>服务发现</h4><p>zookeeper 经常用于服务发现，比如需要某个服务，要连哪个 ip 等。云环境中，虚拟机会起起停停，这种动态的变化让节点无法提前知道服务节点的 IP，所以可以让节点启动时在 zookeeper 注册，其他人想 zookeeper 注册表询问。</p><h4 id="成员服务"><a href="#成员服务" class="headerlink" title="成员服务"></a>成员服务</h4><p>成员服务用来确定哪些节点当前处于活动状态并且是群集的活动成员。由于无限的网络延迟，无法可靠地检测到另一个节点是否发生故障。但是，如果你通过一致的方式进行故障检测，那么节点可以就哪些节点应该被认为是存在或不存在达成一致。</p><p>即使它确实存在，仍然可能发生一个节点被共识错误地宣告死亡。但是对于一个系统来说，就成员资格的问题的决定是全体一致的，这是最重要的。</p>]]></content>
    
    
    <summary type="html">分布式系统利用多个节点的硬件资源，完成了本可以在单点系统上实现的任务。从用户的角度看，分布式系统就好像一个单独的计算机一样，只不过拥有更好的性能和稳定性，同时又易于扩展。为了达到这一目的，同样的一份数据会以副本（Replication）的形式保存在多个节点上。</summary>
    
    
    
    <category term="分布式" scheme="https://zzugzj.github.io/categories/%E5%88%86%E5%B8%83%E5%BC%8F/"/>
    
    
    <category term="分布式" scheme="https://zzugzj.github.io/tags/%E5%88%86%E5%B8%83%E5%BC%8F/"/>
    
    <category term="数据库" scheme="https://zzugzj.github.io/tags/%E6%95%B0%E6%8D%AE%E5%BA%93/"/>
    
  </entry>
  
  <entry>
    <title>分布式系统的挑战</title>
    <link href="https://zzugzj.github.io/posts/165ca954/"/>
    <id>https://zzugzj.github.io/posts/165ca954/</id>
    <published>2021-08-17T13:53:37.951Z</published>
    <updated>2023-11-05T05:53:21.323Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>这是对分布式系统中的一个全面的、近乎悲观的总结。故障可能来源于网络问题，时钟与时序问题。</p><h2 id="故障与部分失效"><a href="#故障与部分失效" class="headerlink" title="故障与部分失效"></a>故障与部分失效</h2><p>我们期望的情况是要不功能正常，要不完全失效，不会介于这两者之间。因此我们宁可让计算机崩溃，也不能返回一个错误的结果。</p><p>但这种情况在涉及多个节点时，理想化的标准正确模型就很难再适用。可能系统的一部分正常工作，一部分出现难以预料的故障，称之为部分失效。</p><h3 id="不可靠的网络"><a href="#不可靠的网络" class="headerlink" title="不可靠的网络"></a>不可靠的网络</h3><p>互联网以及大多数数据中心的内部网络（通常是以太网）都是异步网络。一个节点发消息到另一个节点，但网络不能保证它什么时候到达。而且在这个过程中，很多事情可能出错：</p><ol><li>请求可能已经丢失（可能有人拔掉了网线）。</li><li>请求可能正在排队，稍后将交付（也许网络或接收方超载）。</li><li>远程节点可能已经失效（可能是崩溃或关机）。</li><li>远程节点可能暂时停止了响应（可能会遇到长时间的垃圾回收暂停）。</li><li>远程节点可能已经处理了请求，但是网络上的响应已经丢失（可能是网络交换机配置错误）。</li><li>远程节点可能已经处理了请求，但是响应已经被延迟，并且稍后将被传递（可能是网络或者发送方过载）。</li></ol><p>处理这个问题通常是超时机制：等待一段时间后，如果仍然没有收到恢复则选择放弃，并且认为响应不会到达。但即使判定超时，仍然不知道远程节点是否收到了请求。</p><h3 id="检测故障"><a href="#检测故障" class="headerlink" title="检测故障"></a>检测故障</h3><p>许多系统需要自动检测故障节点。例如：</p><ul><li>负载均衡器需要停止向已死亡的节点转发请求（即下线处理）。</li><li>在单主复制功能的分布式数据库中，如果主库失效，则需要将从库之一升级为新主库，但是由于网络的不确定性很难准确判断节点是否确实失效。</li></ul><ul><li>节点在处理请求时崩溃，很难直到处理了多少数据。</li><li>如果服务进程崩溃，但操作系统正常，可以通过脚本通知其他节点。以便新节点快速接管而跳过等待超时。HBase采用这个。</li></ul><p>相反，如果出了什么问题，你可能会在堆栈的某个层次上得到一个错误响应，但总的来说，你必须假设你根本就没有得到任何回应。您可以重试几次（TCP重试是透明的，但是您也可以在应用程序级别重试），等待超时过期，并且如果在超时时间内没有收到响应，则最终声明节点已经死亡。</p><h3 id="超时与无期限的延迟"><a href="#超时与无期限的延迟" class="headerlink" title="超时与无期限的延迟"></a>超时与无期限的延迟</h3><p>超时时间的设置很难，时间长的超时值意味着更长时间的等待，在此期间用户会收到异常信息。较短的超时时间可能会出现误判，比如出现网络波动。</p><p>如果节点实际上活着，过早声明为失效，新节点尝试接管，则可能操作在两个节点执行两次。</p><p>节点被宣告失效，承担的责任会移交给其他节点，如果系统已经处于高负荷状态，节点因为负载过高而出现响应缓慢，转移负载到其他节点可能会导致失效扩散。</p><p>如果一个网络延迟控制在时间d内，要不完成交付，要不丢失，非故障节点在时间r内完成处理，那么成功请求在2d+r内收到响应，那么2d+r是一个理想的超时设置。</p><p>但绝大多数系统没有类似的保证：异步网络理论上延迟无限大，多数服务端无法保证给定的某个时间内一定完成处理请求。</p><h4 id="网络拥塞和排队"><a href="#网络拥塞和排队" class="headerlink" title="网络拥塞和排队"></a>网络拥塞和排队</h4><ul><li>当多个不同节点同时发送数据包到相同节点时，网络交换机会排队，依次发送数据库包到目标网络。如果网络负担重，可能需要等一会，如果交换机队列塞满，则数据包可能被丢弃，引发大量重传。</li><li>数据包到达目标机器后，如果cpu繁忙，请求被操作系统排队，直到程序处理。</li><li>虚拟化环境中，cpu会切换虚拟机，导致操作系统会突然暂停几十毫秒。这段时间，客户虚拟机无法从网络接受任何数据。</li><li>TCP执行流量控制时，节点会主动限制自己的发送速率以避免加大网络负载。意味着在发送方排队。</li></ul><p><img src="https://raw.githubusercontent.com/zzugzj/blogImg/master/img/fig8-2.png" loading="lazy"></p><p>以上因素会导致网络延迟的变化。当系统有足够处理能力，排队会被处理，但接近系统最大涉及上限时，排队对延迟的影响就变得明显。</p><p>更好的办法是，超时设置并不是一个不变的常量，而是持续测量响应时间及其变化，然后根据最新的响应时间分布来自动调整。这可以通过Phi Accrual故障检测器来完成，该检测器在例如Akka和Cassandra中使用。 TCP超时重传机制也同样起作用。</p><h3 id="同步与异步网络"><a href="#同步与异步网络" class="headerlink" title="同步与异步网络"></a>同步与异步网络</h3><p>传统的固话网络是同步的，语音延迟和掉话现象极为罕见。在电话拨通时，系统会动态的建立一条电路：在整个线路上为呼叫分配一个固定的，带宽有保证的通信链路，一直到通信结束。即使数据中间经过多个路由器，16bit空间在电路建立时已经在网络中保留，不会受到排队影响。没有排队，端到端延迟是固定的，称为有界延迟。</p><h3 id="不可靠的时钟"><a href="#不可靠的时钟" class="headerlink" title="不可靠的时钟"></a>不可靠的时钟</h3><p>网络上的每台机器都有自己的时钟硬件设备，通常是石英晶体震荡器。这些设备不是绝对精确的，每台机器都维护自己本地的时间副本，可能比其他机器稍快或更慢。可以在一定程度上同步时钟：最常用的机制是<strong>网络时间协议（NTP）</strong>，它可以根据一组专门的时间服务器来调整本地时间。时间服务器则从精确度更高的时间源（如GPS接收机）获取高精度时间。</p><h3 id="单调时钟与墙上时钟"><a href="#单调时钟与墙上时钟" class="headerlink" title="单调时钟与墙上时钟"></a>单调时钟与墙上时钟</h3><p>现代计算机内部至少有两种不同的时钟：一个是墙上时钟（钟表时间），一个是单调时钟。</p><h4 id="墙上时钟"><a href="#墙上时钟" class="headerlink" title="墙上时钟"></a>墙上时钟</h4><p>根据某个日历来返回当前的日期与时间。比如Linux的<code>clock_gettime(CLOCK_REALTIME)</code>和Java中的<code>System.currentTimeMillis()</code>返回自epoch以来的秒数（或毫秒），根据公历日历，不包括闰秒。有些系统使用其他日期作为参考点。</p><p>墙上时钟可以与NTP同步。</p><h4 id="单调时钟"><a href="#单调时钟" class="headerlink" title="单调时钟"></a>单调时钟</h4><p>单调时钟更适合测量时间间隔。Linux上的<code>clock_gettime(CLOCK_MONOTONIC)</code>，和Java中的<code>System.nanoTime()</code>都是单调时钟。单调时钟能保证他们总是向前。</p><p>单调时钟的绝对值没有任何意义，它可能是电脑启动以后经历的纳秒数或其他含义。比较不同节点的单调时钟值没有任何意义。</p><p>如果有多个cpu，每个cpu可能有单独的计时器，不与其他cpu同步。应用程序的线程可能在不同cpu上，操作系统会补偿多个计时器的偏差，从而为应用层提供统一的单调递增计时。</p><p>在分布式系统中，可以采用单调时钟测量一段任务的持续时间，它不假定节点间有任何的时钟同步，且可以容忍轻微的测量误差。</p><h3 id="时钟同步与准确性"><a href="#时钟同步与准确性" class="headerlink" title="时钟同步与准确性"></a>时钟同步与准确性</h3><p>单调时钟不需要同步，墙上时钟需要根据NTP服务器或其他时间源来同步。</p><p>但计算机的石英钟不够精确，存在漂移现象。时钟漂移主要取决于机器的温度。如果时钟与NTP服务器差别太大，可能出现拒绝同步，或本地时钟将被强制同步。同步过程也会受网络影响。</p><p>另外闰秒也会产生一分钟为59秒或61秒的现象，这会使一些对闰秒无防范的系统出现混乱。处理闰秒的推荐方案是在NTP服务器汇报时间时故意做些调整，目的是在一天的周期内逐步调整闰秒。</p><p>虚拟机中，当虚拟机共享一个cpu内核时，每个虚拟机会出现数十毫秒的暂停以切换虚拟机。应用角度看就会时钟向前发生了跳跃。</p><p>有的场景需要高精度的时钟，比如金融操作，需要在100微秒内同步时钟。采用GPS接收机，精确时间协议（PTP）。</p><h3 id="依赖同步的时钟"><a href="#依赖同步的时钟" class="headerlink" title="依赖同步的时钟"></a>依赖同步的时钟</h3><p>时钟问题是不容易及时发现的，如果需要精确同步的时钟，最好仔细监控所有节点的时钟偏差。如果某个节点的时钟漂移超出上限，应将其宣告为失败，从集群移除。这样确保在造成重大影响前尽早发现并处理问题。</p><h4 id="时间戳与事件顺序"><a href="#时间戳与事件顺序" class="headerlink" title="时间戳与事件顺序"></a>时间戳与事件顺序</h4><p>在多个节点对事件进行排序，如果它依赖时钟，就有一定的技术风险。</p><p><img src="https://raw.githubusercontent.com/zzugzj/blogImg/master/img/fig8-3.png" loading="lazy"></p><p>上图是在一个多领导者复制的数据库中，客户A写到节点1，节点1异步复制到2和3，客户B进行同样的操作，给x加一，但节点2收到两个事件时，会根据时间戳错误判断x=1是新的值，然后导致客户B的增量操作丢失。</p><p>这种冲突解决测量叫最后写入获胜（LWW），在多主和无主节点复制中广泛使用。LWW的根本问题是：</p><ul><li>数据库写入可能会神秘地消失：后续发生的写操作没法覆盖一个较早的值，因为后者节点时钟太快了，导致一些数据丢弃并且没有报告任何错误。</li><li>LWW无法区分<strong>高频顺序写入</strong>和<strong>真正并发写入</strong>（写操作不依赖其他写）。需要额外的因果关系跟踪机制（例如版本向量），以防止因果关系的冲突。</li><li>由于时钟精度的限制（比如毫秒级），两个节点可能独立产生了相同时间戳。为了解决这样的冲突，需要一个额外的仲裁值（可能是大的随机数），但无法区分因果关系。</li></ul><p>这种错误的顺序问题很难避免，除了石英漂移等误差来源，NTP同步精度也收到网络影响。</p><h4 id="时钟的置信区间"><a href="#时钟的置信区间" class="headerlink" title="时钟的置信区间"></a>时钟的置信区间</h4><p>墙上时钟或许会返回微秒甚至纳秒的信息，但这种精度的测量值是不可信的。因为随便一个误差就会高达几毫米甚至几十毫秒。</p><p>因此，我们将时钟读数视为一个带有置信区间的时间范围。比如系统有95%的置信度任务事件介于10.3-10.5之间，那么时间戳中那些微秒级的读数毫无意义。</p><p>但大多数系统不提供这种误差查询接口。当调用<code>clock_gettime()</code>的时候，返回值没有误差信息，不知道置信区间。</p><p>但谷歌的Spanner中的TrueTime API可以明确报告本地时钟的置信区间。查询时间时会返回两个值，【不早于，不晚于】。时间间隔范围主要取决于本地石英钟最后于高精时钟源同步后所经历的时间长短。</p><h4 id="全局快照的同步时钟"><a href="#全局快照的同步时钟" class="headerlink" title="全局快照的同步时钟"></a>全局快照的同步时钟</h4><p>快照隔离需要单调递增的事务ID，如果数据库分布在多台机器上，就需要一个全局单调递增的事务ID。事务ID要求必须反映因果关系：事务B如果要读取事务A写入的值，则B的事务ID必须大于A的事务ID，否则快照将不一致。如果有很多的小数据包，则分布式系统中创建事务ID会引入瓶颈。</p><p>如果能将墙上时钟进行同步，则用时间戳来衡量事务ID更方便。Google Spanner的True Time API，如果有两个置信区间，$A = [A_{earliest}, A_{latest}]$， $B=[B_{earliest}, B_{latest}]$， 这两个区间如果不重叠（即：$A_{earliest} &lt; A_{latest} &lt; B_{earliest} &lt; B_{latest}$），则B一定在A之后。为此，Google在每个数据中心部署了一个GPS接收器或原子钟，保证所有时间同步在约7ms内完成。</p><p>借助时钟同步来处理分布式事务语义处理Google意外，主流数据库还没有更多实现，但整个领域很活跃和有趣。</p><h3 id="进程暂停"><a href="#进程暂停" class="headerlink" title="进程暂停"></a>进程暂停</h3><p>关于主从复制中如何判断主节点存活，有这样一种思路：主节点从其他节点获取一个租约（类似带时间的锁），只有一个节点能获取租约，某节点获取租约后，要在超时前定期去续约。如果节点发生故障，则续约失败，其他节点接管。</p><p>这种方案，依赖同步的时钟，租约到期时间是另一个节点设置，但和本地时钟进行比较。如果时钟有几秒的差异，可能就会出现问题。</p><p>通常判断是否过期与请求处理间隔很短，但如果进程执行出现意外的暂停，那就会出问题。导致进程暂停的原因有很多：</p><ul><li>GC暂停，即使所谓的并发垃圾收集器也不能完全与应用代码并行运行。</li><li>虚拟化环境，可能暂停虚拟机（比如将内存状态保存到磁盘）然后继续。通常用于实时迁移，把虚拟机迁移到另一个主机但不用重启。</li><li>运行在终端设备（笔记本），可能由于用户关机或休眠而暂停。</li><li>执行线程上下文切换或在虚拟化环境进行虚拟机切换，如果负载很高，可能需要暂停一段时间。</li><li>同步磁盘IO</li><li>操作系统触发缺页中断，内存压力很大时，可能花大量时间在内存换入换出上（称为抖动）。通常在服务器禁止页面调度，宁愿干掉一个进程来释放内存，也不愿意冒抖动风险。</li><li>可以通过发送SIGSTOP信号来暂停Unix进程，例如通过在shell中按下Ctrl-Z。 这个信号立即阻止进程继续执行更多的CPU周期，直到SIGCONT恢复为止，此时它将继续运行。 即使你的环境通常不使用SIGSTOP，也可能由运维工程师意外发送。</li></ul><p>这些情况都可能抢占一个正在运行的线程，而且线程一无所知。分布式系统任何节点必须假定，执行中可能会暂停一段时间，暂停时集群其他部分照常运行。最终，暂停的节点可能会回来继续运行，除非再次检查时钟，否则它对刚刚的暂停毫无知觉。</p><h4 id="响应时间保证"><a href="#响应时间保证" class="headerlink" title="响应时间保证"></a>响应时间保证</h4><p>线程和进程虽然可能会暂停相当长的时间，但如果对系统进行一些配置，这些原因是可以消除的。</p><p>有些软件如果在指定时间内无法响应会造成相当严重后果，比如飞机上对输入传感器快速做出响应的组件等。对这种系统，软件必须有一个做出响应的上限，如果不满足，就会有系统级的故障。这就是所谓的<strong>硬实时（hard real-time）</strong>系统。</p><p>但实时系统往往有很多限制，比如编程语言等，往往吞吐率低，而且造价高昂。对大多数服务器并不适用。</p><h4 id="调整垃圾回收的影响"><a href="#调整垃圾回收的影响" class="headerlink" title="调整垃圾回收的影响"></a>调整垃圾回收的影响</h4><p>可能把GC暂停视为节点的一个计划内的临时离线，当节点启动垃圾回收时，通知其他节点来接管客户端请求。目前一些延迟敏感的系统（如金融交易系统）已经采用这种方法。</p><h2 id="知识、真相与谎言"><a href="#知识、真相与谎言" class="headerlink" title="知识、真相与谎言"></a>知识、真相与谎言</h2><p>分布式系统中，节点只能通过消息交换来获得其他节点当前的状态，如果远程节点没有响应，没法区分网络问题还是节点问题，就不知道节点处于什么状态。</p><h3 id="真相由多数决定"><a href="#真相由多数决定" class="headerlink" title="真相由多数决定"></a>真相由多数决定</h3><p>如果某个节点可以收到别的节点的消息，但发出去的消息要么丢弃，要么延迟发送。其他节点就会一致声明上述节点失效。比如可能垃圾收集运行很长时间。</p><p>节点不能根据自己的信息来判断自己的状态，由于节点可能随时失效或暂停-假死，因此分布式系统不能完全依赖某个节点。许多分布式算法都依靠法定票数，即节点间投票。</p><h4 id="主节点与锁"><a href="#主节点与锁" class="headerlink" title="主节点与锁"></a>主节点与锁</h4><p>有时，我们需要在系统范围内只能有一个实例：</p><ul><li>只允许一个节点作为分区主节点，防止脑裂。</li><li>只允许一个事务或客户端持有锁。</li><li>只允许一个用户来使用特定的用户名，从而确保用户名可以唯一标识用户。</li></ul><p>另外，一个节点即使自认为它是 ”唯一“ 的主节点，但不一定获得了系统法定票数同意。它可能以前是主节点，但其他节点已经宣布它失效并选出另外的主节点。</p><p>比如下面的例子：</p><p><img src="https://raw.githubusercontent.com/zzugzj/blogImg/master/img/fig8-4.png" loading="lazy"></p><p>持有租约的客户端被暂停太久直到租约到期，另一个客户端获取租约，并写了文件，当暂停的客户端回来时，它仍错误的认为合法持有锁并尝试写文件，导致客户2的文件被破坏。</p><h4 id="fencing令牌"><a href="#fencing令牌" class="headerlink" title="fencing令牌"></a>fencing令牌</h4><p>假设每次锁服务在授予锁或租约时，还会同时返回一个 fencing 令牌，该令牌（数字）没授予一次就会递增。然后要求客户端每次向存储系统发送写请求时，都必须包含所持有的 fencing 令牌。</p><p><img src="https://raw.githubusercontent.com/zzugzj/blogImg/master/img/fig8-5.png" loading="lazy"></p><p>使用 ZooKeeper 作为锁服务时，可以用事务标识 zxid 或节点版本 cversion 来充当 fencing 令牌，这两个都可以满足单调递增要求。</p><p>这种令牌检查通常在服务端进行，虽然看起来复杂，但这可以防止一些客户端的滥用情况。</p><h3 id="拜占庭故障"><a href="#拜占庭故障" class="headerlink" title="拜占庭故障"></a>拜占庭故障</h3><p>fencing 令牌可以防止那些误操作，但节点试图破坏系统，发送消息时可以简单的伪造令牌。</p><p>之前的假设是节点不可靠，但一定是诚实的，但如果节点出现 ”撒谎“ 的情况，分布式难度就上升一个台阶。例如节点明明没收到某条消息，但对外声称它收到了，这就是拜占庭故障。在这样不信任的环境中需要达到共识的问题也叫拜占庭将军问题。</p><p>如果某个系统即使发生部分节点故障，甚至不遵从协议，故意攻击，干扰网络，仍可继续正常运行，我们称之为拜占庭式容错系统。比如：</p><ul><li>航天领域，内存或 CPU 寄存器中的数据可能会被辐射而发生故障，导致以不可预知的方式响应其他节点。</li><li>有多个参与者的系统中，某些参与者可能会作弊或欺骗他人。比如比特币和其他区块链一样的点对点网络就是让互不信任的当事方就某项交易达成一致，且不依赖于集中的机制。</li></ul><p>但在数据中心中，所有节点都由一个组织集中控制（可信任），辐射水平也可以忽略。绝大多数服务器端数据系统中，部署拜占庭容错解决方案基本不太可行。</p><p>软件的bug可以被认为是拜占庭故障，但如果将相同软件部署到所有节点，拜占庭式的容错算法也没办法解决问题。因为大多数容错算法要求系统超过三分之二的节点是功能正常的。</p><h4 id="弱的谎言形式"><a href="#弱的谎言形式" class="headerlink" title="弱的谎言形式"></a>弱的谎言形式</h4><p>就算假定节点是诚实的，但依然推荐增加必要的机制来防范一些不那么恶意的 ”谎言“。虽然不是完整的拜占庭容错，但简单实用，提高系统的可靠性和健壮性。比如由于硬件或操作系统等错误，导致网络数据包出现损坏，一些简单的防范措施就是在应用层添加校验和。另一个是需要对公众开放的应用检查用户是所有输入，比如检查输入值大小，字符串大小，防止分配超大内存。</p><h3 id="理论系统模型与现实"><a href="#理论系统模型与现实" class="headerlink" title="理论系统模型与现实"></a>理论系统模型与现实</h3><p>分布式系统的算法不能过分依赖特定的硬件和软件配置。这要求我们需要对预期的系统错误进行形式化描述。我们通过定义一些系统模型来形式化描述这些算法的前提条件。</p><p>关于时间方面，有三种常见的模型：</p><ul><li>同步模型：同步模型假定有上界的网络延迟，有上界的进程暂停和有上界的时钟误差。就是这些不会超过一个界限。大多数实际系统的实际模型并非同步模型，因为无限延迟和暂停确实可能发生。</li><li>部分同步模型：大多数情况下像一个同步系统一样运行，但有时候会超出网络延迟，进程在那头和时钟漂移的预期上界。这是个比较现实的模型。</li><li>异步模型：算法不会对时机做出任何假设，甚至里面根本没有时钟。某些算法支持异步模型，但并不常见。</li></ul><p>除了时间外，还要节点失效。这有三种最常见的节点失效系统模型：</p><ul><li>崩溃-中止模型：算法假设一个节点只能以一种方式发生故障，即遭遇系统崩溃。意味着节点可能在任何时候突然停止响应，且节点以后永远消失，无法恢复。</li><li>崩溃-恢复模型：节点可能在任何时候发生崩溃，但可能在一段时间后得到恢复并再次响应。节点上持久性存储的数据在崩溃中得以保存，但内存的状态可能丢失。</li><li>拜占庭失效模型：节点可能发生任何事情，包括试图作弊和欺骗其他节点。</li></ul><p>真是系统的建模，最普遍用的就是崩溃-恢复模型结合部分同步模型。</p><h4 id="算法的正确性"><a href="#算法的正确性" class="headerlink" title="算法的正确性"></a>算法的正确性</h4><p>为了定义算法是正确的，我们可以描述它的属性。例如，排序算法的输出具有如下特性：对于输出列表中的任何两个不同的元素，左边的元素比右边的元素小。这只是定义对列表进行排序含义的一种形式方式。</p><p>比如前面锁服务的 fencing 令牌算法，属性有：</p><ul><li>唯一性：两个令牌请求不能获得相同的值。</li><li>单调递增</li><li>可用性：请求令牌的节点不发生崩溃最终一定会收到响应。</li></ul><p>如果针对某个系统模型的算法在各种情况下都能满足定义好的属性要求，那么我们称这个算法是正确的。</p><h4 id="安全性和活性"><a href="#安全性和活性" class="headerlink" title="安全性和活性"></a>安全性和活性</h4><p>在上面令牌算法中，唯一性和单调递增就是安全性，可用性则属于活性。</p><p>安全性可以理解为 ”没有发生意外“，而活性则类似 ”预期的事情最终一定会发生“。</p><ul><li>如果违反了安全性，我们可以明确的指向发生的特定的时间点。且一旦违法安全属性，违规行为无法撤销，破坏已经发生。</li><li>活性则反过来，可能无法明确某个具体的时间点，但总是希望在未来某个时间点能满足要求。</li></ul><p>通常对于分布式算法，要求所有可能的系统模型下，都符合安全性。对于活性，则存在一些必要条件，比如只有在大多数节点没有崩溃的情况下，只有当网络最终从中断中恢复时，我们才可以说请求需要接收响应。</p>]]></content>
    
    
    <summary type="html">使用分布式系统与在一台计算机上编写软件有着根本的区别，主要的区别在于，有许多新颖和刺激的方法可以使事情出错。在这一章中，我们将了解实践中出现的问题，理解我们能够依赖，和不可以依赖的东西。</summary>
    
    
    
    <category term="分布式" scheme="https://zzugzj.github.io/categories/%E5%88%86%E5%B8%83%E5%BC%8F/"/>
    
    
    <category term="分布式" scheme="https://zzugzj.github.io/tags/%E5%88%86%E5%B8%83%E5%BC%8F/"/>
    
    <category term="数据库" scheme="https://zzugzj.github.io/tags/%E6%95%B0%E6%8D%AE%E5%BA%93/"/>
    
  </entry>
  
  <entry>
    <title>分布式系统-事务</title>
    <link href="https://zzugzj.github.io/posts/3e9da643/"/>
    <id>https://zzugzj.github.io/posts/3e9da643/</id>
    <published>2021-08-12T13:36:40.889Z</published>
    <updated>2023-11-05T05:53:39.909Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>在一个数据系统中，许多事情都可能出错，但是在一系列操作中，中间某个操作出错，这将会很麻烦，已经执行的需要回滚，代码层面完成很麻烦。所以<strong>事务</strong> 成为这些问题的首选机制。事务中的所有读写操作被视作单个操作来执行：整个事务要么成功（<strong>提交（commit）</strong>）要么失败（<strong>中止（abort）</strong>，<strong>回滚（rollback）</strong>）。</p><p> 本文将研究许多出错案例，并探索数据库用于防范这些问题的算法。尤其会深入<strong>并发控制</strong>的领域，讨论各种可能发生的竞争条件，以及数据库如何实现<strong>读已提交</strong>，<strong>快照隔离</strong>和<strong>可串行化</strong>等隔离级别。</p><h2 id="深入理解事务"><a href="#深入理解事务" class="headerlink" title="深入理解事务"></a>深入理解事务</h2><p>目前的几乎所有关系型数据库和一些非关系型数据库都支持事务。</p><h3 id="ACID的含义"><a href="#ACID的含义" class="headerlink" title="ACID的含义"></a>ACID的含义</h3><p>事务所提供的安全保证，通常由众所周知的首字母缩略词ACID来描述，ACID代表<strong>原子性（Atomicity）</strong>，<strong>一致性（Consistency）</strong>，<strong>隔离性（Isolation）</strong>和<strong>持久性（Durability）</strong>。</p><h4 id="原子性"><a href="#原子性" class="headerlink" title="原子性"></a>原子性</h4><p><strong>能够在错误时中止事务，丢弃该事务进行的所有写入变更的能力。</strong> 也就是一个操作只有两个状态，即只能处于操作之前或操作之后的状态，而不是介于两者之间的状态。</p><h4 id="一致性"><a href="#一致性" class="headerlink" title="一致性"></a>一致性</h4><p>ACID的一致性主要是指对数据有特定的预期状态，任何数据更改都要满足状态约束，比如一个账单系统，贷款和借款要保持平衡。</p><p>如果一个事务从一个有效的状态开始，中间没有违背约束，那最终结果依然是有效状态。</p><p>一致性本质上要求应用层来维护状态一致，它不是数据库可以保证的事情：即如果提供的数据修改违背了恒等条件，数据库也难以检测。</p><p>原子性、隔离性和持久性是数据库自身属性，而一致性更多取决于应用。C其实不应该属于ACID。</p><h4 id="隔离性"><a href="#隔离性" class="headerlink" title="隔离性"></a>隔离性</h4><p>在没有隔离性的情况下，两个客户端同时操作一个数据，可能结果是错的。ACID语义中的隔离性意味着并发执行是多个事务相互隔离。但由于性能，基本很少用串行化隔离，比如oracle使用的快照隔离，快照隔离比串行化更弱。</p><h4 id="持久性"><a href="#持久性" class="headerlink" title="持久性"></a>持久性</h4><p>一旦事务成功完成，即使发生硬件故障或数据库崩溃，写入的数据也不会丢失。</p><h3 id="单对象和多对象事务操作"><a href="#单对象和多对象事务操作" class="headerlink" title="单对象和多对象事务操作"></a>单对象和多对象事务操作</h3><p>多对象事务要求确定事务包含了那些读写操作。对于关系数据库，客户端通常与数据库服务器建立TCP网络连接，因而对于特定的某个连接，SQL语句<code>BEGIN TRANSACTION</code> 和 <code>COMMIT</code> 语句之间的所有操作都属于同一个事务。</p><p>由于数据库操作会出现很多问题，所以存储引擎一个几乎普遍的目标是：对单节点上的单个对象（例如键值对）上提供原子性和隔离性。</p><p>某些数据库还提供一些复杂的原子操作，例如自增操作，还有cas等。这些单对象操作很有用，因为它们可以防止在多个客户端尝试同时写入同一个对象时丢失更新。但它们不是通常意义上的事务。CAS以及其他单一对象操作被称为“轻量级事务”，但和事务有一定的区别，事务通常被理解为，<strong>将多个对象上的多个操作合并为一个执行单元的机制</strong>。</p><h4 id="多对象事务的必要性"><a href="#多对象事务的必要性" class="headerlink" title="多对象事务的必要性"></a>多对象事务的必要性</h4><p>许多分布式数据存储系统不支持多对象事务，主要是跨分区时，多对象事务难以正确实现，对高可用或极致性能的场景有影响。但并不是不可以实现。</p><p><strong>但是否有可能只用键值数据模型和单对象操作来实现任何应用程序？</strong></p><p>有一些场景中，单对象插入，更新和删除是足够的。但是许多其他场景需要协调写入几个不同的对象：</p><ul><li>关系数据模型中，表中的行有另外表的外键，需要同步更新。</li><li>带有二级索引的数据库，更新值时一般需要同步索引。事务角度看，这些索引就是不同的数据库对象。</li></ul><h2 id="弱隔离级别"><a href="#弱隔离级别" class="headerlink" title="弱隔离级别"></a>弱隔离级别</h2><p>数据库使用隔离来隐藏数据库内部的各种并发问题，但可串行化的隔离会严重影响性能，许多数据库不愿牺牲性能，更多采用较弱的隔离级别。</p><h3 id="读-提交"><a href="#读-提交" class="headerlink" title="读-提交"></a>读-提交</h3><p>读-提交是最基本的事务隔离级别，只提供以下两个保证：</p><ol><li>读数据库时，只能看到已经成功提交的数据。</li><li>写数据库时，只会覆盖已成功提交的数据。</li></ol><h4 id="防止脏读"><a href="#防止脏读" class="headerlink" title="防止脏读"></a>防止脏读</h4><p>事务如果更新多个对象，脏读就是另一个事务可能看到部分更新。事务如果中止，那么写入操作回滚，这时候发生脏读，则将已经回滚的数据读取，发生难以预料的后果。</p><h4 id="防止脏写"><a href="#防止脏写" class="headerlink" title="防止脏写"></a>防止脏写</h4><p>两个事务同时尝试更新相同的对象，后写的操作会覆盖较早的写入。如果先写的操作是尚未提交的事务的一部分，后写的事务如果覆盖的话，就是脏写。一般通过推迟第二个写请求，直到前面的事务提交或中止。</p><p><img src="https://raw.githubusercontent.com/zzugzj/blogImg/master/img/fig7-5.png" loading="lazy"></p><p>如果存在脏写，不同事务的并发写入会混杂在一起。</p><p>但是，读提交不能防止对计数器增加这种情况（a对计数器+1，b对计数器+1，最后计数器只加1），第二次写入确实是第一次提交后写入，不属于脏写，但结果错误。</p><h4 id="实现读-提交"><a href="#实现读-提交" class="headerlink" title="实现读-提交"></a>实现读-提交</h4><p>数据库通常使用行锁来防止脏写：当事务想修改某个对象，必须先拿到对象的锁，然后持有到事务提交或中止。只有一个事务能拿到锁。</p><p>但是，这种读锁的方式在实际中并不可行，因为运行时间较长的写事务会导致许多只读事务等待太长时间，大多数数据库对每个待更新的对象，事务提交前，所有读取只会读到旧值。</p><h3 id="快照级别隔离与可重复读"><a href="#快照级别隔离与可重复读" class="headerlink" title="快照级别隔离与可重复读"></a>快照级别隔离与可重复读</h3><p>表面上看读已提交，可能会以为它满足了事务的一切特征：支持中止（原子性），防止读取不完整的结果，并防止并发写的混乱。但还有很多场景可能造成并发错误。</p><p><img src="https://raw.githubusercontent.com/zzugzj/blogImg/master/img/fig7-6.png" loading="lazy"></p><p>这种现象称为不可重复读，或读倾斜。快照隔离是这个问题的最常见解决方案。想法是，每个事务都从数据库的<strong>一致快照（consistent snapshot）</strong> 中读取——也就是说，事务可以看到事务开始时在数据库中提交的所有数据。即使这些数据随后被另一个事务更改，每个事务也只能看到该特定时间点的旧数据。</p><h4 id="实现快照级别隔离"><a href="#实现快照级别隔离" class="headerlink" title="实现快照级别隔离"></a>实现快照级别隔离</h4><p>考虑到多个正在进行的事务可能会在不同的时间点查看数据库状态，所以数据库保存了对象的多个不同的提交版本，这种技术也叫做<strong>多版本并发控制（MVCC, multi-version concurrency control）</strong>。</p><p>支持快照隔离的存储引擎通常也使用MVCC来实现<strong>读已提交</strong>隔离级别。典型的做法是，在读-提交级别下，对每一个不同的查询单独创建一个快照；而快照级别隔离则是使用一个快照来运行整个事务。</p><p>实现基于MVCC的快照级别隔离：</p><p>当事务开始时，首先赋予一个唯一的、单调递增的事务ID。当事务向数据库写入新内容时，所写的数据都会被标记写入者的事务ID。</p><p><img src="https://raw.githubusercontent.com/zzugzj/blogImg/master/img/fig777-7.png" loading="lazy"></p><p>mysql实现MVCC主要通过依赖记录中的 3个隐式字段，undo日志 ，Read View 来实现的。具体见<a href="https://time.geekbang.org/column/article/70562">08 | 事务到底是隔离的还是不隔离的？</a></p><h4 id="一致性快照的可见性原则"><a href="#一致性快照的可见性原则" class="headerlink" title="一致性快照的可见性原则"></a>一致性快照的可见性原则</h4><p>当事务读取数据库时，通过事务ID可以决定那些对象可见，那些不可见。</p><ol><li>每笔事务开始时，数据库列出所有正在进行中的其他事务，然后忽略这些事务完成的部分写入（尽管以后可能提交），即不可见。</li><li>所有中止事务所做的修改全部不可见。</li><li>在当前事务开始只会开始的事务所做的任何修改不可见，不管是否完成的提交。</li><li>除此之外，其他所有写入都对应用查询可见。</li></ol><p>这些是针对于读来说的，但<strong>更新数据都是先读后写的，而这个读，只能读当前的值，称为“当前读”（current read）。</strong></p><h4 id="索引与快照级别隔离"><a href="#索引与快照级别隔离" class="headerlink" title="索引与快照级别隔离"></a>索引与快照级别隔离</h4><p>多版本数据库如何支持索引呢？一种方案是索引之间指向对象的所有版本，然后想办法过滤对当前事务不可见的那些版本。当后台垃圾回收进程决定删除某个旧对象版本时，对应的索引条目也需要随之删除。</p><p><strong>MySQL是通过undolog来实现的多版本，通过最新版本加undolog来将老版本计算出来，也就是版本对应的记录只有一条，不需要处理索引关系。</strong></p><p>在CouchDB，Datomic和LMDB中使用另一种方法。虽然它们也使用B树，但它们使用的是一种<strong>仅追加/写时拷贝（append-only/copy-on-write）</strong> 的变体，它们在更新时不覆盖树的页面，而为每个修改页面创建一份副本。从父页面直到树根都会级联更新，以指向它们子页面的新版本。任何不受写入影响的页面都不需要被复制，并且保持不变。</p><p>使用仅追加的B树，每个写入事务（或一批事务）都会创建一颗新的B树，当创建时，从该特定树根生长的树就是数据库的一个一致性快照。没必要根据事务ID过滤掉对象，因为后续写入不能修改现有的B树；它们只能创建新的树根。但这种方法也需要一个负责压缩和垃圾收集的后台进程。</p><h4 id="可重复读与命名混淆"><a href="#可重复读与命名混淆" class="headerlink" title="可重复读与命名混淆"></a>可重复读与命名混淆</h4><p>快照级别隔离对于只读事务特别有效。但是，具体到实现，许多数据库对它有不同的命名。Oracle称之为可串行化，PostgreSQL和MySQL仍称为可重复读。</p><p>这个命名混淆的原因是SQL标准没有定义快照级别隔离，因为当时还没出现快照隔离。标准定义的是可重复读，看起来比较接近于快照级别隔离。所以MySQL称快照级别隔离叫可重复读，符合标准。</p><h3 id="防止更新丢失"><a href="#防止更新丢失" class="headerlink" title="防止更新丢失"></a>防止更新丢失</h3><p>更新丢失可能发生在这样的场景中：应用从数据库读某些值，然后修改后写回新值。当两个事务在同样的对象执行类似操作时，第二个写操作不包括第一个事务修改的值，最终导致第一个事务修改的值可能会丢失。</p><p>很多场景都会发生：递增计数器，复杂对象的一部分进行修改，两个用户同时编辑Wiki界面。</p><p>虽然并发写冲突是一个普遍的问题，但也有很多解决方案。</p><h4 id="原子写操作"><a href="#原子写操作" class="headerlink" title="原子写操作"></a>原子写操作</h4><p>许多数据库提供了原子更新操作，在应用层面避免了“读-修改-写”操作。</p><p>原子操作通常采用对读取对象加独占锁的方式实现，这样更新被提交之前不会有其他事务读它。</p><h4 id="显示加锁"><a href="#显示加锁" class="headerlink" title="显示加锁"></a>显示加锁</h4><p>应用可以显示锁定待更新的对象。</p><pre class="language-plsql" data-language="plsql"><code class="language-plsql"><span class="token keyword">BEGIN</span> <span class="token keyword">TRANSACTION</span><span class="token punctuation">;</span><span class="token keyword">SELECT</span> <span class="token operator">*</span> <span class="token keyword">FROM</span> figures<span class="token keyword">WHERE</span> <span class="token keyword">name</span> <span class="token operator">=</span> <span class="token string">'robot'</span> <span class="token operator">AND</span> game_id <span class="token operator">=</span> <span class="token number">222</span><span class="token keyword">FOR</span> <span class="token keyword">UPDATE</span><span class="token punctuation">;</span><span class="token comment">-- 检查玩家的操作是否有效，然后更新先前SELECT返回棋子的位置。</span><span class="token keyword">UPDATE</span> figures <span class="token keyword">SET</span> position <span class="token operator">=</span> <span class="token string">'c4'</span> <span class="token keyword">WHERE</span> id <span class="token operator">=</span> <span class="token number">1234</span><span class="token punctuation">;</span><span class="token keyword">COMMIT</span><span class="token punctuation">;</span></code></pre><p><code>FOR UPDATE</code>子句告诉数据库应该对该查询返回的所有结果加锁。</p><h4 id="自动检测丢失的更新"><a href="#自动检测丢失的更新" class="headerlink" title="自动检测丢失的更新"></a>自动检测丢失的更新</h4><p>原子操作和锁是通过强制<strong>读取-修改-写入序列</strong>按顺序发生，来防止丢失更新的方法。另一种方法是允许它们并行执行，如果事务管理器检测到丢失更新，则中止事务并强制它们重试其<strong>读取-修改-写入序列</strong>。</p><p>这种方法的一个优点是，数据库可以结合快照隔离高效地执行此检查。事实上，PostgreSQL的可重复读，Oracle的可串行化和SQL Server的快照隔离级别，都会自动检测到丢失更新，并中止违规的事务。但是，MySQL/InnoDB的可重复读并不会检测<strong>丢失更新</strong>。一些作者认为，数据库必须能防止丢失更新才称得上是提供了<strong>快照隔离</strong>，所以在这个定义下，MySQL下没有完全提供快照隔离。</p><h4 id="原子比较和设置（CAS）"><a href="#原子比较和设置（CAS）" class="headerlink" title="原子比较和设置（CAS）"></a>原子比较和设置（CAS）</h4><p>也就是常说的乐观锁，此操作的目的是为了避免丢失更新：只有当前值从上次读取时一直未改变，才允许更新发生。如果当前值与先前读取的值不匹配，则更新不起作用，且必须重试读取-修改-写入序列。</p><pre class="language-plsql" data-language="plsql"><code class="language-plsql"><span class="token comment">-- 根据数据库的实现情况，这可能也可能不安全</span><span class="token keyword">UPDATE</span> wiki_pages <span class="token keyword">SET</span> content <span class="token operator">=</span> <span class="token string">'新内容'</span>  <span class="token keyword">WHERE</span> id <span class="token operator">=</span> <span class="token number">1234</span> <span class="token operator">AND</span> content <span class="token operator">=</span> <span class="token string">'旧内容'</span><span class="token punctuation">;</span></code></pre><p>但也有ABA问题，使用上见仁见智。</p><h4 id="冲突解决与复制"><a href="#冲突解决与复制" class="headerlink" title="冲突解决与复制"></a>冲突解决与复制</h4><p>对于支持多副本的数据库，防止丢失更新还需要考虑另一方面：由于多节点上的数据副本，不同的节点可能并发的修改数据，因此必须采取一些额外的措施来防止丢失更新。</p><p>加锁和原子修改的前提是只有一个最新的数据副本。在多主节点或无主节点的数据库不适用。但多副本数据库也通过保留多个冲突版本，来进行合并解决。</p><h3 id="更新丢失和脏写区别"><a href="#更新丢失和脏写区别" class="headerlink" title="更新丢失和脏写区别"></a>更新丢失和脏写区别</h3><p>更新丢失：应用从数据库读某些值，然后修改后写回新值。当两个事务在同样的对象执行类似操作时，第二个写操作不包括第一个事务修改的值，最终导致第一个事务修改的值可能会丢失。</p><p>脏写：两个事务同时尝试更新相同的对象，后写的操作会覆盖较早的写入。如果先写的操作是尚未提交的事务的一部分，后写的事务如果覆盖的话，就是脏写。</p><p>具体取决于时间窗口。</p><h3 id="写倾斜和幻读"><a href="#写倾斜和幻读" class="headerlink" title="写倾斜和幻读"></a>写倾斜和幻读</h3><p>多个事务并发写入同一对象引发了脏写和更新丢失，但还有一些更微妙的问题。</p><p><img src="https://raw.githubusercontent.com/zzugzj/blogImg/master/img/fig7-8.png" loading="lazy"></p><p>比如这个，就是一个问题。</p><h4 id="写倾斜的特征"><a href="#写倾斜的特征" class="headerlink" title="写倾斜的特征"></a>写倾斜的特征</h4><p>这种异常情况称为写倾斜。既不是脏写，也不是丢失更新，两个事务更新的是两个对象。</p><p>广义上：<strong>如果两个事务读取相同的一组对象，然后更新其中一部分，不同的事务可能更新不同的对象，则可能发生写倾斜；而不同的事务如果更新的是一个对象，则可能发生脏写或丢失更新。</strong></p><p>对于写倾斜，可选的方案有很多限制：</p><ul><li><p>由于涉及多个对象，单对象的原子操作不起作用。</p></li><li><p>不幸的是，在一些快照隔离的实现中，自动检测丢失更新对此并没有帮助。在PostgreSQL的可重复读，MySQL/InnoDB的可重复读，Oracle可序列化或SQL Server的快照隔离级别中，都不会自动检测写入偏差。自动防止写倾斜需要真正的可串行化隔离。</p></li><li><p>某些数据库允许配置约束，然后由数据库代为检查、执行约束（如外键约束，唯一性）。但是为了指定至少有一名医生必须在线，需要一个涉及多个对象的约束。大多数数据库没有内置对这种约束的支持，但是你可以使用触发器，或者物化视图来实现它们，这取决于不同的数据库。</p></li><li><p>如果不能使用串行化隔离，可以使用for update的方式来显示的加锁。</p></li></ul><h4 id="实体化冲突"><a href="#实体化冲突" class="headerlink" title="实体化冲突"></a>实体化冲突</h4><p>将幻读问题转变为针对数据库中一组具体行的锁冲突问题，就是实体化冲突。但是弄清楚如何实体化也很难，并且容易出错。不到万不得已，不推荐实体化冲突。大多数情况下，可串行化隔离方案更加可行。</p><h2 id="串行化"><a href="#串行化" class="headerlink" title="串行化"></a>串行化</h2><p>对于应对并发问题。读-提交和快照隔离虽然可以防止其中一部分，但也有写倾斜和幻读导致的问题。最后会面临如下挑战：</p><ul><li>隔离级别难以理解，并且在不同的数据库中实现的不尽一致（例如，“可重复读”的含义有区别）。</li><li>光检查应用代码很难判断在特定的隔离级别运行是否安全。 特别是在大型应用程序中，难以预测所有可能的并发情况。</li><li>没有检测竞争条件的好工具。原则上来说，静态分析可能会有帮助，但研究中的技术还没法实际应用。并发问题的测试是很难的，因为它们通常是非确定性的 —— 只有在倒霉的时机下才会出现问题。</li></ul><p>这些问题的答案也很简单：采用可串行化隔离级别。</p><p><strong>可串行化（Serializability）</strong>隔离通常被认为是最强的隔离级别。它保证即使事务可以并行执行，最终的结果与串行执行结果相同。这意味着，数据库可以防止<strong>所有</strong>可能的竞争条件。</p><p>目前大多数可串行化的数据库都使用以下技术之一：</p><ul><li>严格按照串行顺序执行。</li><li>两阶段锁定，几十年来几乎是唯一可行的选择。</li><li>乐观并发控制技术，如可串行化的快照隔离。</li></ul><h3 id="实际串行执行"><a href="#实际串行执行" class="headerlink" title="实际串行执行"></a>实际串行执行</h3><p>解决并发问题的方式就是避免并发，即一个线程按顺序每次只执行一个事务。</p><p>虽然很直白的想法，但数据库设计人员到2007年前后才认为它是可行的。因为内存越来越便宜，并且OLTP事务执行很快，只产生少量的读写操作。相比之下，运行时间较长的分析查询通常是只读的，可以在一致性快照上运行。</p><p>H-Store、Redis等采用串行方式执行事务。单线程执行有时可能比支持并发的系统效率更高，并避免锁开销。但是其吞吐量仅限于单个CPU核的吞吐量。为了充分利用单线程，需要与传统形式不同的结构的事务。</p><h4 id="在存储过程中封装事务"><a href="#在存储过程中封装事务" class="headerlink" title="在存储过程中封装事务"></a>在存储过程中封装事务</h4><p>采用事务的机制是希望将用户的所有操作都囊括，但人回应的速度会很慢，数据库总是等待人的回应，就会浪费大量资源，所以应用要提交整个事务代码作为存储过程打包发送到数据库。差异如图所示：</p><p><img src="https://raw.githubusercontent.com/zzugzj/blogImg/master/img/fig7-9.png" loading="lazy"></p><p>如果事务所需的所有数据都在内存中，则存储过程可以非常快地执行，而不用等待任何网络或磁盘I/O。</p><h4 id="存储过程的优缺点"><a href="#存储过程的优缺点" class="headerlink" title="存储过程的优缺点"></a>存储过程的优缺点</h4><p>存储过程存在有一段时间了，1999年以来就一直是SQL标准的一部分。但由于各种原因，名声不太好：</p><ul><li>每个数据库厂商都有自己的存储过程语言（Oracle有PL/SQL，SQL Server有T-SQL，PostgreSQL有PL/pgSQL等）。这些语言并没有跟上通用编程语言的发展，所以从今天的角度来看，它们看起来相当丑陋和陈旧，而且缺乏大多数编程语言中能找到的库的生态系统。</li><li>与应用服务器相比，在数据库中运行的管理困难，调试困难，版本控制和部署起来也更为尴尬，更难测试，更难和用于监控的指标收集系统相集成。</li><li>数据库通常比应用服务器对性能敏感的多，因为单个数据库实例通常由许多应用服务器共享。数据库中一个写得不好的存储过程（例如，占用大量内存或CPU时间）会比在应用服务器中相同的代码造成更多的麻烦。</li></ul><p>但是这些问题都是可以克服的。现代的存储过程实现放弃了PL/SQL，而是使用现有的通用编程语言：VoltDB使用Java或Groovy，而Redis使用Lua。</p><p><strong>存储过程与内存式数据存储</strong>，使得在单个线程上执行所有事务变得可行。由于不需要等待I/O，且避免了加锁开销，它们可以在单个线程上实现相当好的吞吐量。</p><h4 id="分区"><a href="#分区" class="headerlink" title="分区"></a>分区</h4><p>虽然串行执行使并发变简单，但单线程事务也会是很严重的瓶颈。</p><p>对于需要访问多个分区的任何事务，数据库必须在涉及的所有分区之间协调事务。存储过程需要跨越所有分区加锁执行，以确保整个系统的可串行性。</p><p>跨分区事务需要额外的协调开销，性能可能比单分区慢好几个数量级，而且很难通过加机器的方式来扩展性能。</p><p>事务是否可以是划分至单个分区很大程度上取决于应用数据的结构。简单的键值数据通常可以非常容易地进行分区，但是具有多个二级索引的数据可能需要大量的跨分区协调。</p><h4 id="串行执行小结"><a href="#串行执行小结" class="headerlink" title="串行执行小结"></a>串行执行小结</h4><p>在特定约束条件下，真的串行执行事务，已经成为一种实现可序列化隔离等级的可行办法。</p><ul><li>事务都必须简短而高效，只要有一个缓慢的事务，就会拖慢所有事务处理。</li><li>仅限于活跃数据集可以放入内存的情况。很少访问的数据可能会被移动到磁盘，但如果需要在单线程执行的事务中访问磁盘，就会严重拖累性能（可以中止事务，异步提取数据，完了再重启事务，这种方法叫反高速缓存）。</li><li>写入吞吐量必须足够低，才能在单个CPU核上处理，如若不然，事务需要采用分区。</li><li>跨分区事务虽然可以支持，但占比必须很小。</li></ul><h3 id="两阶段加锁"><a href="#两阶段加锁" class="headerlink" title="两阶段加锁"></a>两阶段加锁</h3><p>多个事务可以同时读取一个对象。但只要出现任何写操作，就需要<strong>加锁以独占访问</strong>。相当于只有读读可以并发，读写-写写都不行。区别于快照隔离中读写可以并发。</p><h4 id="实现两阶段锁（TWO-Phase-Lock）"><a href="#实现两阶段锁（TWO-Phase-Lock）" class="headerlink" title="实现两阶段锁（TWO-Phase Lock）"></a>实现两阶段锁（TWO-Phase Lock）</h4><p>2PL 已经用于 MySQL 和 SQL Server 中的可串行化隔离。已经 DB2 中的“可重复读隔离”。</p><p>数据库中每个对象都有一个读写锁来隔离读写操作。锁可以处于共享模式或独占模式。用法如下：</p><ul><li>事务读取对象，先以共享模式获得锁。共享锁可以多个事务同时获得，独占锁只能一个事务获取。</li><li>事务要修改对象，先以独占模式获得锁。</li><li>事务先读取对象，后尝试写入对象，需要把共享锁升级为独占锁，相当于直接获取独占锁。</li><li>事务获得锁后，持有锁到事务结束。</li></ul><p>这也是两阶段锁的由来，第一阶段事务执行前要获得锁，第二阶段事务结束时要释放锁。</p><p>这也很容易死锁，A事务等待B事务的锁，B事务等待A事务的锁。但数据库会自动检测事务间的死锁，并强行中止其中一个来打破死锁。被中止的事务需要应用层来重试。</p><h4 id="两阶段加锁的性能"><a href="#两阶段加锁的性能" class="headerlink" title="两阶段加锁的性能"></a>两阶段加锁的性能</h4><p>两阶段加锁的性能：事务吞吐量和查询响应时间比其他弱隔离级别下降非常多。</p><p>锁的获取和释放本身就有开销，更重要的是降低了事务的并发性。</p><p>虽然基于加锁方式的读-提交隔离也可能发生死锁，但在2PL下，死锁可能会更为频繁。因此导致的另一个性能问题就是由于死锁解除，应用重复尝试也导致最后的性能和效率降低。</p><h4 id="谓词锁"><a href="#谓词锁" class="headerlink" title="谓词锁"></a>谓词锁</h4><p>还有一个细节：上面的 “写倾斜与幻读” 中提到的一个事务改变另一个事务的查询结果的问题。</p><p>可串行化隔离是通过谓词锁来实现的，具体是在满足事务搜索条件的所有查询对象上加锁，例如：</p><pre class="language-plsql" data-language="plsql"><code class="language-plsql"><span class="token keyword">SELECT</span> <span class="token operator">*</span> <span class="token keyword">FROM</span> bookings<span class="token keyword">WHERE</span> room_id <span class="token operator">=</span> <span class="token number">123</span> <span class="token operator">AND</span>      end_time <span class="token operator">></span> <span class="token string">'2018-01-01 12:00'</span> <span class="token operator">AND</span>       start_time <span class="token operator">&lt;</span> <span class="token string">'2018-01-01 13:00'</span><span class="token punctuation">;</span></code></pre><p>谓词锁限制如下访问：</p><ul><li>如果事务A想要读取匹配某些条件的对象，它必须以共享模式获取查询条件的谓词锁。如果另一个事务B持有任何满足这一查询条件对象的互斥锁，那么A必须等到B释放锁之后才允许进行查询。</li><li>如果事务A想要插入，更新或删除任何对象，则必须首先检查旧值或新值是否与任何现有的谓词锁匹配。如果事务B持有匹配的谓词锁，那么A必须等到B完成后才能继续。</li></ul><h4 id="索引区间锁"><a href="#索引区间锁" class="headerlink" title="索引区间锁"></a>索引区间锁</h4><p>可以看出，谓词锁性能不好，会锁很多行。因此大多数使用2PL的数据库实际上使用索引区间锁。</p><p>索引区间锁，顾名思义，就是对索引上加锁，索引位置要包含查询的行，所以可能会将保护的对象扩大化。因为几乎所有的查询都会经过索引，另一个事务如果修改这个表，肯定要更新有关的索引，就会与共享锁冲突，于是处于等待状态到共享锁释放。</p><p>索引区间锁虽然不像谓词锁那样精确，但开销低很多。</p><p>如果没有合适的索引加区间锁，数据库可以回退到对整个表加共享锁。性能虽然不好，但也可以保证安全性。</p><h3 id="可串行化的快照隔离"><a href="#可串行化的快照隔离" class="headerlink" title="可串行化的快照隔离"></a>可串行化的快照隔离</h3><p>2PL可以保证串行化，但性能差强人意而且无法扩展（由于串行执行）；弱隔离级别虽然性能不出，但容易更新丢失，写倾斜和幻读。</p><p><strong>可序列化快照隔离（SSI, serializable snapshot isolation）</strong>在2008年首次提出，提供完整的可串行化保证，性能相比于快照隔离损失很小。可以用在单节点和分布式数据库中。但还需在实践中证明其性能。</p><h4 id="悲观与乐观的并发控制"><a href="#悲观与乐观的并发控制" class="headerlink" title="悲观与乐观的并发控制"></a>悲观与乐观的并发控制</h4><p>2PL是典型的悲观并发控制，设计原则是：如果某些操作可能出错（与其他事务发生锁冲突），那就直接放弃。</p><p>相比，可串行化的快照隔离是乐观并发控制。如果可能发生潜在冲突，那么事务会继续执行而不是中止，事务提交时，数据库检测是否确实发生冲突，如果发生了，中止事务并重试。</p><p>如果系统还有足够的性能提升空间，且事务竞争不大，乐观并发控制高效的多。如果存在很多冲突，则性能不佳，系统已经接近最大吞吐量，反复重试事务可能会使性能更差。</p><p>SSI基于快照隔离，与早期的乐观并发控制区别是，快照隔离基础上，SSI新增了相关算法来检测写入之间的串行化冲突从而决定中止那些事务。</p><h4 id="基于过期的条件做决定"><a href="#基于过期的条件做决定" class="headerlink" title="基于过期的条件做决定"></a>基于过期的条件做决定</h4><p>写倾斜是，事务先查询某些数据，查询期间数据如果被修改，那事务在提交时决策的依据信息就会变化。</p><p>所以为了安全起见，查询结果会与写事务间存在因果依赖关系。为了提供可串行化的隔离，数据库必须检测事务是否会修改其他事务的查询结果，并在此情况下中止事务。</p><p>数据库如何知道查询结果是否可能已经改变？有两种情况需要考虑：</p><ul><li>读取是否作用于一个即将过期的MVCC对象。</li><li>检测写入是否影响即将完成的读取。</li></ul><h4 id="检测是否读取了过期的MVCC对象"><a href="#检测是否读取了过期的MVCC对象" class="headerlink" title="检测是否读取了过期的MVCC对象"></a>检测是否读取了过期的MVCC对象</h4><p><img src="https://raw.githubusercontent.com/zzugzj/blogImg/master/img/fig7-10.png" loading="lazy"></p><p>如图，虽然由于MVCC机制，事务忽略在创建快照时尚未提交的事务写入，事务43不知道42已经修改了Alice的状态，但事务管理器可以发现这个值已经变化。当事务提交时，数据库会检查是否存在一些当初被忽略的写操作是否完成提交，如果是，则必须中止当前事务。</p><h4 id="检测写是否影响之前的读"><a href="#检测写是否影响之前的读" class="headerlink" title="检测写是否影响之前的读"></a>检测写是否影响之前的读</h4><p>另一种是读取数据后，另一个事务修改了数据。</p><p><img src="https://raw.githubusercontent.com/zzugzj/blogImg/master/img/fig7-11.png" loading="lazy"></p><p>如果shift_id上有索引，数据库可以通过索引条目1234来记录事务42和43都查询了相同的结果。如果没有索引，可以在表级别跟踪此信息。该额外记录只要保存一小段时间，并发的事务处理完后就丢弃。</p><p>另一个事务尝试修改时，首先检查索引，从而确定是否存在一些读目标数据的其他事务。在事务提交时，会提示其他事务，所读的数据已经发生变化。</p><p>图中，43的修改影响了42，但43还未提交，42首先尝试提交，可以成功，然后43试图提交时，来自42的冲突写已经提交生效，43中止。</p><h4 id="可串行化快照隔离的性能"><a href="#可串行化快照隔离的性能" class="headerlink" title="可串行化快照隔离的性能"></a>可串行化快照隔离的性能</h4><p>与2PL相比，可串行化快照隔离优点事务不需要等待其他事务所持有的锁。读写通常不会阻塞。这样设计使查询延迟更加稳定、可预测。一致性快照执行只读查询不需要任何锁。</p><p>与串行执行相比，可串行化快照隔离可以突破单个CPU核的限制。FoundationDB将冲突检测分布在多台机器上，从而提高总体吞吐量。数据即使跨多台机器分区，事务也可以在多个分区上读、写数据并保证可串行化隔离。</p><p>另外，事务中止比例会显著影响SSI的性能表现。SSI要求读-写型事务要简短（只读事务没有限制）。总体上讲，SSI比2PL和串行执行更能容忍执行缓慢的事务。</p><h2 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h2><h3 id="并发控制的问题"><a href="#并发控制的问题" class="headerlink" title="并发控制的问题"></a>并发控制的问题</h3><p><strong>脏读</strong></p><p>客户端读到了其他客户端尚未提交的写入。读-提交以及更强的隔离级别可以防止脏读。</p><p><strong>脏写</strong></p><p>客户端覆盖了另一个客户端尚未提交的写入。几乎所有的数据库实现都可以防止脏写。</p><p><strong>读倾斜(不可重复读)</strong></p><p>客户在不同的时间点看到了不同值。快照隔离是最常用的防范手段，即事务总是在某个时间点的一致性快照中读取数据。通常采用多版本并发控制(MVCC) 来实现快照隔离。</p><p><strong>更新丢失</strong></p><p>两个客户端同时执行读-修改-写入操作序列，出现了其中一个覆盖 了另一个的写入，但又没有包含对方最新值的情况，最终导致了部分修改数据发生了丢失。快照隔离的一些实现可以自动防止这种异常，而另一些则需要手动锁定查询结果(SELECT FOR UPDATE)。</p><p><strong>写倾斜</strong></p><p>事务首先查询数据，根据返回的结果而作出某些决定，然后修改数据库。当事务提交时，支持决定的前提条件已不再成立。只有可串行化的隔离才能防止这种异常。</p><p><strong>幻读</strong></p><p>事务读取了某些符合查询条件的对象，同时另一个客户端执行写入，改变了先前的查询结果。快照隔离可以防止简单的幻读，但写倾斜情况则需要特殊处理，例如采用区间范围锁。</p><h3 id="可串行化隔离的三种不同方法"><a href="#可串行化隔离的三种不同方法" class="headerlink" title="可串行化隔离的三种不同方法"></a>可串行化隔离的三种不同方法</h3><p><strong>严格串行执行事务</strong></p><p>如果每个事务的执行速度非常快，且单个CPU核可以满足事务的吞吐量要求，严格串行执行是一个非常简单有效的方案。</p><p><strong>两阶段加锁</strong></p><p>几十年来，一直是实现可串行化的标准方式，但还是很多系统出于性能原因放弃使用它。</p><p><strong>可串行化的快照隔离（SSI）</strong></p><p>新算法，避免前面方法的大部分缺点。它秉持乐观预期的原则，允许多个事务并发执行而不互相阻塞；仅当事务尝试提交时，才检查可能的冲突，如果发现违背了串行化，某些事务会中止重试。</p>]]></content>
    
    
    <summary type="html">数十年来，事务（transaction） 一直是简化这些问题的首选机制。事务是应用程序将多个读写操作组合成一个逻辑单元的一种方式。从概念上讲，事务中的所有读写操作被视作单个操作来执行：整个事务要么成功（提交（commit））要么失败（中止（abort），回滚（rollback））。如果失败，应用程序可以安全地重试。对于事务来说，应用程序的错误处理变得简单多了，因为它不用再担心部分失败的情况了，即某些操作成功，某些失败（无论出于何种原因）。</summary>
    
    
    
    <category term="分布式" scheme="https://zzugzj.github.io/categories/%E5%88%86%E5%B8%83%E5%BC%8F/"/>
    
    
    <category term="分布式" scheme="https://zzugzj.github.io/tags/%E5%88%86%E5%B8%83%E5%BC%8F/"/>
    
    <category term="数据库" scheme="https://zzugzj.github.io/tags/%E6%95%B0%E6%8D%AE%E5%BA%93/"/>
    
  </entry>
  
  <entry>
    <title>分布式系统-数据复制</title>
    <link href="https://zzugzj.github.io/posts/a89650f0/"/>
    <id>https://zzugzj.github.io/posts/a89650f0/</id>
    <published>2021-08-11T12:52:34.837Z</published>
    <updated>2023-11-05T05:53:33.076Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>数据复制的困难之处在于处理复制数据的变更。几乎所有分布式数据库都使用这三种复制算法：<strong>单领导者（single leader）</strong>，<strong>多领导者（multi leader）</strong>和<strong>无领导者（leaderless）</strong>。</p><h2 id="领导者与追随者"><a href="#领导者与追随者" class="headerlink" title="领导者与追随者"></a>领导者与追随者</h2><p>存储数据库副本的节点称为副本。为了保证副本数据的一致性，最常见的方式是 <strong>基于领导者的复制（leader-based replication）</strong> （也称 <strong>主动/被动（active/passive）</strong> 或 <strong>主/从（master/slave）</strong> 复制）。原理如下：</p><ol><li>副本之一被指定为 <strong>领导者（leader）</strong>，也称为 <strong>主库（master|primary）</strong> 。当客户端要向数据库写入时，它必须将请求发送给<strong>领导者</strong>，领导者会将新数据写入其本地存储。</li><li>其他副本被称为<strong>追随者（followers）</strong>，亦称为<strong>只读副本（read replicas）</strong>，<strong>从库（slaves）</strong>，<strong>备库（ sencondaries）</strong>，<strong>热备（hot-standby）</strong>。每当领导者将新数据写入本地存储时，它也会将数据变更发送给所有的追随者，称之为<strong>复制日志（replication log）</strong>记录或<strong>变更流（change stream）</strong>。每个跟随者从领导者拉取日志，并相应更新其本地数据库副本，方法是按照领导者处理的相同顺序应用所有写入。</li><li>当客户想要从数据库中读取数据时，它可以向领导者或追随者查询。 但只有领导者才能接受写操作（从客户端的角度来看从库都是只读的）。</li></ol><p><img src="https://raw.githubusercontent.com/zzugzj/blogImg/master/img/fig5-1.png" loading="lazy"></p><h3 id="同步复制和异步复制"><a href="#同步复制和异步复制" class="headerlink" title="同步复制和异步复制"></a>同步复制和异步复制</h3><p>下图展示了同步复制和异步复制的区别，follower1是同步复制，2是异步复制。</p><p><img src="https://raw.githubusercontent.com/zzugzj/blogImg/master/img/fig5-2.png" loading="lazy"></p><p>同步复制的优点是，从库保证有与主库一致的最新数据副本。如果主库突然失效，我们可以确信这些数据仍然能在从库上上找到。缺点是，如果同步从库没有响应，主库就无法处理写入操作。主库必须阻止所有写入，并等待同步副本再次可用。</p><p>将所有从库都设置为同步的是不切实际的：任何一个节点的中断都会导致整个系统停滞不前。所以，可以令一个跟随者同步，其他异步，当同步从库变慢或不可用，就换一个。这种配置有时也被称为 <strong>半同步（semi-synchronous）</strong>。</p><p>通常情况下，基于领导者的复制都配置为完全异步。 这意味着即使已经向客户端确认成功，写入也不能保证 <strong>持久（Durable）</strong> 。 然而，一个完全异步的配置也有优点：即使所有的从库都落后了，主库也可以继续处理写入。</p><h3 id="设置新从库"><a href="#设置新从库" class="headerlink" title="设置新从库"></a>设置新从库</h3><p>如果要设置一个新的从库（比如增加副本数量等），可能要进行如下步骤：</p><ol><li>在某个时刻获取主库的一致性快照（如果可能），而不必锁定整个数据库。</li><li>将快照复制到新的从库节点。</li><li>从库连接到主库，并拉取快照之后发生的所有数据变更。这要求快照与主库复制日志中的位置精确关联。这个位置在MySQL中称为 <strong>二进制日志坐标（binlog coordinates）</strong>。</li><li>当从库处理完快照之后积压的数据变更，我们说它 <strong>赶上（caught up）</strong> 了主库。</li></ol><h3 id="处理节点宕机"><a href="#处理节点宕机" class="headerlink" title="处理节点宕机"></a>处理节点宕机</h3><h4 id="从库失效"><a href="#从库失效" class="headerlink" title="从库失效"></a>从库失效</h4><p>从库可以从日志中知道，在发生故障之前处理的最后一个事务。因此，从库可以连接到主库，并请求在从库断开连接时发生的所有数据变更。</p><h4 id="主库失效"><a href="#主库失效" class="headerlink" title="主库失效"></a>主库失效</h4><p>其中一个从库需要被提升为新的主库，需要重新配置客户端，以将它们的写操作发送给新的主库，其他从库需要开始拉取来自新主库的数据变更。这个过程被称为<strong>故障切换（failover）</strong>。步骤如下：</p><ol><li>确认主库失效。大多数系统只是简单使用 <strong>超时（Timeout）</strong> ：节点频繁地相互来回传递消息，并且如果一个节点在一段时间内（例如30秒）没有响应，就认为它挂了。</li><li>选择一个新的主库。这可以通过选举过程（主库由剩余副本以多数选举产生）来完成，或者可以由之前选定的<strong>控制器节点（controller node）</strong>来指定新的主库。</li><li>重新配置系统以启用新的主库。客户端现在需要将它们的写请求发送给新主库。如果老领导回来，可能仍然认为自己是主库，没有意识到其他副本已经让它下台了。系统需要确保老领导认可新领导，成为一个从库。</li></ol><h4 id="故障切换出现的问题"><a href="#故障切换出现的问题" class="headerlink" title="故障切换出现的问题"></a>故障切换出现的问题</h4><ul><li><p>如果使用异步复制，则新主库可能没有收到老主库宕机前最后的写入操作。在选出新主库后，如果老主库重新加入集群，新主库在此期间可能会收到冲突的写入，那这些写入该如何处理？最常见的解决方案是简单丢弃老主库未复制的写入，这很可能打破客户对于数据持久性的期望。</p></li><li><p>如果数据库需要和其他外部存储相协调，那么丢弃写入内容是极其危险的操作。例如在GitHub的一场事故中，一个过时的MySQL从库被提升为主库。数据库使用自增ID作为主键，因为新主库的计数器落后于老主库的计数器，所以新主库重新分配了一些已经被老主库分配掉的ID作为主键。这些主键也在Redis中使用，主键重用使得MySQL和Redis中数据产生不一致，最后导致一些私有数据泄漏到错误的用户手中。</p></li><li><p>发生某些故障时可能会出现两个节点都以为自己是主库的情况。这种情况称为 **脑裂(split brain)**，非常危险：如果两个主库都可以接受写操作，却没有冲突解决机制，那么数据就可能丢失或损坏。一些系统采取了安全防范措施：当检测到两个主库节点同时存在时会关闭其中一个节点，但设计粗糙的机制可能最后会导致两个节点都被关闭。</p></li><li><p>主库被宣告死亡之前的正确超时应该怎么配置？在主库失效的情况下，超时时间越长，意味着恢复时间也越长。但是如果超时设置太短，又可能会出现不必要的故障切换。例如，临时负载峰值可能导致节点的响应时间超时，或网络故障可能导致数据包延迟。如果系统已经处于高负载或网络问题的困扰之中，那么不必要的故障切换可能会让情况变得更糟糕。</p></li></ul><h3 id="复制日志的实现"><a href="#复制日志的实现" class="headerlink" title="复制日志的实现"></a>复制日志的实现</h3><h4 id="基于语句的复制"><a href="#基于语句的复制" class="headerlink" title="基于语句的复制"></a>基于语句的复制</h4><p>就是将sql语句发送给从库，从库需要解析并执行语句，但会出很多问题：如果调用 <strong>非确定性函数（nondeterministic）</strong> 的语句，可能会在每个副本上生成不同的值，比如<code>NOW()</code>。如果使用了自增列，则必须在每个副本以完全相同的顺序执行他们。</p><p>基于语句的复制在5.1版本前的MySQL中使用。因为它相当紧凑，现在有时候也还在用。但现在在默认情况下，如果语句中存在任何不确定性，MySQL会切换到基于行的复制。</p><h4 id="传输预写式日志（WAL）"><a href="#传输预写式日志（WAL）" class="headerlink" title="传输预写式日志（WAL）"></a>传输预写式日志（WAL）</h4><p>通常都是将写操作追加到日志中：</p><ul><li>对于日志结构存储引擎，日志是主要的存储位置。日志段在后台压缩，并进行垃圾回收。</li><li>对于覆写单个磁盘块的<a href="ch3.md#B%E6%A0%91">B树</a>，每次修改都会先写入 <strong>预写式日志（Write Ahead Log, WAL）</strong>，以便崩溃后索引可以恢复到一个一致的状态。</li></ul><p>当从库应用这个日志时，它会建立和主库一模一样数据结构的副本。</p><h4 id="逻辑日志复制（基于行）"><a href="#逻辑日志复制（基于行）" class="headerlink" title="逻辑日志复制（基于行）"></a>逻辑日志复制（基于行）</h4><p>逻辑日志，比如MySQL的binlog，这种关系数据库的逻辑日志通常是以行的粒度描述对数据库表的写入的记录序列：</p><ul><li>对于插入的行，日志包含所有列的新值。</li><li>对于删除的行，日志包含足够的信息来唯一标识已删除的行。通常是主键，但是如果表上没有主键，则需要记录所有列的旧值。</li><li>对于更新的行，日志包含足够的信息来唯一标识更新的行，以及所有列的新值（或至少所有已更改的列的新值）。</li></ul><p>修改多行的事务会生成多个这样的日志记录，后面跟着一条记录，指出事务已经提交。</p><p>由于逻辑日志与存储引擎内部分离，因此可以更容易地保持向后兼容，从而使领导者和跟随者能够运行不同版本的数据库软件甚至不同的存储引擎。对于外部应用程序来说，逻辑日志格式也更容易解析。</p><h2 id="复制延迟问题"><a href="#复制延迟问题" class="headerlink" title="复制延迟问题"></a>复制延迟问题</h2><p>如果使用异步复制的话，应用程序难免会从从库读到过时的信息，这会导致数据库的不一致。</p><h3 id="读己之写"><a href="#读己之写" class="headerlink" title="读己之写"></a>读己之写</h3><p>读后一致性的实现方法：</p><ul><li><p>读用户<strong>可能已经修改过</strong>的内容时，都从主库读；比如某些用户可以修改的信息，读的时候从主库读，但如何判断那些是用户可以修改的信息，是个问题。</p></li><li><p>跟踪上一次更新时间，比如上一次更新在一分钟内，从主库读，一分钟后读从库。</p></li><li><p>客户端可以记住最近一次写入的时间戳，系统需要确保从库为该用户提供任何查询时，该时间戳前的变更都已经传播到了本从库中。如果当前从库不够新，则可以从另一个从库读，或者等待从库追赶上来。</p></li><li><p>如果您的副本分布在多个数据中心，则会增加复杂性。任何需要由领导者提供服务的请求都必须路由到包含主库的数据中心。</p></li></ul><h3 id="单调读"><a href="#单调读" class="headerlink" title="单调读"></a>单调读</h3><p>如果用户多次查询的情况下，查的是进度不同的从库，可能出现第二次查询比第一次查询滞后的情况。如图：</p><p><img src="https://raw.githubusercontent.com/zzugzj/blogImg/master/img/fig5-4.png" loading="lazy"></p><p>单调读取仅意味着如果一个用户顺序地进行多次读取，如果先前读取到较新的数据，后续读取不会得到更旧的数据。</p><p>实现单调读取的一种方式是确保每个用户总是从同一个副本进行读取。例如，可以基于用户ID的散列来选择副本，而不是随机选择副本。但是，如果该副本失败，用户的查询将需要重新路由到另一个副本。</p><h3 id="一致前缀读"><a href="#一致前缀读" class="headerlink" title="一致前缀读"></a>一致前缀读</h3><p>如果数据进行分区存储的话，没个分区都有主从库，那么可能导致这种情况：</p><p><img src="https://raw.githubusercontent.com/zzugzj/blogImg/master/img/fig5-5.png" loading="lazy"></p><p><strong>一致前缀读（consistent prefix reads）</strong>：如果一系列写入按某个顺序发生，那么任何人读取这些写入时，也会看见它们以同样的顺序出现。</p><p>一种解决方案是，确保任何因果相关的写入都写入相同的分区。对于某些无法高效完成这种操作的应用，还有一些显式跟踪因果依赖关系的算法。</p><h2 id="多主复制"><a href="#多主复制" class="headerlink" title="多主复制"></a>多主复制</h2><p>基于领导者的复制模型的自然延伸是允许多个节点接受写入。 复制仍然以同样的方式发生：处理写入的每个节点都必须将该数据更改转发给所有其他节点。 称之为<strong>多领导者配置</strong>（也称多主、多活复制）。在这种情况下，每个领导者同时扮演其他领导者的追随者。</p><h3 id="多主复制的应用场景"><a href="#多主复制的应用场景" class="headerlink" title="多主复制的应用场景"></a>多主复制的应用场景</h3><h4 id="运维多个数据中心"><a href="#运维多个数据中心" class="headerlink" title="运维多个数据中心"></a>运维多个数据中心</h4><p>多领导者配置中可以在每个数据中心都有主库。在每个数据中心内使用常规的主从复制；在数据中心之间，每个数据中心的主库都会将其更改复制到其他数据中心的主库中。 </p><p><img src="https://raw.githubusercontent.com/zzugzj/blogImg/master/img/fig5-6.png" loading="lazy"></p><p>在运维多个数据中心时，单主和多主的优劣比较：</p><ul><li><p><strong><em>性能</em></strong></p><p>在单活配置中，每个写入都必须穿过互联网，这可能会增加写入时间，并可能违背了设置多个数据中心的初心。在多活配置中，每个写操作都可以在本地数据中心进行处理，并与其他数据中心异步复制。</p></li><li><p><strong><em>容忍数据中心停机</em></strong></p><p>在单主配置中，故障切换可以使另一个数据中心里的追随者成为领导者。在多活配置中，发生故障的数据中心归队时，复制会自动赶上。</p></li><li><p><strong><em>容忍网络问题</em></strong></p><p>单主配置对这数据中心间的连接问题非常敏感，因为通过这个连接进行的写操作是同步的。采用异步复制功能的多活配置通常能更好地承受网络问题：临时的网络中断并不会妨碍正在处理的写入。</p></li></ul><p>尽管多主复制有这些优势，但也有一个很大的缺点：两个不同的数据中心可能会同时修改相同的数据，写冲突是必须解决的。</p><h4 id="需要离线操作的客户端"><a href="#需要离线操作的客户端" class="headerlink" title="需要离线操作的客户端"></a>需要离线操作的客户端</h4><p>多主复制的另一种适用场景是：应用程序在断网之后仍然需要继续工作。</p><p>在这种情况下，每个设备都有一个充当领导者的本地数据库，并且在所有设备上的日历副本之间同步时，存在异步的多主复制过程。复制延迟可能是几小时甚至几天，具体取决于何时可以访问互联网。</p><p>从架构的角度来看，这种设置实际上与数据中心之间的多领导者复制类似，每个设备都是一个“数据中心”，而它们之间的网络连接是极度不可靠的。实现起来很困难。</p><h3 id="处理写入冲突"><a href="#处理写入冲突" class="headerlink" title="处理写入冲突"></a>处理写入冲突</h3><p>两个用户如果将各自的更改同步到各自的主库中，这时主库之间的同步就会有冲突。</p><p><img src="https://raw.githubusercontent.com/zzugzj/blogImg/master/img/fig5-7.png" loading="lazy"></p><h4 id="同步和异步冲突检测"><a href="#同步和异步冲突检测" class="headerlink" title="同步和异步冲突检测"></a>同步和异步冲突检测</h4><p>单主数据库中，第二个写入会被阻塞，等待第一个写入完成，或终止第二个写入，强制用户重试。多活配置中，两个写入都是成功的，并且在稍后的时间点仅仅异步地检测到冲突。那时要求用户解决冲突可能为时已晚。</p><p>如果使冲突检测同步，即等待写入被复制到所有副本，然后告诉用户写入成功，但这样会丢弃多主复制的主要优点：允许每个副本独立接受写入。</p><h4 id="避免冲突"><a href="#避免冲突" class="headerlink" title="避免冲突"></a>避免冲突</h4><p>如果应用程序可以确保特定记录的所有写入都通过同一个领导者，那么冲突就不会发生。</p><p>但有时需要更改指定的主库，比如数据中心出现故障，需要将流量路由到其他数据中心，冲突避免会中断。</p><h4 id="收敛至一致的状态"><a href="#收敛至一致的状态" class="headerlink" title="收敛至一致的状态"></a>收敛至一致的状态</h4><p>数据库必须以一种 <strong>收敛（convergent）</strong> 的方式解决冲突，这意味着所有副本必须在所有变更复制完成时收敛至一个相同的最终值。</p><p>实现冲突合并解决有多种途径：</p><ul><li>给每个写入一个唯一的ID，挑选最高ID的写入作为胜利者，并丢弃其他写入。如果使用时间戳，这种技术被称为<strong>最后写入胜利（LWW, last write wins）</strong>。虽然这种方法很流行，但是很容易造成数据丢失。</li><li>为每个副本分配一个唯一的ID，ID编号更高的写入具有更高的优先级。这种方法也意味着数据丢失。</li><li>以某种方式将这些值合并在一起 - 例如，按字母顺序排序，然后连接它们。</li><li>用一种可保留所有信息的显式数据结构来记录冲突，并编写解决冲突的应用程序代码。</li></ul><h4 id="自定义冲突解决逻辑"><a href="#自定义冲突解决逻辑" class="headerlink" title="自定义冲突解决逻辑"></a>自定义冲突解决逻辑</h4><p>作为解决冲突最合适的方法可能取决于应用程序，大多数多主复制工具允许使用应用程序代码编写冲突解决逻辑。该代码可以在写入或读取时执行：</p><p><strong><em>写时执行</em></strong></p><p>只要数据库系统检测到复制更改日志中存在冲突，就会调用冲突处理程序。</p><p><strong><em>读时执行</em></strong></p><p>当检测到冲突时，所有冲突写入被存储。下一次读取数据时，会将这些多个版本的数据返回给应用程序。应用程序可能会提示用户或自动解决冲突，并将结果写回数据库。</p><h3 id="多主复制拓扑"><a href="#多主复制拓扑" class="headerlink" title="多主复制拓扑"></a>多主复制拓扑</h3><p>如果领导者在两个以上，哪如何定义他们的拓扑结构呢？</p><p><img src="https://raw.githubusercontent.com/zzugzj/blogImg/master/img/fig5-8.png" loading="lazy"></p><p>a和b这两种拓扑的问题是，只要一个节点故障，就可能会中断其他节点之间的复制消息流，导致它们无法通信，直到节点修复。</p><p>c这种拓扑的问题是，一些网络链接比其他网络链接更快的情况下，一些复制消息可能“超过”其他复制消息：</p><p><img src="https://raw.githubusercontent.com/zzugzj/blogImg/master/img/fig5-9.png" loading="lazy"></p><h2 id="无主复制"><a href="#无主复制" class="headerlink" title="无主复制"></a>无主复制</h2><p>在一些无领导者的实现中，客户端直接将写入发送到到几个副本中，而另一些情况下，一个 <strong>协调者（coordinator）</strong> 节点代表客户端进行写入。但与主库数据库不同，协调者不执行特定的写入顺序。我们将会看到，这种设计上的差异对数据库的使用方式有着深远的影响。</p><h3 id="当节点故障时写入数据库"><a href="#当节点故障时写入数据库" class="headerlink" title="当节点故障时写入数据库"></a>当节点故障时写入数据库</h3><p>无主复制情况下，故障切换是不存在的。比如有三个副本，客户端收到两个副本的确认信息后，认为写入成功，忽略了第三个副本错过写入的事实：</p><p><img src="https://raw.githubusercontent.com/zzugzj/blogImg/master/img/fig5-10.png" loading="lazy"></p><p>为了解决这个问题，当一个客户端从数据库中读取数据时，它不仅仅发送它的请求到一个副本：读请求也被并行地发送到多个节点。客户可能会从不同的节点获得不同的响应。即来自一个节点的最新值和来自另一个节点的陈旧值。版本号用于确定哪个值更新。</p><h4 id="读修复和周期性静默修复"><a href="#读修复和周期性静默修复" class="headerlink" title="读修复和周期性静默修复"></a>读修复和周期性静默修复</h4><p>读修复：当发现某个副本有陈旧值，则将新值写回该副本。</p><p>周期性静默修复：一些数据存储具有后台进程，该进程不断查找副本之间的数据差异，并将任何缺少的数据从一个副本复制到另一个副本。这个过程不会以特定的顺序复制写入。</p><h4 id="读写的法定人数"><a href="#读写的法定人数" class="headerlink" title="读写的法定人数"></a>读写的法定人数</h4><p>如果有n个副本，每个写入必须由w节点确认才能被认为是成功的，并且我们必须至少为每个读取查询r个节点。只要$w + r&gt; n$，我们期望在读取时获得最新的值，因为r个读取中至少有一个节点是最新的。遵循这些r值，w值的读写称为<strong>法定人数（quorum）</strong>的读和写。</p><p>法定人数条件$w + r&gt; n$允许系统容忍不可用的节点。如果少于所需的w或r节点可用，则写入或读取将返回错误。 </p><h3 id="仲裁一致性的局限性"><a href="#仲裁一致性的局限性" class="headerlink" title="仲裁一致性的局限性"></a>仲裁一致性的局限性</h3><p>通常，r和w被选为多数（超过 $n/2$ ）节点，因为这确保了$w + r&gt; n$，同时容忍多达$n/2$个节点故障。</p><p>较小的w和r虽然更有可能会读取过时的数据，但是这种配置允许更低的延迟和更高的可用性：如果存在网络中断，并且许多副本变得无法访问，则可以继续处理读取和写入的机会更大。只有当可达副本的数量低于w或r时，数据库才分别变得不可用于写入或读取。</p><p>即使在$w + r&gt; n$的情况下，也可能存在返回陈旧值的边缘情况。这取决于实现，但可能的情况包括：</p><ul><li>如果使用松散的法定人数，w个写入和r个读取落在完全不同的节点上，因此r节点和w之间不再保证有重叠节点。</li><li>如果写操作与读操作同时发生，写操作可能仅反映在某些副本上。在这种情况下，不确定读取是返回旧值还是新值。</li><li>如果写操作在某些副本上成功，而在其他节点上失败，在小于w个副本上写入成功。所以整体判定写入失败，但整体写入失败并没有在写入成功的副本上回滚。这意味着如果一个写入虽然报告失败，后续的读取仍然可能会读取这次失败写入的值。</li><li>如果携带新值的节点失败，需要读取其他带有旧值的副本。并且其数据从带有旧值的副本中恢复，则存储新值的副本数可能会低于w，从而打破法定人数条件。</li></ul><h4 id="监控陈旧度"><a href="#监控陈旧度" class="headerlink" title="监控陈旧度"></a>监控陈旧度</h4><p>从运维的角度来看，监视你的数据库是否返回最新的结果是很重要的。即使应用可以容忍陈旧的读取，您也需要了解复制的健康状况。如果显著落后，应该提醒您，以便您可以调查原因。</p><p>在无领导者复制的系统中，没有固定的写入顺序，这使得监控变得更加困难。</p><h3 id="松散法定人数与带提示的接力"><a href="#松散法定人数与带提示的接力" class="headerlink" title="松散法定人数与带提示的接力"></a>松散法定人数与带提示的接力</h3><p>一般大型的集群（节点数大于n个），客户端可能连接集群中部分数据库，当网络中断或数据库出问题时，可能客户端连接就小于n了，那么如果将客户端的写入写入到一些别的可达节点，不在客户端本来连接的n个节点间时，写和读仍有成功响应，这就叫<strong>松散的法定人数</strong>，一旦网络中断解决，代表节点临时接受的节点的任何写入，都发送到适当的“本地”节点，这就是所谓的<strong>带提示的接力（hinted handoff）</strong>。</p><p>松散法定人数对写入可用性的提高特别有用：只要有任何w节点可用，数据库就可以接受写入。然而，这意味着即使当$w + r&gt; n$时，也不能确定读取某个键的最新值，因为最新的值可能已经临时写入了n之外的某些节点。</p><h4 id="运维多个数据中心-1"><a href="#运维多个数据中心-1" class="headerlink" title="运维多个数据中心"></a>运维多个数据中心</h4><p>Cassandra和Voldemort在正常的无主模型中实现了他们的多数据中心支持：副本的数量n包括所有数据中心的节点，在配置中，您可以指定每个数据中心中您想拥有的副本的数量。无论数据中心如何，每个来自客户端的写入都会发送到所有副本，但客户端通常只等待来自其本地数据中心内的法定节点的确认，从而不会受到跨数据中心链路延迟和中断的影响。对其他数据中心的高延迟写入通常被配置为异步发生，尽管配置有一定的灵活性。</p><h3 id="检测并发写入"><a href="#检测并发写入" class="headerlink" title="检测并发写入"></a>检测并发写入</h3><p>由于可变的网络延迟和部分故障，事件可能在不同的节点以不同的顺序到达：</p><p><img src="https://raw.githubusercontent.com/zzugzj/blogImg/master/img/fig5-12.png" loading="lazy"></p><p>如果每个节点只要接收到来自客户端的写入请求就简单地覆盖了某个键的值，那么节点就会永久地不一致，如图中的最终获取请求所示：节点2认为 X 的最终值是 B，而其他节点认为值是 A 。</p><h4 id="最后写入胜利"><a href="#最后写入胜利" class="headerlink" title="最后写入胜利"></a>最后写入胜利</h4><p>即使写入没有自然的排序，我们也可以强制任意排序。例如，可以为每个写入附加一个时间戳，挑选最 <strong>“最近”</strong> 的最大时间戳，并丢弃具有较早时间戳的任何写入。这种冲突解决算法被称为 <strong>最后写入胜利（LWW, last write wins）</strong>。</p><p>LWW实现了最终收敛的目标，但以<strong>持久性</strong>为代价：如果同一个Key有多个并发写入，即使它们都被报告为客户端成功（因为它们被写入 w 个副本），但只有一个写入将存活，而其他写入将被静默丢弃。如果丢失数据不可接受，LWW是解决冲突的一个很烂的选择。</p><h4 id="如何判断两个操作是否并发"><a href="#如何判断两个操作是否并发" class="headerlink" title="如何判断两个操作是否并发"></a>如何判断两个操作是否并发</h4><p>为了简单起见，我们从一个只有一个副本的数据库开始。一旦我们已经制定了如何在单个副本上完成这项工作，我们可以将该方法概括为具有多个副本的无领导者数据库。</p><p>两个客户端同时向同一购物车添加项目：</p><p><img src="https://raw.githubusercontent.com/zzugzj/blogImg/master/img/fig5-13.png" loading="lazy"></p><p>因果依赖关系图：</p><p><img src="https://raw.githubusercontent.com/zzugzj/blogImg/master/img/fig5-14.png" loading="lazy"></p><p>服务器可以通过查看版本号来确定两个操作是否是并发的——它不需要解释该值本身（因此该值可以是任何数据结构）。该算法的工作原理如下：</p><ul><li>服务器为每个主键保留一个版本号，每次写入主键时都增加版本号，并将新版本号与写入的值一起存储。</li><li>当客户端读取键时，服务器将返回所有未覆盖的当前值以及最新的版本号。客户端在写入前必须读取。</li><li>客户端写入主键时，必须包含之前读取的版本号，并且必须将之前读取的所有值合并在一起。 （来自写入请求的响应可以像读取一样，返回所有当前值，这使得我们可以像购物车示例那样连接多个写入。）</li><li>当服务器接收到具有特定版本号的写入时，它可以覆盖该版本号或更低版本的所有值（因为它知道它们已经被合并到新的值中），但是它必须保持所有值更高版本号（因为这些值与传入的写入同时发生）。</li></ul><p>当一个写入包含前一次读取的版本号时，它会告诉我们写入的是哪一种状态。如果在不包含版本号的情况下进行写操作，则与所有其他写操作并发，因此它不会覆盖任何内容 —— 只会在随后的读取中作为其中一个值返回。</p><h4 id="合并同时写入的值"><a href="#合并同时写入的值" class="headerlink" title="合并同时写入的值"></a>合并同时写入的值</h4><p>上述算法可以保证不会数据丢弃，但客户端必须通过合并并发写入的值来继承旧值。riak称这些并发值是兄弟关系。</p><p>上述例子中，最后购物车是将并发值合并和去重来展示的，但如果某个客户端删去了商品，另一个没删去，删去的商品就会出现在最后的合并值中。</p><p>为了防止该问题，删除时系统要保留一个对应的版本号来标记这个商品需要在合并时去除。</p><p>这个实现挺复杂的，需要设计一个专门的数据结构来自动合并。比如riak支持CRDT的数据结构来高效的自动合并和删除标记。</p><h4 id="版本矢量"><a href="#版本矢量" class="headerlink" title="版本矢量"></a>版本矢量</h4><p>多个副本同时接受并发希写入时，需要为每个副本和主键定义一个版本号。每个副本处理写入时增加版本号，并跟踪其他副本看到的版本号。所有版本号的集合称为版本矢量。</p><p>当读取数据时，数据库副本会返回版本矢量给客户端，在随后写入时需要将版本信息包含在请求发送到数据库。</p><p>和单副本例子一样，程序要执行合并操作。版本矢量可以保证从某个副本读取值写入另一个副本，虽然会衍生新的兄弟值，但不会发生数据丢失并可以正确合并所有并发值。</p>]]></content>
    
    
    <summary type="html">如果复制中的数据不会随时间而改变，那复制就很简单：将数据复制到每个节点一次就万事大吉。复制的困难之处在于处理复制数据的变更（change），这就是本章所要讲的。我们将讨论三种流行的变更复制算法：单领导者（single leader），多领导者（multi leader）和无领导者（leaderless）。几乎所有分布式数据库都使用这三种方法之一。</summary>
    
    
    
    <category term="分布式" scheme="https://zzugzj.github.io/categories/%E5%88%86%E5%B8%83%E5%BC%8F/"/>
    
    
    <category term="分布式" scheme="https://zzugzj.github.io/tags/%E5%88%86%E5%B8%83%E5%BC%8F/"/>
    
    <category term="数据库" scheme="https://zzugzj.github.io/tags/%E6%95%B0%E6%8D%AE%E5%BA%93/"/>
    
  </entry>
  
  <entry>
    <title>分布式系统-数据分区</title>
    <link href="https://zzugzj.github.io/posts/167c9cdb/"/>
    <id>https://zzugzj.github.io/posts/167c9cdb/</id>
    <published>2021-08-11T00:54:12.127Z</published>
    <updated>2023-11-05T05:53:29.384Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>数据在不同节点上的副本,对于非常大的数据集,或非常高的吞吐量，仅仅进行复制是不够的：我们需要将数据进行<strong>分区（partitions）</strong>，也称为<strong>分片（sharding）</strong>。</p><p>分区主要是为了可伸缩性，不同分区可以放在不共享集群的不同节点上。</p><h2 id="分区与复制"><a href="#分区与复制" class="headerlink" title="分区与复制"></a>分区与复制</h2><p>分区通常与复制结合使用，使得每个分区的副本存储在多个节点上。 这意味着，即使每条记录属于一个分区，它仍然可以存储在多个不同的节点上以获得容错能力。</p><p>一个节点存储多个分区。如果主从复制模型，每个分区领导者在一个节点，从库在其他节点。每个节点可能是某些分区的领导者，同时是其他分区的追随者。</p><p><img src="https://raw.githubusercontent.com/zzugzj/blogImg/master/img/fig6-1.png" loading="lazy"></p><h2 id="键值数据的分区"><a href="#键值数据的分区" class="headerlink" title="键值数据的分区"></a>键值数据的分区</h2><p>分区目标是将数据和查询负载均匀分布在各个节点上。如果每个节点公平分享数据和负载，那么理论上10个节点应该能够处理10倍的数据量和10倍的单个节点的读写吞吐量（暂时忽略复制）。</p><p>如果分区是不公平的情况下，一些分区比其他分区有更多的数据或查询，我们称之为<strong>偏斜（skew）</strong>。不均衡导致的高负载的分区被称为<strong>热点（hot spot）</strong>。</p><h3 id="根据键的范围分区"><a href="#根据键的范围分区" class="headerlink" title="根据键的范围分区"></a>根据键的范围分区</h3><p>一种分区的方法是为每个分区指定一块连续的键范围。如果知道范围之间的边界，则可以轻松确定哪个分区包含某个值。</p><p>但这样键的范围不一定分布均匀，因为数据分布可能不均匀。这就需要根据数据调整分区边界。</p><h3 id="根据键的散列分区"><a href="#根据键的散列分区" class="headerlink" title="根据键的散列分区"></a>根据键的散列分区</h3><p>由于偏斜和热点的风险，许多分布式数据存储使用散列函数来确定给定键的分区。</p><p>如果有一个合适的散列函数，那就可以为每个分区分配一个散列范围。</p><p>这种技术擅长在分区之间分配键。分区边界可以是均匀间隔的，也可以是伪随机选择的（在这种情况下，该技术有时也被称为<strong>一致性哈希（consistent hashing）</strong>）。</p><p>但是，通过使用key散列进行分区，就会失去键范围分区的一个好的属性：高效执行范围查询的能力。</p><h3 id="负载倾斜与消除热点"><a href="#负载倾斜与消除热点" class="headerlink" title="负载倾斜与消除热点"></a>负载倾斜与消除热点</h3><p>哈希分区可以帮助减少热点。但是，它不能完全避免它们：在极端情况下，所有的读写操作都是针对同一个键的，所有的请求都会被路由到同一个分区。</p><p>这个缺点目前没有好的解决方案，一个简单的方法是在主键的开始或结尾添加一个随机数。只要一个两位数的十进制随机数就可以将主键分散为100种不同的主键,从而存储在不同的分区中，然而，将主键进行分割之后，任何读取都必须要做额外的工作，这就需要自己权衡。</p><h2 id="分片与二级索引"><a href="#分片与二级索引" class="headerlink" title="分片与二级索引"></a>分片与二级索引</h2><p>通过主键分区很简单，只需要通过关键字来确定分区即可。但二级索引通常不能唯一的标记一条记录，而是加速特定值的查询。他们不能规整的映射进分区中。</p><p>有两种用二级索引对数据库进行分区的方法：<strong>基于文档的分区（document-based）</strong>和<strong>基于词条（term-based）的分区</strong>。</p><h3 id="基于文档分区的二级索引"><a href="#基于文档分区的二级索引" class="headerlink" title="基于文档分区的二级索引"></a>基于文档分区的二级索引</h3><p>比如用户搜索汽车，允许他们通过颜色和厂商过滤，所以需要一个在颜色和厂商上的二级索引。</p><p><img src="https://raw.githubusercontent.com/zzugzj/blogImg/master/img/fig6-4.png" loading="lazy"></p><p>在这种索引方法中，每个分区是完全独立的：每个分区维护自己的二级索引，仅覆盖该分区中的文档。它不关心存储在其他分区的数据。出于这个原因，<strong>文档分区索引</strong>也被称为<strong>本地索引（local index）</strong>（而不是将在下一节中描述的<strong>全局索引（global index）</strong>）。</p><p>这种查询分区数据库的方法有时被称为<strong>分散/聚集（scatter/gather）</strong>，显然这种二级索引的查询代价高昂。但实践中应用也广泛，比如MongoDB，Riak， Elasticsearch 等都是文档方式的二级索引。</p><h3 id="基于词条的二级索引"><a href="#基于词条的二级索引" class="headerlink" title="基于词条的二级索引"></a>基于词条的二级索引</h3><p>对所有数据构建<strong>全局索引</strong>， 而不是每个分区维护本地索引。为了避免成为瓶颈，不能将全局索引存储在一个节点上，否则就破坏分区均衡的目标。</p><p><img src="https://raw.githubusercontent.com/zzugzj/blogImg/master/img/fig6-5.png" loading="lazy"></p><p>如图：所有分区的颜色为红的汽车收录在索引color:red中，索引本身也是分区的。比如从a到r在1区，s到z在2区。可以根据词条本身或它的散列进行分区，对本身分区的好处就是可以范围查询，散列分区可以更好的负载均衡。</p><p>全局的词条分区相比文档分区的优点是读取高效，不需要<strong>分散/收集</strong>所有分区。但写入速度较慢且较为复杂，因为写入单个文档现在可能会影响索引的多个分区。</p><p>另一方面，写入的每个数据都要立即反映在索引上，对词条分区来说，这时个跨多个分区的分布式事务，速度受到很大影响，所以所有数据库都不支持同步更新二级索引。在实践中，对全局二级索引的更新通常是<strong>异步</strong>的。</p><h2 id="分区再平衡"><a href="#分区再平衡" class="headerlink" title="分区再平衡"></a>分区再平衡</h2><p>随着时间的推移，数据库会有各种变化。</p><ul><li>查询压力增加，添加更多的CPU来处理负载。</li><li>数据规模增加，添加更多的磁盘和RAM。</li><li>节点出现故障，需要其他机器来接管失效的节点。</li></ul><p>这些变化都需要将数据和请求从一个节点移动到另一个节点。这个迁移负载的过程称为<strong>再平衡</strong>。</p><p>无论使用哪种分区方案，再平衡通常都要满足一些最低要求：</p><ul><li>再平衡之后，数据存储，读取和写入请求应该在集群范围更均匀的分布。</li><li>再平衡发生时，数据库应该继续提供读写服务。</li><li>避免不必要的负载迁移，加快动态再平衡，并减少网络和磁盘I/O负载。</li></ul><h3 id="平衡策略"><a href="#平衡策略" class="headerlink" title="平衡策略"></a>平衡策略</h3><p>下面是几种分配策略：</p><h4 id="反面教材：取模"><a href="#反面教材：取模" class="headerlink" title="反面教材：取模"></a>反面教材：取模</h4><p>取模有很大问题，如果节点数N发生变化，会导致很多关键字从现有节点迁移。不符合避免不必要的负载迁移的最低要求。</p><h4 id="固定数量的分区"><a href="#固定数量的分区" class="headerlink" title="固定数量的分区"></a>固定数量的分区</h4><p>这个方案较为简单，一开始就创建远超节点数量的分区，比如10个节点，我创建1000个分区，那么，有新节点加入，就可以从每个现有节点匀走几个分区，直到达到均衡。删除则采取相反的均衡措施。</p><p>分区在节点迁移，但数量不变，也不改变关键字到分区的映射关系。考虑到节点的网络运输数据的实践，可以逐步完成，在此期间，旧的分区仍旧可以接受读写请求。</p><p><img src="https://raw.githubusercontent.com/zzugzj/blogImg/master/img/fig6-6.png" loading="lazy"></p><p>更可以将集群中不同的硬件配置考虑进来，强大的节点负责更多分区。</p><h4 id="动态分区"><a href="#动态分区" class="headerlink" title="动态分区"></a>动态分区</h4><p>多使用关键字区间分区的数据库，如果边界设置有问题，可能导致大多数数据都挤在少部分分区。手动重新配置分区边界将非常繁琐。</p><p>所以，一些数据库如HBase和RethinkDB采用动态分区。当分区增长到超过配置的大小时（在HBase上，默认值是10GB），会被分成两个分区，每个分区约占一半的数据。与之相反，如果大量数据被删除并且分区缩小到某个阈值以下，则可以将其与相邻分区合并。类似b树的分裂操作。</p><p>仍旧是每个分区在一个节点，一个节点多个分区。大分区裂开后，可以将一半转移到其他节点来平衡负载。在HBase中，分区文件的传输通过HDFS（底层分布式文件系统）来实现</p><p>动态分区另一个优点是分区数量可以适配数据总量。少量数据就少量分区，大量数据，则每个分区大小被限制在一个可配置的最大值。</p><p>动态分区在初始时一般会创建一系列初始分区（称为<strong>预分裂</strong>，可以通过一些关键字的分布情况来设置）。动态分区不仅适合关键字区间分区，也适合基于哈希的分区策略。从版本2.4开始，MongoDB同时支持范围和哈希分区，并且都是进行动态分割分区。</p><h4 id="按节点比例分区"><a href="#按节点比例分区" class="headerlink" title="按节点比例分区"></a>按节点比例分区</h4><p>也就是分区随节点数量变化，分区大小和数据集大小是正比关系。</p><p>新节点加入集群时，随机选择固定数量的现有分区进行拆分，这个随机选择需要好的算法来维护。放在不公平的分裂。</p><p>随机选择分区边界的前提是采用基于哈希的分区。</p><h3 id="自动与手动再平衡操作"><a href="#自动与手动再平衡操作" class="headerlink" title="自动与手动再平衡操作"></a>自动与手动再平衡操作</h3><p>全自动与全手动都有缺点，一般让管理员介入到再平衡可能是更好的选择。</p><h4 id="请求路由"><a href="#请求路由" class="headerlink" title="请求路由"></a>请求路由</h4><p>现在将数据集分布到多个节点上，但仍有一个问题，用户如何知道请求需要发送到哪个节点？如果分区再平衡，分区地址可能也会变化。</p><p>这种问题一般使用<strong>服务发现</strong>来解决：</p><ol><li>允许客户链接任何节点（例如，通过<strong>循环策略的负载均衡（Round-Robin Load Balancer）</strong>）。如果该节点恰巧拥有请求的分区，则它可以直接处理该请求；否则，它将请求转发到适当的节点，接收回复并传递给客户端。</li><li>将所有客户端的请求发送到路由层，由它来负责请求转发。此路由层本身不处理任何请求；它仅充当一个分区感知的负载均衡器。</li><li>要求客户端知道分区和节点的分配。在这种情况下，客户端可以直接连接到适当的节点，而不需要任何中介。</li></ol><p><img src="https://raw.githubusercontent.com/zzugzj/blogImg/master/img/fig6-7.png" loading="lazy"></p><p>方法有多种，但最核心的是：作为路由决策的组件，如何知道分区和节点的对应关系以及变化情况？</p><p>许多分布式数据系统都依赖一个独立的协调服务，比如zookeeper。节点在zookeeper中注册自己，zookeeper维护分区到节点的映射，其他参与者（如客户端）向zookeeper订阅信息。一旦信息改变，ZooKeeper就会通知路由层，使路由信息保持最新状态。</p><p><img src="https://raw.githubusercontent.com/zzugzj/blogImg/master/img/fig6-8.png" loading="lazy"></p>]]></content>
    
    
    <summary type="html">通常情况下，每条数据（每条记录，每行或每个文档）属于且仅属于一个分区。有很多方法可以实现这一点，本章将进行深入讨论。实际上，每个分区都是自己的小型数据库，尽管数据库可能支持同时进行多个分区的操作。</summary>
    
    
    
    <category term="分布式" scheme="https://zzugzj.github.io/categories/%E5%88%86%E5%B8%83%E5%BC%8F/"/>
    
    
    <category term="分布式" scheme="https://zzugzj.github.io/tags/%E5%88%86%E5%B8%83%E5%BC%8F/"/>
    
    <category term="数据库" scheme="https://zzugzj.github.io/tags/%E6%95%B0%E6%8D%AE%E5%BA%93/"/>
    
  </entry>
  
  <entry>
    <title>reactor</title>
    <link href="https://zzugzj.github.io/posts/3cf52171/"/>
    <id>https://zzugzj.github.io/posts/3cf52171/</id>
    <published>2021-08-07T03:49:34.244Z</published>
    <updated>2023-11-05T05:53:58.202Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><h2 id="Reactor"><a href="#Reactor" class="headerlink" title="Reactor"></a>Reactor</h2><h3 id="基于事件的程序设计"><a href="#基于事件的程序设计" class="headerlink" title="基于事件的程序设计"></a>基于事件的程序设计</h3><p>事件驱动的好处是占用资源少，效率高，可扩展性强，是支持高性能高并发的不二之选。</p><p>如果你熟悉 GUI 编程的话，你就会知道，GUI 设定了一系列的控件，如 Button、Label、文本框等，当我们设计基于控件的程序时，一般都会给 Button 的点击安排一个函数，类似这样：</p><pre class="language-c" data-language="c"><code class="language-c"><span class="token comment">//按钮点击的事件处理</span><span class="token keyword">void</span> <span class="token function">onButtonClick</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">&#123;</span><span class="token punctuation">&#125;</span></code></pre><p>这个设计的思想是，一个无限循环的事件分发线程在后台运行，一旦用户在界面上产生了某种操作，例如点击了某个 Button，或者点击了某个文本框，一个事件会被产生并放置到事件队列中，这个事件会有一个类似前面的 onButtonClick 回调函数。事件分发线程的任务，就是为每个发生的事件找到对应的事件回调函数并执行它。这样，一个基于事件驱动的 GUI 程序就可以完美地工作了。</p><p>还有一个类似的例子是 Web 编程领域。同样的，Web 程序会在 Web 界面上放置各种界面元素，例如 Label、文本框、按钮等，和 GUI 程序类似，给感兴趣的界面元素设计 JavaScript 回调函数，当用户操作时，对应的 JavaScript 回调函数会被执行，完成某个计算或操作。这样，一个基于事件驱动的 Web 程序就可以在浏览器中完美地工作了。</p><p>事件驱动模型，也被叫做反应堆模型（reactor），或者是 Event loop 模型。这个模型的核心有两点。</p><p>第一，它存在一个无限循环的事件分发线程，或者叫做 reactor 线程、Event loop 线程。这个事件分发线程的背后，就是 poll、epoll 等 I/O 分发技术的使用。</p><p>第二，所有的 I/O 操作都可以抽象成事件，每个事件必须有回调函数来处理。acceptor 上有连接建立成功、已连接套接字上发送缓冲区空出可以写、通信管道 pipe 上有数据可以读，这些都是一个个事件，通过事件分发，这些事件都可以一一被检测，并调用对应的回调函数加以处理。</p><h3 id="几种-I-O-模型和线程模型设计"><a href="#几种-I-O-模型和线程模型设计" class="headerlink" title="几种 I/O 模型和线程模型设计"></a>几种 I/O 模型和线程模型设计</h3><p>任何一个网络程序，所做的事情可以总结成下面几种：</p><ul><li>read：从套接字收取数据；</li><li>decode：对收到的数据进行解析；</li><li>compute：根据解析之后的内容，进行计算和处理；</li><li>encode：将处理之后的结果，按照约定的格式进行编码；</li><li>send：最后，通过套接字把结果发送出去。</li></ul><h3 id="single-reactor-thread"><a href="#single-reactor-thread" class="headerlink" title="single reactor thread"></a>single reactor thread</h3><p>这里有一张图，解释了这一讲的设计模式。一个 reactor 线程上同时负责分发 acceptor 的事件、已连接套接字的 I/O 事件。</p><img src="https://raw.githubusercontent.com/zzugzj/blogImg/master/img/b8627a1a1d32da4b55ac74d4f0230f33.png" alt="img" style="zoom: 80%;" / loading="lazy"><h3 id="single-reactor-thread-worker-threads"><a href="#single-reactor-thread-worker-threads" class="headerlink" title="single reactor thread + worker threads"></a>single reactor thread + worker threads</h3><p>上述的设计模式有一个问题，和 I/O 事件处理相比，应用程序的业务逻辑处理是比较耗时的，这些工作相对而言比较独立，它们会拖慢整个反应堆模式的执行效率。</p><p>将这些 decode、compute、encode 型工作放置到另外的线程池中，和反应堆线程解耦。反应堆线程只负责处理 I/O 相关的工作，业务逻辑放到线程池里由空闲的线程来执行。当结果完成后，再交给反应堆线程，由反应堆线程通过套接字将结果发送出去。</p><img src="https://raw.githubusercontent.com/zzugzj/blogImg/master/img/7e4505bb75fef4a4bb945e6dc3040823.png" alt="img" style="zoom: 80%;" / loading="lazy"><p>reactor模式虽然可以同时分发Acceptor上的连接建立事件和已建立连接的 I/O 事件，但如果客户端比较多的情况下，单 reactor 线程既分发连接建立，又分发已建立连接的 I/O，有点忙不过来，导致客户端连接成功率偏低。</p><h3 id="主-从-reactor-模式"><a href="#主-从-reactor-模式" class="headerlink" title="主 - 从 reactor 模式"></a>主 - 从 reactor 模式</h3><p>主 - 从这个模式的核心思想是，主反应堆线程只负责分发 Acceptor 连接建立，已连接套接字上的 I/O 事件交给 sub-reactor 负责分发。其中 sub-reactor 的数量，可以根据 CPU 的核数来灵活设置。而且，同一个套接字事件分发只会出现在一个反应堆线程中，这会大大减少并发处理的锁开销。</p><img src="https://raw.githubusercontent.com/zzugzj/blogImg/master/img/9269551b14c51dc9605f43d441c5a92a.png" alt="img" style="zoom: 80%;" / loading="lazy"><p>我们的主反应堆线程一直在感知连接建立的事件，如果有连接成功建立，主反应堆线程通过 accept 方法获取已连接套接字，接下来会按照一定的算法选取一个从反应堆线程，并把已连接套接字加入到选择好的从反应堆线程中。</p><h3 id="主-从-reactor-worker-threads-模式"><a href="#主-从-reactor-worker-threads-模式" class="headerlink" title="主 - 从 reactor+worker threads 模式"></a>主 - 从 reactor+worker threads 模式</h3><p>如果说主 - 从 reactor 模式解决了 I/O 分发的高效率问题，那么 work threads 就解决了业务逻辑和 I/O 分发之间的耦合问题。把这两个策略组装在一起，就是实战中普遍采用的模式。</p><img src="https://raw.githubusercontent.com/zzugzj/blogImg/master/img/1e647269a5f51497bd5488b2a44444b4.png" alt="img" style="zoom: 80%;" / loading="lazy"><p>这张图解释了主 - 从反应堆下加上 worker 线程池的处理模式。</p><p>主 - 从反应堆跟上面介绍的做法是一样的。和上面不一样的是，这里将 decode、compute、encode 等 CPU 密集型的工作从 I/O 线程中拿走，这些工作交给 worker 线程池来处理，而且这些工作拆分成了一个个子任务进行。encode 之后完成的结果再由 sub-reactor 的 I/O 线程发送出去。</p><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>1：阻塞IO+多进程——实现简单，性能一般</p><p>2：阻塞IO+多线程——相比于阻塞IO+多进程，减少了上下文切换所带来的开销，性能有所提高。</p><p>3：阻塞IO+线程池——相比于阻塞IO+多线程，减少了线程频繁创建和销毁的开销，性能有了进一步的提高。</p><p>4：Reactor+线程池——相比于阻塞IO+线程池，采用了更加先进的事件驱动设计思想，资源占用少、效率高、扩展性强，是支持高性能高并发场景的利器。</p><p>5：主从Reactor+线程池——相比于Reactor+线程池，将连接建立事件和已建立连接的各种IO事件分离，主Reactor只负责处理连接事件，从Reactor只负责处理各种IO事件，这样能增加客户端连接的成功率，并且可以充分利用现在多CPU的资源特性进一步的提高IO事件的处理效率。</p><p>6：主 - 从Reactor模式的核心思想是，主Reactor线程只负责分发 Acceptor 连接建立，已连接套接字上的 I/O 事件交给 从Reactor 负责分发。其中 sub-reactor 的数量，可以根据 CPU 的核数来灵活设置。</p>]]></content>
    
    
    <summary type="html">网络编程模型通常有如下几种：Reactor, Proactor, Asynchronous, Completion Token, and Acceptor-Connector. 本文主要对最主流的Reactor模型进行介绍。通常网络编程模型处理的主要流程如下</summary>
    
    
    
    <category term="网络编程" scheme="https://zzugzj.github.io/categories/%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B/"/>
    
    
    <category term="reactor" scheme="https://zzugzj.github.io/tags/reactor/"/>
    
  </entry>
  
  <entry>
    <title>IO模型</title>
    <link href="https://zzugzj.github.io/posts/aeafbee0/"/>
    <id>https://zzugzj.github.io/posts/aeafbee0/</id>
    <published>2021-08-06T14:36:45.140Z</published>
    <updated>2023-11-05T05:54:02.275Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><h2 id="阻塞-非阻塞"><a href="#阻塞-非阻塞" class="headerlink" title="阻塞 / 非阻塞"></a>阻塞 / 非阻塞</h2><p>当应用程序调用阻塞IO来完成某个操作时，应用程序会被挂起，比如网络延迟等原因造成的卡顿，这时整个程序感觉就像被阻塞一样。实际上，之所以调用阻塞IO的程序卡顿，是因为内核将CPU的时间切换给其他有需要的进程，如计算，数据复制等操作，应用程序就不会得到CPU，也就进行不了了。</p><p>非阻塞 I/O 则不然，当应用程序调用非阻塞 I/O 完成某个操作时，内核立即返回，不会把 CPU 时间切换给其他进程，应用程序在返回后，可以得到足够的 CPU 时间继续完成其他事情。</p><p>一张表来总结一下 read 和 write 在阻塞模式和非阻塞模式下的不同行为特性：</p><p><img src="https://raw.githubusercontent.com/zzugzj/blogImg/master/img/6e7a467bc6f5985eebbd94ef7de14aaa.png" alt="img" loading="lazy"></p><p>关于多路复用和非阻塞IO的区别，多路复用的轮询是内核帮我们完成的，不用像非阻塞IO一样需要我们手动去轮询，另外就是一个进程能同时等待多个文件描述符，而这些文件描述符（套接字描述符）其中的任意一个进入读就绪状态，select()函数就可以返回。</p><p>那么，如果在连接数比较低的情况下，使用select/epoll的web server不一定比使用multi-threading + blocking IO的web server性能更好，可能延迟还更大。select/epoll的优势并不是对于单个连接能处理得更快，而是在于能处理更多的连接。</p><p>关于accept</p><p>当 accept 和 I/O 多路复用 select、poll 等一起配合使用时，如果在监听套接字上触发事件，说明有连接建立完成，此时调用 accept 肯定可以返回已连接套接字。这样看来，似乎把监听套接字设置为非阻塞，没有任何好处。</p><p>如果在监听套接字上有可读事件发生时，并没有马上调用 accept。由于客户端发生了 RST 分节，该连接被接收端内核从自己的已完成队列中删除了，此时再调用 accept，由于没有已完成连接，accept 一直阻塞，更为严重的是，该线程再也没有机会对其他 I/O 事件进行分发，相当于该服务器无法对其他 I/O 进行服务。如果我们将监听套接字设为非阻塞，上述的情形就不会再发生。只不过对于 accept 的返回值，需要正确地处理各种看似异常的错误，例如忽略 EWOULDBLOCK、EAGAIN 等。</p><h3 id="阻塞IO和进程模型"><a href="#阻塞IO和进程模型" class="headerlink" title="阻塞IO和进程模型"></a>阻塞IO和进程模型</h3><h4 id="父进程和子进程"><a href="#父进程和子进程" class="headerlink" title="父进程和子进程"></a>父进程和子进程</h4><p>一个进程有完整的地址空间、程序计数器等，如果想创建一个新的进程，使用函数 fork 就可以。</p><pre class="language-c" data-language="c"><code class="language-c"><span class="token class-name">pid_t</span> <span class="token function">fork</span><span class="token punctuation">(</span><span class="token keyword">void</span><span class="token punctuation">)</span>返回：在子进程中为<span class="token number">0</span>，在父进程中为子进程ID，若出错则为<span class="token operator">-</span><span class="token number">1</span></code></pre><p>程序调用 fork 一次，它却在父、子进程里各返回一次（fork前是一个进程执行，fork后就是两个进程执行了，所以返回两次）。在调用该函数的进程（即为父进程）中返回的是新派生的进程 ID 号，在子进程中返回的值为 0。想要知道当前执行的进程到底是父进程，还是子进程，只能通过返回值来进行判断。</p><p>fork 函数实现的时候，实际上会把当前父进程的所有相关值都克隆一份，包括地址空间、打开的文件描述符、程序计数器等，就连执行代码也会拷贝一份，新派生的进程的表现行为和父进程近乎一样。</p><pre class="language-c" data-language="c"><code class="language-c"><span class="token keyword">if</span><span class="token punctuation">(</span><span class="token function">fork</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">&#123;</span>  <span class="token function">do_child_process</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span> <span class="token comment">//子进程执行代码</span><span class="token punctuation">&#125;</span><span class="token keyword">else</span><span class="token punctuation">&#123;</span>  <span class="token function">do_parent_process</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>  <span class="token comment">//父进程执行代码</span><span class="token punctuation">&#125;</span></code></pre><p>当一个子进程退出时，系统内核还保留了该进程的若干信息，比如退出状态。这样的进程如果不回收，就会变成僵尸进程。在 Linux 下，这样的“僵尸”进程会被挂到进程号为 1 的 init 进程上。所以，由父进程派生出来的子进程，也必须由父进程负责回收，否则子进程就会变成僵尸进程。僵尸进程会占用不必要的内存空间，如果量多到了一定数量级，就会耗尽我们的系统资源。</p><p>使用阻塞 I/O 和进程模型，为每一个连接创建一个独立的子进程来进行服务，是一个非常简单有效的实现方式，这种方式可能很难满足高性能程序的需求，但好处在于实现简单。在实现这样的程序时，需要注意两点：要注意对套接字的关闭梳理；要注意对子进程进行回收，避免产生不必要的僵尸进程。</p><h2 id="IO多路复用之select、poll、epoll"><a href="#IO多路复用之select、poll、epoll" class="headerlink" title="IO多路复用之select、poll、epoll"></a>IO多路复用之select、poll、epoll</h2><p>I/O 多路复用的设计初衷就是解决这样的场景。我们可以把标准输入、套接字等都看做 I/O 的一路，多路复用的意思，就是在任何一路 I/O 有“事件”发生的情况下，==通知==应用程序去处理相应的 I/O 事件，这样我们的程序就可以在同一时刻仿佛可以处理多个 I/O 事件。</p><p>select，poll，epoll本质上都是同步I/O，因为他们都需要在读写事件就绪后自己负责进行读写，也就是说这个读写过程是阻塞的，而异步I/O则无需自己负责进行读写，异步I/O的实现会负责把数据从内核拷贝到用户空间。</p><h3 id="select"><a href="#select" class="headerlink" title="select"></a>select</h3><p>select 函数是一种常见的 I/O 多路复用技术。使用 select 函数，通知内核挂起进程，当一个或多个 I/O 事件发生后，控制权返还给应用程序，由应用程序进行 I/O 事件的处理。</p><p>这些 I/O 事件的类型非常多，比如：</p><ul><li>标准输入文件描述符准备好可以读。</li><li>监听套接字准备好，新的连接已经建立成功。</li><li>已连接套接字准备好可以写。</li><li>如果一个 I/O 事件等待超过了 10 秒，发生了超时事件。</li></ul><h4 id="select-函数的使用方法"><a href="#select-函数的使用方法" class="headerlink" title="select 函数的使用方法"></a>select 函数的使用方法</h4><p>select 方法是多个 UNIX 平台支持的非常常见的 I/O 多路复用技术，其良好跨平台支持也是它的一个优点。它通过描述符集合来表示检测的 I/O 对象，通过三个不同的描述符集合来描述 I/O 事件 ：可读、可写和异常。但是 select 有一个缺点，那就是所支持的文件描述符的个数是有限的。在 Linux 系统中，select 的默认最大值为 1024。</p><p>函数声明：</p><pre class="language-c" data-language="c"><code class="language-c"><span class="token keyword">int</span> <span class="token function">select</span><span class="token punctuation">(</span><span class="token keyword">int</span> maxfd<span class="token punctuation">,</span> fd_set <span class="token operator">*</span>readset<span class="token punctuation">,</span> fd_set <span class="token operator">*</span>writeset<span class="token punctuation">,</span> fd_set <span class="token operator">*</span>exceptset<span class="token punctuation">,</span> <span class="token keyword">const</span> <span class="token keyword">struct</span> <span class="token class-name">timeval</span> <span class="token operator">*</span>timeout<span class="token punctuation">)</span><span class="token punctuation">;</span>返回：若有就绪描述符则为其数目，若超时则为<span class="token number">0</span>，若出错则为<span class="token operator">-</span><span class="token number">1</span></code></pre><p>在这个函数中，maxfd 表示的是待测试的描述符基数，它的值是待测试的最大描述符加 1。</p><p>紧接着的是三个描述符集合，分别是读描述符集合 readset、写描述符集合 writeset 和异常描述符集合 exceptset，这三个分别通知内核，在哪些描述符上检测数据可以读，可以写和有异常发生。</p><p>这些描述符集合的控制可以使用下面的宏：</p><pre class="language-c" data-language="c"><code class="language-c"><span class="token keyword">void</span> <span class="token function">FD_ZERO</span><span class="token punctuation">(</span>fd_set <span class="token operator">*</span>fdset<span class="token punctuation">)</span><span class="token punctuation">;</span>　　　　　　<span class="token keyword">void</span> <span class="token function">FD_SET</span><span class="token punctuation">(</span><span class="token keyword">int</span> fd<span class="token punctuation">,</span> fd_set <span class="token operator">*</span>fdset<span class="token punctuation">)</span><span class="token punctuation">;</span>　　<span class="token keyword">void</span> <span class="token function">FD_CLR</span><span class="token punctuation">(</span><span class="token keyword">int</span> fd<span class="token punctuation">,</span> fd_set <span class="token operator">*</span>fdset<span class="token punctuation">)</span><span class="token punctuation">;</span>　　　<span class="token keyword">int</span>  <span class="token function">FD_ISSET</span><span class="token punctuation">(</span><span class="token keyword">int</span> fd<span class="token punctuation">,</span> fd_set <span class="token operator">*</span>fdset<span class="token punctuation">)</span><span class="token punctuation">;</span></code></pre><p>关于这些宏可以这样理解，把描述符集合想象为一个向量（数组），这个向量的每个元素都是二进制数中的 0 或者 1：</p><pre class="language-c" data-language="c"><code class="language-c">a<span class="token punctuation">[</span>maxfd<span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">,</span> a<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> a<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span></code></pre><p>那么：</p><ul><li><p>FD_ZERO 用来将这个向量的所有元素都设置成 0；</p></li><li><p>FD_SET 用来把对应套接字 fd 的元素，a[fd]设置成 1；</p></li><li><p>FD_CLR 用来把对应套接字 fd 的元素，a[fd]设置成 0；</p></li><li><p>FD_ISSET 对这个向量进行检测，判断出对应套接字的元素 a[fd]是 0 还是 1。</p></li></ul><p>其中 0 代表不需要处理，1 代表需要处理。</p><h3 id="poll"><a href="#poll" class="headerlink" title="poll"></a>poll</h3><h4 id="poll-函数介绍"><a href="#poll-函数介绍" class="headerlink" title="poll 函数介绍"></a>poll 函数介绍</h4><p>poll 是除了 select 之外，另一种普遍使用的 I/O 多路复用技术，和 select 相比，它和内核交互的数据结构有所变化，另外，也突破了文件描述符的个数限制。poll函数原型：</p><pre class="language-c" data-language="c"><code class="language-c"><span class="token keyword">int</span> <span class="token function">poll</span><span class="token punctuation">(</span><span class="token keyword">struct</span> <span class="token class-name">pollfd</span> <span class="token operator">*</span>fds<span class="token punctuation">,</span> <span class="token keyword">unsigned</span> <span class="token keyword">long</span> nfds<span class="token punctuation">,</span> <span class="token keyword">int</span> timeout<span class="token punctuation">)</span><span class="token punctuation">;</span> 　　　返回值：若有就绪描述符则为其数目，若超时则为<span class="token number">0</span>，若出错则为<span class="token operator">-</span><span class="token number">1</span></code></pre><p>这个函数里面输入了三个参数，第一个参数是一个 pollfd 的数组。其中 pollfd 的结构如下：</p><pre class="language-c" data-language="c"><code class="language-c"><span class="token keyword">struct</span> <span class="token class-name">pollfd</span> <span class="token punctuation">&#123;</span>    <span class="token keyword">int</span>    fd<span class="token punctuation">;</span>       <span class="token comment">/* file descriptor */</span>    <span class="token keyword">short</span>  events<span class="token punctuation">;</span>   <span class="token comment">/* events to look for */</span>    <span class="token keyword">short</span>  revents<span class="token punctuation">;</span>  <span class="token comment">/* events returned */</span> <span class="token punctuation">&#125;</span><span class="token punctuation">;</span></code></pre><p>pollfd结构包含了要监视的event和发生的event，不再使用select“参数-值”传递的方式。同时，pollfd并没有最大数量限制（但是数量过大后性能也是会下降）。 和select函数一样，poll返回后，需要轮询pollfd来获取就绪的描述符。</p><blockquote><p>从上面看，select和poll都需要在返回后，<code>通过遍历文件描述符来获取已经就绪的socket</code>。事实上，同时连接的大量客户端在一时刻可能只有很少的处于就绪状态，因此随着监视的描述符数量的增长，其效率也会线性下降。##</p></blockquote><h3 id="epoll"><a href="#epoll" class="headerlink" title="epoll"></a>epoll</h3><p>这张图可以更直观的观察这三种多路复用的性能优劣：</p><p><img src="https://raw.githubusercontent.com/zzugzj/blogImg/master/img/fd2e25f72a5103ef78c05c7ad2dab060.png" alt="img" loading="lazy"></p><h4 id="epoll的用法"><a href="#epoll的用法" class="headerlink" title="epoll的用法"></a>epoll的用法</h4><p>epoll 可以说是和 poll 非常相似的一种 I/O 多路复用技术。epoll 通过监控注册的多个描述字，来进行 I/O 事件的分发处理。不同于 poll 的是，epoll 不仅提供了默认的 level-triggered（条件触发）机制，还提供了性能更为强劲的 edge-triggered（边缘触发）机制。</p><p>使用 epoll 进行网络程序的编写，需要三个步骤，分别是 epoll_create，epoll_ctl 和 epoll_wait。</p><h5 id="epoll-create"><a href="#epoll-create" class="headerlink" title="epoll_create"></a>epoll_create</h5><pre class="language-c" data-language="c"><code class="language-c"><span class="token keyword">int</span> <span class="token function">epoll_create</span><span class="token punctuation">(</span><span class="token keyword">int</span> size<span class="token punctuation">)</span><span class="token punctuation">;</span></code></pre><p>epoll_create() 方法创建了一个 epoll 实例。这个 epoll 实例被用来调用 epoll_ctl 和 epoll_wait，如果这个 epoll 实例不再需要，比如服务器正常关机，需要调用 close() 方法释放 epoll 实例，这样系统内核可以回收 epoll 实例所分配使用的内核资源。</p><p>关于参数 size，在一开始的 epoll_create 实现中，是用来告知内核期望监控的文件描述字的数量，然后内核使用这部分的信息来初始化内核数据结构，在新的实现中，这个参数不再被需要，因为内核可以动态分配需要的内核数据结构。我们只需要注意，每次将 size 设置成一个大于 0 的整数就可以了。</p><h5 id="epoll-ctl"><a href="#epoll-ctl" class="headerlink" title="epoll_ctl"></a>epoll_ctl</h5><pre class="language-c" data-language="c"><code class="language-c"><span class="token keyword">int</span> <span class="token function">epoll_ctl</span><span class="token punctuation">(</span><span class="token keyword">int</span> epfd<span class="token punctuation">,</span> <span class="token keyword">int</span> op<span class="token punctuation">,</span> <span class="token keyword">int</span> fd<span class="token punctuation">,</span> <span class="token keyword">struct</span> <span class="token class-name">epoll_event</span> <span class="token operator">*</span>event<span class="token punctuation">)</span><span class="token punctuation">;</span>       返回值<span class="token operator">:</span> 若成功返回<span class="token number">0</span>；若返回<span class="token operator">-</span><span class="token number">1</span>表示出错</code></pre><p>调用 epoll_ctl 可以往这个 epoll 实例增加或删除监控的事件。</p><p>第一个参数 epfd 是刚刚调用 epoll_create 创建的 epoll 实例描述字，可以简单理解成是 epoll 句柄。</p><p>第二个参数表示增加还是删除一个监控事件，它有三个选项可供选择：添加EPOLL_CTL_ADD，删除EPOLL_CTL_DEL，修改EPOLL_CTL_MOD。分别添加、删除和修改对fd的监听事件。</p><p>第三个参数是注册的事件的文件描述符，比如一个监听套接字。</p><p>第四个参数表示的是注册的事件类型，并且可以在这个结构体里设置用户需要的数据，其中最为常见的是使用联合结构里的 fd 字段，表示事件所对应的文件描述符。</p><pre class="language-c" data-language="c"><code class="language-c"><span class="token keyword">typedef</span> <span class="token keyword">union</span> epoll_data <span class="token punctuation">&#123;</span>     <span class="token keyword">void</span>        <span class="token operator">*</span>ptr<span class="token punctuation">;</span>     <span class="token keyword">int</span>          fd<span class="token punctuation">;</span>     <span class="token class-name">uint32_t</span>     u32<span class="token punctuation">;</span>     <span class="token class-name">uint64_t</span>     u64<span class="token punctuation">;</span> <span class="token punctuation">&#125;</span> <span class="token class-name">epoll_data_t</span><span class="token punctuation">;</span> <span class="token keyword">struct</span> <span class="token class-name">epoll_event</span> <span class="token punctuation">&#123;</span>     <span class="token class-name">uint32_t</span>     events<span class="token punctuation">;</span>      <span class="token comment">/* Epoll events */</span>     <span class="token class-name">epoll_data_t</span> data<span class="token punctuation">;</span>        <span class="token comment">/* User data variable */</span> <span class="token punctuation">&#125;</span><span class="token punctuation">;</span><span class="token comment">//events可以是以下几个宏的集合：</span>EPOLLIN：表示对应的文件描述字可以读；EPOLLOUT：表示对应的文件描述字可以写；EPOLLRDHUP：表示套接字的一端已经关闭，或者半关闭；EPOLLHUP：表示对应的文件描述字被挂起；EPOLLET：设置为 edge<span class="token operator">-</span>triggered，默认为 level<span class="token operator">-</span>triggered。<span class="token punctuation">(</span>边缘触发、水平触发<span class="token punctuation">)</span></code></pre><h5 id="epoll-wait"><a href="#epoll-wait" class="headerlink" title="epoll_wait"></a>epoll_wait</h5><pre class="language-c" data-language="c"><code class="language-c"><span class="token keyword">int</span> <span class="token function">epoll_wait</span><span class="token punctuation">(</span><span class="token keyword">int</span> epfd<span class="token punctuation">,</span> <span class="token keyword">struct</span> <span class="token class-name">epoll_event</span> <span class="token operator">*</span>events<span class="token punctuation">,</span> <span class="token keyword">int</span> maxevents<span class="token punctuation">,</span> <span class="token keyword">int</span> timeout<span class="token punctuation">)</span><span class="token punctuation">;</span>  返回值<span class="token operator">:</span> 成功返回的是一个大于<span class="token number">0</span>的数，表示事件的个数；返回<span class="token number">0</span>表示的是超时时间到；若出错返回<span class="token operator">-</span><span class="token number">1.</span></code></pre><p>epoll_wait() 函数类似之前的 poll 和 select 函数，调用者进程被挂起，在等待内核 I/O 事件的分发。</p><p>这个函数的第一个参数是 epoll 实例描述字，也就是 epoll 句柄。</p><p>第二个参数返回给用户空间需要处理的 I/O 事件，这是一个数组，数组定义的大小就是maxevents，==数组含义元素的数目由 epoll_wait 的返回值决定==，这个数组的每个元素都是一个需要待处理的 I/O 事件，其中 events 表示具体的事件类型，事件类型取值和 epoll_ctl 可设置的值一样，这个 epoll_event 结构体里的 data 值就是在 epoll_ctl 那里设置的 data，也就是用户空间和内核空间调用时需要的数据。</p><p>第三个参数是一个大于 0 的整数，表示 epoll_wait 可以返回的最大事件值。</p><p>第四个参数是 epoll_wait 阻塞调用的超时值，如果这个值设置为 -1，表示不超时；如果设置为 0 则立即返回，即使没有任何 I/O 事件发生。</p><h5 id="edge-triggered-VS-level-triggered"><a href="#edge-triggered-VS-level-triggered" class="headerlink" title="edge-triggered VS level-triggered"></a>edge-triggered VS level-triggered</h5><p>　　<strong>LT模式</strong>：当epoll_wait检测到描述符事件发生并将此事件通知应用程序，<code>应用程序可以不立即处理该事件</code>。下次调用epoll_wait时，会再次响应应用程序并通知此事件。<br>　　<strong>ET模式</strong>：当epoll_wait检测到描述符事件发生并将此事件通知应用程序，<code>应用程序必须立即处理该事件</code>。如果不处理，下次调用epoll_wait时，不会再次响应应用程序并通知此事件。</p><p>ET模式在很大程度上减少了epoll事件被重复触发的次数，因此效率要比LT模式高。epoll工作在ET模式的时候，必须使用非阻塞套接口，以避免由于一个文件句柄的阻塞读/阻塞写操作把处理多个文件描述符的任务饿死。</p><h5 id="epoll-的性能分析"><a href="#epoll-的性能分析" class="headerlink" title="epoll 的性能分析"></a>epoll 的性能分析</h5><p><strong>边缘触发和水平触发：</strong></p><p>如果某个套接字有 100 个字节可以读，边缘触发（edge-triggered）和条件触发（level-triggered）都会产生 read ready notification 事件，如果应用程序只读取了 50 个字节，边缘触发就会陷入等待；而条件触发则会因为还有 50 个字节没有读取完，不断地产生 read ready notification 事件。</p><p>在条件触发下（level-triggered），如果某个套接字缓冲区可以写，会无限次返回 write ready notification 事件，在这种情况下，如果应用程序没有准备好，不需要发送数据，一定需要解除套接字上的 ready notification 事件，否则 CPU 就直接跪了。</p><p>我们简单地总结一下，边缘触发只会产生一次活动事件，性能和效率更高。不过，程序处理起来要更为小心。</p><p><strong>epoll和poll/select的对比：</strong></p><p>poll/select 先将要监听的 fd 从用户空间拷贝到内核空间, 然后在内核空间里面进行处理之后，再拷贝给用户空间。这里就涉及到内核空间申请内存，释放内存等等过程，这在大量 fd 情况下，是非常耗时的。而 epoll 维护了一个红黑树，通过对这棵黑红树进行操作，可以避免大量的内存申请和释放的操作，而且查找速度非常快。</p><p>第二，select/poll 从休眠中被唤醒时，如果监听多个 fd，只要其中有一个 fd 有事件发生，内核就会遍历内部的 list 去检查到底是哪一个事件到达，并没有像 epoll 一样, 通过 fd 直接关联 eventpoll 对象，快速地把 fd 直接加入到 eventpoll 的就绪列表中。</p><p>epoll 维护了一棵红黑树来跟踪所有待检测的文件描述字，黑红树的使用减少了内核和用户空间大量的数据拷贝和内存分配，大大提高了性能。</p><p>同时，epoll 维护了一个链表来记录就绪事件，内核在每个文件有事件发生时将自己登记到这个就绪事件列表中，通过内核自身的文件 file-eventpoll 之间的回调和唤醒机制，减少了对内核描述字的遍历，大大加速了事件通知和检测的效率，这也为 level-triggered 和 edge-triggered 的实现带来了便利。</p>]]></content>
    
    
    <summary type="html">同步（synchronous） IO和异步（asynchronous） IO，阻塞（blocking） IO和非阻塞（non-blocking）IO分别是什么，到底有什么区别？这个问题其实不同的人给出的答案都可能不同，比如wiki，就认为asynchronous IO和non-blocking IO是一个东西。</summary>
    
    
    
    <category term="网络编程" scheme="https://zzugzj.github.io/categories/%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B/"/>
    
    
    <category term="IO模型" scheme="https://zzugzj.github.io/tags/IO%E6%A8%A1%E5%9E%8B/"/>
    
  </entry>
  
  <entry>
    <title>是否要从整体架构开始</title>
    <link href="https://zzugzj.github.io/posts/483873e8/"/>
    <id>https://zzugzj.github.io/posts/483873e8/</id>
    <published>2021-07-25T13:25:15.073Z</published>
    <updated>2021-07-25T13:53:02.858Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><p><a href="https://martinfowler.com/bliki/MonolithFirst.html">原文</a>     <a href="https://www.cnblogs.com/rainisic/articles/5203149.html">译文</a></p><h2 id="整体架构先行（Monolith-first）"><a href="#整体架构先行（Monolith-first）" class="headerlink" title="整体架构先行（Monolith first）"></a>整体架构先行（Monolith first）</h2><p>在我所听说的使用微服务架构（Microservices Architecture）的团队里，有这么一些共性：</p><ol><li>绝大多数微服务的成功案例，都是从整体架构（Monolith）开始的。并且由于整体架构过于庞大，导致架构无法继续支撑。</li><li>绝大多数我所听说的系统，如果从一开始就使用微服务架构，最终都遇到了很严重的问题。</li></ol><p>这个规律导致我的同僚们认为，<strong>并不应该从项目一开始就使用微服务架构，即便你能够保证你的应用足够大，以至于使用微服务架构是值得的</strong>。</p><p>微服务是一个很有用的系统架构，但是即便是它的支持者，也会承认这将导致一个巨额的<a href="http://martinfowler.com/bliki/MicroservicePremium.html">微服务额外代价</a>，这意味着，只在极为复杂的系统中微服务架构才能发挥作用。这巨额代价的本质实际上是对一系列服务进行管理的开销，对于简单的应用来说，整体架构反而更加有利。这成为了整体架构先行（monolith-first）策略的一个有力的论据——在创建一个新的应用的时候，即便你认为在将来它将更适合采用微服务架构，你在最初仍然应该先采用整体架构。</p><p>第一个原因是，这是一个典型的 <a href="http://martinfowler.com/bliki/Yagni.html">YAGNI</a>（You Aren’t Gonna Need It）。当你开始创建一个新应用的时候，你怎么知道他会对你的用户有用？你的应用可能设计的很难被扩展，却能出色的完成任务。但总比你得到一个能够轻易被扩展，却无法正常工作的系统强得多。</p><p>微服务的第二个问题是，只有当你提出一个良好的、服务边界稳定的设计，他才能良好的运行。这就意味着，你需要拟定一套正确的<a href="http://martinfowler.com/bliki/BoundedContext.html">边界上下文</a>。服务间的功能性重构相比整体架构而言都将变得更加复杂。但是，即便是经验丰富的架构师，在熟悉的领域，在一开始也很难制定出完全正确的系统边界。通过采用整体架构先行设计，在微服务架构前，能够先找出正确的系统边界。并且，先进行整体架构设计能够给你充足的时间，让你做好细粒度微服务的<a href="http://martinfowler.com/bliki/MicroservicePrerequisites.html">前提准备</a>。</p><p>我听说过很多种方法去进行整体架构先行的架构策略。理论上的做法是，小心谨慎的进行整体架构设计，无论是 API 边界还是数据存储，都要注重模块化。专注于这些，相较于迁移至微服务架构，要简单的多。但是现在并没有足够的案例证明这种方法能够行之有效。</p><p>更常见的方法是，开始采用整体架构，然后逐渐将边缘部分剥离为微服务。这种方法将会在微服务架构的核心处，留下一个独立的整体架构。但相较于大量出现的微服务而言，整体架构部分处于相对稳定状态。</p><p>我还见过一种方法，在项目开始初期只做一些粗粒度的服务，这些粗粒度服务要比期望的最终服务单元大一些，通过这些粗粒度的服务来习惯多服务合作的模式。这种方式降低了内部服务重构导致的代价。当服务边界稳定后，再将其拆分为更细粒度的服务。</p><p>虽然我所接触的人大多倾向于整体架构先行的方式，但也并不是所有人都这么认为。这些人反对的理由是，从一开始就采用微服务架构，能够让你更快的适应微服务架构的开发节奏。如果要构建一个模块化的整体架构，并且需要让其在未来能够很容易的拆分为微服务，将会付出较大乃至极大的代价。如果从一开始就采用微服务架构，团队中的每个人从一开始就习惯于在一个个独立的小团队中进行开发，并且，当你需要扩张时，独立的服务边界将会让其变得更加简单。如果能够提前制定出足够稳定的系统边界，这将具有极强的可行性。虽然我没有足够的证据，但是我依然认为，如果你没有合理构建微服务系统的经验，不要一开始就采用微服务架构。</p><p>我还没有足够的案例来决定是否使用整体架构先行的策略。我们对微服务的认识尚属早期，我们针对微服务架构案例的学习也相对较少。所以任何人针对这个话题的建议都只是临时性的，大家的争论也只是出自自信而非经验。</p>]]></content>
    
    
    <summary type="html">微服务是一个很有用的系统架构，但是即便是它的支持者，也会承认这将导致一个巨额的微服务额外代价，这意味着，只在极为复杂的系统中微服务架构才能发挥作用。这巨额代价的本质实际上是对一系列服务进行管理的开销，对于简单的应用来说，整体架构反而更加有利。这成为了整体架构先行（monolith-first）策略的一个有力的论据——在创建一个新的应用的时候，即便你认为在将来它将更适合采用微服务架构，你在最初仍然应该先采用整体架构。</summary>
    
    
    
    <category term="微服务" scheme="https://zzugzj.github.io/categories/%E5%BE%AE%E6%9C%8D%E5%8A%A1/"/>
    
    
    <category term="MartinFlower文章笔记" scheme="https://zzugzj.github.io/tags/MartinFlower%E6%96%87%E7%AB%A0%E7%AC%94%E8%AE%B0/"/>
    
  </entry>
  
  <entry>
    <title>权衡微服务</title>
    <link href="https://zzugzj.github.io/posts/2efefcae/"/>
    <id>https://zzugzj.github.io/posts/2efefcae/</id>
    <published>2021-07-25T12:29:31.271Z</published>
    <updated>2021-07-25T13:53:02.857Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><p><a href="https://martinfowler.com/articles/microservice-trade-offs.html">原文</a>     <a href="https://www.cnblogs.com/savorboard/p/microservices.html">译文</a></p><h2 id="微服务的优势"><a href="#微服务的优势" class="headerlink" title="微服务的优势"></a>微服务的优势</h2><h3 id="具有边界的健壮模块"><a href="#具有边界的健壮模块" class="headerlink" title="具有边界的健壮模块"></a>具有边界的健壮模块</h3><p>有边界的模块化业务，可以随着团队规模的扩大而陆续增加。</p><p>微服务最大的好处就是功能模块的划分，彼此可以分离解耦，我想要修改某一部分，只需要弄清楚这个小模块，做些改动。</p><p>模块虽然可以解耦，但由于模块间的边界，也造成了一些引用的障碍。单体系统虽然可以很容易的绕过这个障碍，但也会削弱模块的结构和降低团队生产力，所以将模块放入独立的服务，可以使这种自杀式的解决方案难以实现。</p><p>在一个单体系统中，使用模块化完全可能，但是它需要纪律来保证。使用微服务，可以实现更好的模块化。</p><p>另外，微服务的一个好处就是，和单体架构相比，团队更容易扩张，在项目初期使用微服务，到需要人手的时候，就可以让一大批人涌入。但缺点是可以耗费了更多的人力。</p><h3 id="独立部署"><a href="#独立部署" class="headerlink" title="独立部署"></a>独立部署</h3><p>服务的部署更加简单容易，另外，因为每个微服务是独立的，所以其中一个出问题不会影响到整个系统。</p><p>微服务的一个关键原则是， <a href="http://martinfowler.com/articles/microservices.html#ComponentizationViaServices">每个服务都是系统的一个组件</a>，均可独立部署。所以现在当你做出改变时，你只需要测试和部署一个小服务。如果你把它搞砸了，你不会把整个系统都搞砸。毕竟，事先对故障进行了设计，即使失败了，你的组件也不应该停止其他部分的系统工作，尽管功能上有些退化。</p><p>同时，许多服务也需要频繁的部署，那这时候的应用快速部署和快速配置（自动化技术）也就成了微服务的先决条件。对任何以此为基础的服务，都需要持续交付。</p><p>持续交付的好处是减少了由想法变成软件的时间。那么，团队可以快速响应市场变化，并快于竞争对手先引入新的功能。</p><h3 id="技术的多样性"><a href="#技术的多样性" class="headerlink" title="技术的多样性"></a>技术的多样性</h3><p>由于每个微服务都是一个独立的部署单元，你有相当的自由选择需要的技术。微服务可以用不同的语言，使用不同的库，并使用不同的数据存储方式。这使得团队可以选择合适的工具来工作，有些语言和库更适合某些类型的问题。</p><p>微服务另外一个好处就是版本问题（我理解的是pom依赖）。单体应用一般使用单一的版本库，这种情况经常会导致版本库升级出问题，系统的一部分可能需要升级，来实现使用它的新功能，但不能因为升级而中断系统的另一部分。处理库的版本问题是其中的一个难题，因为随着代码库的增大，难度会呈指数级增长。</p><p>用单体架构系统，早期对语言和框架的决定是很难逆转的。经过十年左右，这些的决定可能会限制团队并使团队陷入尴尬的技术境地。微服务让团队尝试新工具，并逐步一次迁移系统的一个服务，使新老技术有所关联。</p><h2 id="微服务的附加成本"><a href="#微服务的附加成本" class="headerlink" title="微服务的附加成本"></a>微服务的附加成本</h2><h3 id="分布式"><a href="#分布式" class="headerlink" title="分布式"></a>分布式</h3><p>分布式系统编程相对困难，因为远程调用慢，所以可能总是会存在失败的风险。</p><p>微服务采用分布式系统来提高模块化。但是分布式软件有一个主要的缺陷，就是分布式系统本身。</p><p>首先是性能，微服务使用远程调用的方式来进行信息的传递，如果服务调用了一些远程服务，远程服务又调用了其他的远程服务，这些时间加起来，延迟也是很久的。但也可以降低延迟，第一种方法是使用粗粒度的API，减少调用的数目，但也会使程序变复杂。第二种方法就是使用异步通信。如果六个服务异步并行调用，延迟只会是那个最慢的调用，而不是所有调用延迟的总和。这大大改善了性能，但也带来了认知成本。异步编程很难，你很难用好它，而且很难调试。</p><p>速度之后就是可靠性的问题。你期望in-process函数调用能够成功，可是一个远程调用可能在任何时间失败。在很多的微服务中，甚至有很多的潜在的故障点。</p><h3 id="最终一致性"><a href="#最终一致性" class="headerlink" title="最终一致性"></a>最终一致性</h3><p>在分布式系统中，保持强一致性是非常困难的，所以必须要处理最终一致性。</p><p>在分布式系统上，存在这种情况，更新被节点P收到，请求却被另一个节点G处理。直到节点G从节点P那儿得到更新之前，一直处于数据不一致的状态，虽然最终会变成一致的，但业务逻辑可能会停滞在对不一致的信息上做出决策，当这种事发生时，就比较麻烦。</p><p>微服务带来了最终一致性的问题，是因为他们坚持对去中心的数据管理。单体架构在这些问题上同样不能全身而退。随着系统的增长，更需要使用缓存来提高性能，缓存失效是 <a href="http://martinfowler.com/bliki/TwoHardThings.html">另一个困难的问题</a>。</p><h3 id="操作复杂性"><a href="#操作复杂性" class="headerlink" title="操作复杂性"></a>操作复杂性</h3><p>你需要一个经验丰富的运营团队来管理很多需要定时重新部署的服务。</p><p>当单体应用变成几百个微服务的时候，迅速部署独立的小单位成了运维的福音，但也增加了额外的复杂度。</p><p>持续交付在单体应用和微服务中一样重要。没有自动化协作，持续交付也无法处理那么多的服务。运维的复杂性也是由管理这些服务和监控的需求的增加而增加。</p><p>处理这种运维复杂度，需要一个新的技能和工具——重点是技能。工具仍然是不成熟的。要想高效解决这个问题，需要引入一个DevOps文化：开发者和运维之间的紧密合作，每个人都参与软件交付。</p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>单体架构和微服务并不是简单的二选一。两者都是模糊的定义，意味着大多数系统都将在一个模糊的边界区域。当然也还有其他系统，不适合这两个类别的。大多数人，讨论微服务时用单体架构作对比，这是因为它们更常见，但我们必须记住，还是有系统不属于这两类的。我认为，单体架构和微服务是架构设计领域重要的两部分。它们值得被讨论，因为它们存在有趣的特性，以及有用的讨论，但是没有合适的架构师可以对它们在架构设计领域进行一个全面的区分。</p><p>总结起来，微服务的好处：微服务提高了生产效率，但同时也带来了复杂性。所以如果可以用单体架构管理好系统，那么就无需微服务。</p><p>对微服务的讨论不应该让我们忘记了更重要的问题，驱动软件项目成功和失败的重要因素。软因素如团队中人的素质，以及他们如何彼此合作，与领域专家的沟通能力，这都会对是否使用微服务有更加的影响。在纯技术层面上来讲，更重要的是把重点放在干净的代码、完善的测试，并持续关注架构的演化进步。</p>]]></content>
    
    
    <summary type="html">很多开发团队已经认识到 微服务架构比单体架构更优越。但是也有其他团队感觉到这是一种消弱生产力的负担。就像任何软件架构，微服务架构同样有利弊。为了能做出一个明智的选择，你必须了解这些应用并将它们运用到你特定的环境中。</summary>
    
    
    
    <category term="微服务" scheme="https://zzugzj.github.io/categories/%E5%BE%AE%E6%9C%8D%E5%8A%A1/"/>
    
    
    <category term="MartinFlower文章笔记" scheme="https://zzugzj.github.io/tags/MartinFlower%E6%96%87%E7%AB%A0%E7%AC%94%E8%AE%B0/"/>
    
  </entry>
  
  <entry>
    <title>Microservice</title>
    <link href="https://zzugzj.github.io/posts/6f3f7b57/"/>
    <id>https://zzugzj.github.io/posts/6f3f7b57/</id>
    <published>2021-07-25T10:15:02.078Z</published>
    <updated>2023-11-05T05:54:19.556Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>本文是读<a href="https://martinfowler.com/articles/microservices.html">微服务</a>(<a href="https://mp.weixin.qq.com/s?__biz=MjM5MjEwNTEzOQ==&mid=401500724&idx=1&sn=4e42fa2ffcd5732ae044fe6a387a1cc3#rd">翻译链接</a>)的笔记。</p><h3 id="微服务与单块应用的对比"><a href="#微服务与单块应用的对比" class="headerlink" title="微服务与单块应用的对比"></a>微服务与单块应用的对比</h3><p>单块应用：一个单块应用系统是以一个单个单元的方式来构建的。企业应用系统经常包含三个主要部分：客户端用户界面、数据库和服务端应用系统。客户端用户界面包括HTML页面和运行在用户机器的浏览器中的JavaScript。数据库中包括许多表，这些表被插入一个公共的且通常为关系型的数据库管理系统中。这个服务端的应用系统就是一个单块应用——一个单个可执行的逻辑程序。对于该系统的任何改变，都会涉及构建和部署上述服务端应用系统的一个新版本。</p><p>微服务：以构建一组小型服务的方式来构建应用系统。除了这些服务能被独立地部署和扩展，每一个服务还能提供一个稳固的模块边界，甚至能允许使用不同的编程语言来编写不同的服务。这些服务也能被不同的团队来管理。</p><p><img src="https://raw.githubusercontent.com/zzugzj/blogImg/master/img/6401.webp" alt="6401" loading="lazy"></p><h3 id="微服务架构的九大特性"><a href="#微服务架构的九大特性" class="headerlink" title="微服务架构的九大特性"></a>微服务架构的九大特性</h3><p>微服务风格还未被正式的定义，但是也总结了微服务架构的共性。这些共性并不是所有的微服务架构都完全具备，但期望大多数微服务架构都具备这些共性中的大多数特性。</p><h4 id="特性一：“组件化”与“多服务”"><a href="#特性一：“组件化”与“多服务”" class="headerlink" title="特性一：“组件化”与“多服务”"></a>特性一：“组件化”与“多服务”</h4><p>组件化，就是将一堆组件结合在一起就可以构建成一个系统。</p><p>什么是组件？我们的定义是，一个<strong>组件</strong>就是一个可以独立更换和升级的软件单元。</p><p>我们将<strong>软件库</strong>(libraries)定义为这样的组件，即它能被链接到一段程序，且能通过内存中的函数来进行调用。然而，<strong>服务</strong>(services)是进程外的组件，它们通过诸如web service请求或远程过程调用这样的机制来进行通信。</p><p>由于服务可以独立部署，所以使用服务的方式来实现组件化。</p><p>如果一个应用系统由在单个进程中的多个软件库所组成，那么对任一组件做一处修改，都不得不重新部署整个应用系统。但是如果该应用系统被分解为多个服务，那么对于一个服务的多处修改，仅需要重新部署这一个服务。</p><p>通过多服务的方式来构建系统也有不足之处，比起进程内调用，远程调用更加昂贵。所以远程调用API接口必须是粗粒度的，而这往往更加难以使用。如果需要修改组件间的职责分配，那么当跨越进程边界时，这种组件行为的改动会更加难以实现。</p><h4 id="特性二：围绕“业务功能”组织团队"><a href="#特性二：围绕“业务功能”组织团队" class="headerlink" title="特性二：围绕“业务功能”组织团队"></a>特性二：围绕“业务功能”组织团队</h4><blockquote><p><em>任何设计（广义上的）系统的组织，都会产生这样一个设计，即该设计的结构与该组织的沟通结构相一致。</em></p><p>​                <em>——梅尔文•康威（Melvyn Conway）, 1967年</em></p></blockquote><p>根据康威定律，当面对一个大型的应用系统时，管理层会根据目前的组织架构来分解系统：前端团队负责用户界面，后端团队负责后端服务，数据库团队负责数据库运维，一个根据组织架构而产生的设计架构应运而生——又一个单体怪物的雏形开始孕育。</p><p>微服务使用不同的方法来分解系统，即根据<strong>业务功能</strong>（business capability）来将系统分解为若干服务。这些服务针对该业务领域提供多层次广泛的软件实现，包括用户界面、持久性存储以及任何对外的协作性操作。因此，团队是跨职能的，它拥有软件开发所需的全方位的技能：用户体验、数据库和项目管理。</p><h4 id="特性三：“做产品”而不是“做项目”"><a href="#特性三：“做产品”而不是“做项目”" class="headerlink" title="特性三：“做产品”而不是“做项目”"></a>特性三：“做产品”而不是“做项目”</h4><p>传统 开发模式是项目模式：目标是交付某一块软件，之后就认为完工了。一旦完工后，软件就被移交给维护团队，接着那个构建该软件的项目团队就会被解散。</p><p>微服务的支持者们倾向于避免使用上述模型，而宁愿采纳“一个团队在一个产品的整个生命周期中都应该保持对其拥有”这样的理念。通常认为这一点源自亚马逊的“谁构建，谁运行”的理念，即一个开发团队对一个在生产环境下运行的软件负全责。这会使开发人员每天都会关注软件是如何在生产环境下运行的，并且增进他们与用户的联系，因为他们必须承担某些支持工作。</p><h4 id="特性四：“智能端点”与“傻瓜管道”"><a href="#特性四：“智能端点”与“傻瓜管道”" class="headerlink" title="特性四：“智能端点”与“傻瓜管道”"></a>特性四：“智能端点”与“傻瓜管道”</h4><p>微服务需要在不同的进程间建立通信，一般采用智能端点(smart endpoints)和傻瓜管道(dumb pipes)。</p><p>微服务构建的应用都尽可能的实现一个目标：高内聚和低耦合。微服务内部拥有独立而完整的业务逻辑，微服务之间像管道（Pipe）那样传递消息流。这种模式就像经典的Unix系统上过滤器（filter）的工作机制，接收请求，按照业务逻辑进行处理，最后产生响应消息。</p><p>智能端点就是指拥有独立而完整的业务逻辑的微服务，它们从管道上获取消息，进行智能处理，然后产生处理后的消息，放回管道。</p><p>傻瓜管道就是指连接微服务进行消息传递的通信机制，它们只负责消息流的传送，不承载更多的关于业务逻辑上的分析和处理。</p><p>将一个单块系统改造为若干微服务的最大问题，在于对通信模式的改变。仅仅将内存中的方法调用转换为RPC调用这样天真的做法，会导致微服务之间产生繁琐的通信，使得系统表现变糟。取而代之的是，需要用更粗粒度的协议来替代细粒度的服务间通信。</p><h4 id="特性五：“去中心化”地治理技术"><a href="#特性五：“去中心化”地治理技术" class="headerlink" title="特性五：“去中心化”地治理技术"></a>特性五：“去中心化”地治理技术</h4><p>使用中心化的方式对开发进行治理，其中一个后果，就是趋向于在单一技术平台上制定标准。不同的问题有不同的解决方案。</p><p>如果能将单块应用的那些组件拆分成多个服务，那么在构建每个服务时，就可以有选择不同技术栈的机会。</p><h4 id="特性六：“去中心化”地管理数据"><a href="#特性六：“去中心化”地管理数据" class="headerlink" title="特性六：“去中心化”地管理数据"></a>特性六：“去中心化”地管理数据</h4><p>传统的应用系统使用一个中心的数据库来管理数据，这样方便事务操作，可以保证数据的一致性。</p><p>微服务主张去中心化的来部署数据库，也就是让每一个服务来管理自己的数据库。但这样部署数据库的话，对一致性将是一个很大的挑战，通常情况下，为了快速响应需求，只能一定程度上让数据“非一致性”，来通过做某种反向过程进行错误处理。只要修复错误的成本，与在保持更大的数据一致性却导致丢了生意所产生的成本相比，前者更低，那么这种“非一致性”地管理数据的权衡就是值得的。</p><p><img src="https://raw.githubusercontent.com/zzugzj/blogImg/master/img/641.webp" alt="641" loading="lazy"></p><h4 id="特性七：“基础设施”自动化"><a href="#特性七：“基础设施”自动化" class="headerlink" title="特性七：“基础设施”自动化"></a>特性七：“基础设施”自动化</h4><p>微服务与自动化技术密不可分，云的演进，特别是AWS的发展，已经降低了构建、部署和运维微服务的操作复杂性。</p><p>采用微服务的架构，意味着可能有几十上百的服务被划分出来，相对于之前的单体应用来说，微服务系统在构建、部署和运维上要复杂的多，单靠人工操作，将会很麻烦。</p><p>自动化部署的流水线：</p><p><img src="https://raw.githubusercontent.com/zzugzj/blogImg/master/img/642.webp" alt="642" loading="lazy"></p><h4 id="特性八：“容错”设计"><a href="#特性八：“容错”设计" class="headerlink" title="特性八：“容错”设计"></a>特性八：“容错”设计</h4><p>使用各个微服务来替代组件，其结果是各个应用程序需要设计成能够容忍这些服务所出现的故障。如果服务提供方不可用，那么任何对该服务的调用都会出现故障。</p><p>因为各个服务可以在任何时候发生故障，所以下面两件事就变得很重要，即能够快速地检测出故障，而且在可能的情况下能够自动恢复服务。</p><p>那当服务提供方不可用时，客户端如何优雅的应对这种情况？</p><p>具体的应对措施有以下几种：</p><ol><li>网络超时：当等待响应时，不要无限期的阻塞，而是采用超时策略。使用超时策略可以确保资源不会无限期的占用。</li><li>限制请求的次数：可以为客户端对某特定服务的请求设置一个访问上限。如果请求已达上限,就要立刻终止请求服务。</li><li>断路器模式：记录成功和失败请求的数量。如果失效率超过一个阈值，触发断路器使得后续的请求立刻失败。如果大量的请求失败，就可能是这个服务不可用，再发请求也无意义。在一个失效期后，客户端可以再试，如果成功，关闭此断路器。</li><li>提供回滚：当一个请求失败后可以进行回滚逻辑。例如，返回缓存数据或者一个系统默认值。</li></ol><h4 id="特性九：“演进式”设计"><a href="#特性九：“演进式”设计" class="headerlink" title="特性九：“演进式”设计"></a>特性九：“演进式”设计</h4><p>那些微服务的从业者们，通常具有演进式设计的背景，而且通常将服务的分解，视作一个额外的工具，来让应用开发人员能够控制应用系统中的变化，而无须减少变化的发生。</p><p>从一个单块系统作为起点，保持其模块化，当这个单块系统达到一定的规模，开始出现问题后，再将其拆分成微服务，是一个不错的开始。</p><p>当然，在系统演化的过程中，我们要考虑模块化和组件化，这是走向微服务之路的必要保证。一个组件的关键属性，是具有独立更换和升级的特点，想象一下，能够在一个点上重写该组件，而无须影响该组件的其它合作组件，是一个考虑组件是否独立更换和升级的好方法。</p>]]></content>
    
    
    <summary type="html">“微服务架构”这个术语最近几年横空出世，来描述这样一种特定的软件设计方法，即以若干组可独立部署的服务的方式进行软件应用系统的设计。尽管这种架构风格尚无精确的定义，但其在下述方面还是存在一定的共性，即围绕业务功能的组织、自动化部署、端点智能、和在编程语言和数据方面进行去中心化的控制。</summary>
    
    
    
    <category term="微服务" scheme="https://zzugzj.github.io/categories/%E5%BE%AE%E6%9C%8D%E5%8A%A1/"/>
    
    
    <category term="MartinFlower文章笔记" scheme="https://zzugzj.github.io/tags/MartinFlower%E6%96%87%E7%AB%A0%E7%AC%94%E8%AE%B0/"/>
    
  </entry>
  
  <entry>
    <title>REST原则六约束与Richardson成熟度模型</title>
    <link href="https://zzugzj.github.io/posts/d05c43b2/"/>
    <id>https://zzugzj.github.io/posts/d05c43b2/</id>
    <published>2021-05-21T15:13:49.000Z</published>
    <updated>2021-05-21T15:32:46.854Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><h3 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h3><p>REST即Representational State Transfer，表征状态转移。这里Representational被翻译成表述或表征，其含义在网络上存在各种模糊的解释。</p><p>Representational State Transfer中，它指的是什么呢？</p><p>在计算机领域“Representational”表述或表征的对象是一种资源，这里的资源具体一点可以指图片，视频，数据库中的字段等等，那么这种表述或表征就是定义这些资源的方式，那具体一点，就是JSON，XML这些描述资源的东西。“Representational”是个大的概念，它包括一切的这些JSON，XML的子集。</p><h3 id="REST原则六约束"><a href="#REST原则六约束" class="headerlink" title="REST原则六约束"></a>REST原则六约束</h3><p><strong>（1）Client–server 客户端-服务器模式</strong></p><p>信只能由客户端单方面发起，表现为请求-响应的形式。</p><p><strong>（2）Stateless 无状态</strong></p><p>通信的会话状态（Session State）应该全部由客户端负责维护。</p><p><strong>（3）Cacheable 可缓存</strong></p><p>响应内容可以在通信链的某处被缓存，以改善网络效率。</p><p><strong>（4）Layered system 分层系统</strong></p><p>通过限制组件的行为（即，每个组件只能“看到”与其交互的紧邻层），将架构分解为若干等级的层。</p><p><strong>（5）Code on demand (optional) 按需扩展代码（可选）</strong></p><p>支持通过下载并执行一些代码（例如Java Applet、Flash或JavaScript），对客户端的功能进行扩展。</p><p><strong>（6）Uniform interface 统一接口</strong></p><p>通信链的组件之间通过统一的接口相互通信，以提高交互的可见性。</p><h3 id="Richardson的REST成熟度模型"><a href="#Richardson的REST成熟度模型" class="headerlink" title="Richardson的REST成熟度模型"></a>Richardson的REST成熟度模型</h3><p>一个WEB服务有多么的“RESTful”，最有名的就是《RESTful Web Services》的合著者Leonard Richardson提出的REST成熟度模型，简称 Richardson成熟度模型！</p><p><strong>1）资源标识的唯一性（资源的标识） Identification of resources</strong></p><p>每个资源的资源标识可以用来唯一地标明该资源。<br>请求中的独立资源是可以被标识的，基于web的REST系统使用的URI就是典型的例子。资源在概念上是独立的，并由表述返回客户端。举例来说，服务器把数据库中的数据以HTML，XML 或者 JSON发送给客户端，而这些表述不是在服务中内置的。</p><p><strong>2）资源的自描述性（通过表述对资源执行的操作）Manipulation of resources through these representations</strong></p><p>一个REST系统所返回的资源需要能够描述自身，并提供足够的用于操作该资源的信息，如如何对资源进行添加，删除以及修改等操作。也就是说，一个典型的REST服务不需要额外的文档对如何操作资源进行说明。<br>当客户端抓取一个资源表述的时候，它都可以通过充足的信息来保证对资源的修改或者删除。</p><p><strong>3）消息的自描述性（自描述消息）Self-descriptive messages</strong></p><p>在REST系统中所传递的消息需要能够提供自身如何被处理的足够信息。例如该消息所使用的MIME类型，是否可以被缓存等。</p><p><strong>4）超媒体驱动性（超媒体作为应用状态的引擎）Hypermedia as the engine of application state</strong></p><p>即客户只可以通过服务端所返回各结果中所包含的信息来得到下一步操作所需要的信息，如：到底是向哪个URL发送请求等。也就是说，一个典型的REST服务不需要额外的文档标示通过哪些URL访问特定类型的资源，而是通过服务端返回的响应来标示到底能在该资源上执行什么样的操作。<br>一个REST服务的客户端也不需要知道任何有关哪里有什么样的资源这种信息。当客户端抓取一个资源表述的时候，它都可以通过充足的信息来保证对资源的修改或者删除。</p><p><strong>分级解释：</strong></p><ul><li><p><strong>第0级：使用HTTP作为传输方式；一个URI，一个HTTP方法</strong><br>SOAP、XML-RPM都属于这一级别，仅是来回传送”Plain Old XML”(POX)。即使没有显式调用RPC接口（SOAP、XML-RPM），通常会调用服务器端的一个处理过程。一个接口会有一个端点，文档的内容会被解析用还判断所要调用的处理过程及其参数。这种做法相当于把 HTTP 这个应用层协议降级为传输层协议用。HTTP 头和有效载荷是完全隔离的，HTTP 头只用于保证传输，不涉及业务逻辑；有效载荷包含全部业务逻辑，因此 API 可以无视 HTTP 头中的任何信息。</p></li><li><p><strong>第1级：引入了资源的概念，每个资源有对应的标识符和表达；多个URI，一个HTTP方法</strong><br>这些资源仍是被“GETful”接口操作而不是HTTP动词，服务基本上只提供操作这些资源。例如：<br>GET <a href="">http://example.com/app/createUser</a><br>GET <a href="">http://example.com/app/getUser?id=123</a><br>GET <a href="">http://example.com/app/changeUser?id=123&amp;field=value</a><br>GET <a href="">http://example.com/app/deleteUser?id=123</a></p></li><li><p><strong>第2级：根据语义使用HTTP动词，适当处理HTTP响应状态码；多个URI，多个HTTP方法</strong><br>在这一级别，资源名称为基URI的一部分，而不是查询参数。<br>GET（SELECT）：从服务器取出资源（一项或多项）。<br>POST（CREATE）：在服务器新建一个资源。<br>PUT（UPDATE）：在服务器更新资源（客户端提供改变后的完整资源）。<br>PATCH（UPDATE）：在服务器更新资源（客户端提供改变的属性）。<br>DELETE（DELETE）：从服务器删除资源。<br>HEAD：获取资源的元数据。<br>OPTIONS：获取信息，关于资源的哪些属性是客户端可以改变的。</p></li><li><p><strong>第3级：使用超媒体作为应用状态引擎（HATEOAS）；多个URI，多个HTTP方法</strong><br>特别注意，这里是超媒体（hypermedia），超媒体概念是包括超文本的。<br>我们已经知道什么是多媒体（multimedia），以及什么是超文本（hypertext）。其中超文本特有的优势是拥有超链接（hyperlink）。如果我们把超链接引入到多媒体当中去，那就得到了超媒体，因此关键角色还是超链接。使用超媒体作为应用引擎状态，意思是应用引擎的状态变更由客户端访问不同的超媒体资源驱动。</p></li></ul><p>Roy Fielding（REST论文的作者）说”只有使用了超媒体的才能算是 REST！，那么第 3 级成熟度以外的都不算 REST！</p>]]></content>
    
    
    <summary type="html">REST即Representational State Transfer，表述状态转移。这里Representational被翻译成表述或表征，其含义在网络上存在各种模糊的解释。</summary>
    
    
    
    <category term="网络编程" scheme="https://zzugzj.github.io/categories/%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B/"/>
    
    
    <category term="REST" scheme="https://zzugzj.github.io/tags/REST/"/>
    
  </entry>
  
  <entry>
    <title>InnoDB的锁和事务模型</title>
    <link href="https://zzugzj.github.io/posts/5c27e2b9/"/>
    <id>https://zzugzj.github.io/posts/5c27e2b9/</id>
    <published>2021-04-13T01:37:59.592Z</published>
    <updated>2021-04-13T12:34:14.301Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><h2 id="InnoDB的锁"><a href="#InnoDB的锁" class="headerlink" title="InnoDB的锁"></a>InnoDB的锁</h2><h3 id="共享锁和排他锁"><a href="#共享锁和排他锁" class="headerlink" title="共享锁和排他锁"></a>共享锁和排他锁</h3><p>InnoDB通过共享锁和排他锁实现了行级锁。</p><ul><li>共享(s)锁允许持有锁的事务读取一行。</li><li>排他(x)锁允许持有锁的事务更新或删除一行。</li></ul><p>事务T1在row行上拥有s锁，那事务T2申请row行上的s锁可立即获得，T1，2会同时拥有s锁。申请x锁需要等待T1释放锁。</p><p>事务T1在row行上拥有x锁，那事务T2申请row行的s或x锁必须等待T1释放锁。</p><h3 id="意向锁"><a href="#意向锁" class="headerlink" title="意向锁"></a>意向锁</h3><p>InnoDB存储引擎支持多粒度的锁：即可以同时支持行锁和表锁。为了支持这个机制，有了意图锁。</p><p>意向锁是表级锁，目的是表明事务稍后需要对表中的行使用那种类型的锁(s或x)。</p><p>存在两种类型的意向锁：</p><ul><li>意向共享(IS)锁：事务打算在一张表的个别行申请共享锁(select … lock in share mode)。</li><li>意向排他(IX)锁：事务打算再一张表的个别行申请排他锁(select … for update)。</li></ul><p>意向锁需要遵循一下协定：</p><ul><li>事务打算在一张表的个别行申请一个s锁前，必须先申请表的IS或IX锁。</li><li>事务打算在一张表的个别行申请一个x锁前，必须先申请表的IX锁。</li></ul><p>表的锁类型兼容性：</p><table><thead><tr><th></th><th>X</th><th>IX</th><th>S</th><th>IS</th></tr></thead><tbody><tr><td>X</td><td>互斥</td><td>互斥</td><td>互斥</td><td>互斥</td></tr><tr><td>IX</td><td>互斥</td><td>兼容</td><td>互斥</td><td>兼容</td></tr><tr><td>S</td><td>互斥</td><td>互斥</td><td>兼容</td><td>兼容</td></tr><tr><td>IS</td><td>互斥</td><td>兼容</td><td>兼容</td><td>兼容</td></tr></tbody></table><p>（意图锁之间互相兼容，其余遵循X,S互斥原则）</p><p>如果事务请求的锁与现有锁兼容，则将其授予请求的事务。 事务会等待直到现有的锁被释放。 如果锁请求与现有锁发生冲突，并且由于可能导致死锁而无法被授予许可，则会发生错误。</p><p>意向锁不会阻塞除表级锁(比如：lock tables … write)外的任何锁，意图锁的主要目的是表明有人正在锁表中的行，或者将要锁表中的行。</p><h3 id="记录锁-Record-Locks"><a href="#记录锁-Record-Locks" class="headerlink" title="记录锁(Record Locks)"></a>记录锁(Record Locks)</h3><p>记录锁是索引记录上的锁。比如：SELECT c1 FROM t WHERE c1 = 10 FOR UPDATE;就是给c1=10的行上加排他锁，防止别的事务的insert、update、delete这个c1=10的行。即使这个表没有定义索引，InnoDB也会隐式的创建一个聚集索引来加记录锁。</p><p>记录锁的事务在SHOW ENGINE INNODB STATUS和InnoDB监视器输出中看起来类似于以下内容：</p><pre class="language-mysql" data-language="mysql"><code class="language-mysql">RECORD LOCKS space id 58 page no 3 n bits 72 index &#96;PRIMARY&#96; of table &#96;test&#96;.&#96;t&#96;trx id 10078 lock_mode X locks rec but not gapRecord lock, heap no 2 PHYSICAL RECORD: n_fields 3; compact format; info bits 0 0: len 4; hex 8000000a; asc     ;; 1: len 6; hex 00000000274f; asc     &#39;O;; 2: len 7; hex b60000019d0110; asc        ;;</code></pre><h3 id="间隙锁-Gap-Locks"><a href="#间隙锁-Gap-Locks" class="headerlink" title="间隙锁(Gap Locks)"></a>间隙锁(Gap Locks)</h3><p>间隙锁是对索引记录间的间隙的锁定。比如：SELECT c1 FROM t WHERE c1 BETWEEN 10 and 20 FOR UPDATE;给10-20上排他间隙锁，防止其他事务插入10-20间的值。</p><p>间隙锁在部分隔离级别下使用。</p><p>对于使用唯一索引来查询行的语句，不需要间隙锁(如果是多列的索引，需要where条件全部命中，才不会加间隙锁，只会加记录锁)。例如，<code>SELECT * FROM child WHERE id = 100;</code>只有记录锁，没有间隙锁。如果id没有索引或者不是唯一索引，则该语句会锁住前面的间隙。</p><p>注意：不同的事务可以在一个间隙上拥有不同的间隙锁。例如：事务A在一个间隙上拥有共享间隙锁，同时事务B在同一间隙上可以拥有排他间隙锁（无论是间隙S锁还是间隙X锁）。这个机制被允许存在是因为，一个记录被删除时，会合并不同事务在这个记录上的间隙锁。</p><p>InnoDB中的间隙锁“纯粹是抑制性的”，这意味着它们的唯一目的是防止其他事务更改间隙间的内容。 间隙锁可以共存。一个事务进行的间隙锁不会阻止另一事务对相同的间隙获取间隙锁。 共享间隙锁和排他间隙锁之间没有区别。 它们彼此不冲突，并且执行相同的功能。</p><p>间隙锁可以在READ COMMITTED隔离级别下显式禁用。在这种情况下，将禁用间隙锁进行搜索和索引扫描，并且仅将其用于外键约束检查和重复键检查。</p><p>在READ COMMITTED隔离级别上还有其他效果。 MySQL评估WHERE条件后，将释放不匹配行的记录锁。 对于UPDATE语句，InnoDB进行“半一致”读取，将最新的提交版本返回给MySQL，以便MySQL可以确定该行是否与UPDATE的WHERE条件匹配。</p><h3 id="Next-Key-Locks"><a href="#Next-Key-Locks" class="headerlink" title="Next-Key Locks"></a>Next-Key Locks</h3><p>Next-Key Locks是索引记录上的记录锁和索引记录之前的间隙上的间隙锁的组合。</p><p>InnoDB执行行级锁的方式是：当它搜索或扫描表索引时，会在遇到的索引记录上设置共享或排他锁。 因此，行级锁实际上是索引记录锁。 索引记录上的Next-Key Locks也会影响该索引记录之前的“间隙”。 所以，Next-Key Locks是索引记录锁加上索引记录之前的间隙上的间隙锁。</p><p>如果一个会话在索引中的记录R上具有共享或排他锁，则另一会话不能按照索引顺序在R之前的间隙中插入新的索引记录。</p><p>假设一个索引包含10，11，13和20，该索引可能的Next-Key Locks覆盖以下间隔：</p><pre class="language-mysql" data-language="mysql"><code class="language-mysql">(负无穷, 10](10, 11](11, 13](13, 20](20, 正无穷)</code></pre><p>最后一个间隔，next-key lock锁定最大索引值之后的间隙。</p><p>默认情况下，InnoDB在REPEATABLE READ隔离级别中运行。 在这种情况下，InnoDB使用next-key锁进行搜索和索引扫描，这可以防止幻读。</p><h3 id="插入意向锁"><a href="#插入意向锁" class="headerlink" title="插入意向锁"></a>插入意向锁</h3><p>插入意向锁是一种在行插入之前通过INSERT操作设置的间隙锁。</p><p>如果多个事务插入共同的索引间隙的不同位置，那无需等待。假设有索引记录，其值分别为4和7。单独的事务分别尝试插入值5和6，在获得插入行的排他锁之前，每个事务都使用插入意图锁来锁定4和7之间的间隙， 但不互相阻塞，因为行是无冲突的。</p><p>举例：客户端A创建一张表有2个索引数据（90和102），开始一个事务，放置一个排他索引记录锁在ID&gt;100的数据，排他锁也包括一个102数据之前的间隙锁。</p><pre class="language-mysql" data-language="mysql"><code class="language-mysql">mysql&gt; CREATE TABLE child (id int(11) NOT NULL, PRIMARY KEY(id)) ENGINE&#x3D;InnoDB;mysql&gt; INSERT INTO child (id) values (90),(102);mysql&gt; START TRANSACTION;mysql&gt; SELECT * FROM child WHERE id &gt; 100 FOR UPDATE;+-----+| id  |+-----+| 102 |+-----+</code></pre><p>客户端B开始一个事务插入一条记录到间隙中，这个事务在等待排他锁的时候持有一个插入意图锁</p><pre class="language-mysql" data-language="mysql"><code class="language-mysql">mysql&gt; START TRANSACTION;mysql&gt; INSERT INTO child (id) VALUES (101);</code></pre><h3 id="AUTO-INC锁（自增锁）"><a href="#AUTO-INC锁（自增锁）" class="headerlink" title="AUTO-INC锁（自增锁）"></a>AUTO-INC锁（自增锁）</h3><p>AUTO-INC锁是一种特殊的表级锁，当事务插入表并有自增列的时候持有。 在最简单的情况下，如果一个事务正在向表中插入值，其他事务都必须等待自己的插入，以便第一个事务插入的行接收连续的主键值。</p><h2 id="autocommit-Commit-and-Rollback"><a href="#autocommit-Commit-and-Rollback" class="headerlink" title="autocommit, Commit, and Rollback"></a>autocommit, Commit, and Rollback</h2><p>在InnoDB中，所有用户活动都在事务内部进行。 如果启用了自动提交模式，则每个SQL语句将自己形成一个事务。 默认情况下，MySQL在启用了自动提交的情况下为每个新连接启动会话，因此如果该SQL语句未返回错误，则MySQL在每个SQL语句之后执行一次提交。 如果一条语句返回错误，则提交或回退行为取决于该错误。 </p><p>启用了自动提交的会话可以通过以显式START TRANSACTION或BEGIN语句开始并以COMMIT或ROLLBACK语句结束的方式执行多语句事务。</p><p>如果在SET autocommit = 0的会话中禁用了自动提交模式，则该会话将始终打开一个事务。 COMMIT或ROLLBACK语句结束当前事务，并开始新的事务。如果没有在显式提交最终事务的情况下结束，则MySQL将回滚事务。</p><p>COMMIT表示在当前事务中所做的更改将永久化，并在其他会话中可见。 另一方面，ROLLBACK语句取消当前事务所做的所有修改。 COMMIT和ROLLBACK都释放在当前事务期间设置的所有InnoDB锁。</p><h2 id="InnoDB中由不同的SQL语句设置的锁"><a href="#InnoDB中由不同的SQL语句设置的锁" class="headerlink" title="InnoDB中由不同的SQL语句设置的锁"></a>InnoDB中由不同的SQL语句设置的锁</h2><p>锁读取、更新或删除通常会对SQL语句扫描的每个索引记录设置记录锁。语句中是否存在排除该行的WHERE条件并不重要。InnoDB不知道确切的WHERE条件，只知道扫描了哪些索引范围。这些锁通常是next-key锁，也会阻止插入到紧靠记录之前的“间隙”中。</p><p>如果没有适合语句的索引，MySQL必须扫描整个表来处理语句，那么表的每一行都会被锁定，从而阻止其他用户对表的所有插入。创建好的索引非常重要，这样查询就不会扫描许多行。</p><p>下面是一些InnoDB设置的特殊类型的锁：</p><ul><li><p>SELECT … FROM是一致的读取，读取数据库的快照并且没有锁，除非将事务隔离级别设置为SERIALIZABLE。对于SERIALIZABLE级别，搜索会在遇到的索引记录上设置共享的下一键锁定。但是，对于使用唯一索引来搜索唯一行的行锁定的语句，仅需要索引记录锁。 </p></li><li><p>SELECT … FOR UPDATE或SELECT … LOCK IN SHARE MODE，将为扫描的行获取锁，并释放在结果集中不符合查询条件的行（例如，如果它们不符合WHERE子句中给出的条件）。但是，在某些情况下，行可能不会立即被解锁，因为结果行与其原始行之间的关系在查询执行过程中会丢失。例如，在UNION中，在评估它们是否符合结果集之前，可以将表中的扫描（和锁定）行插入到临时表中。在这种情况下，临时表中的行与原始表中的行之间的关系将丢失，并且直到查询执行结束后，行才被解锁。 </p></li><li><p>SELECT … LOCK IN SHARE MODE在所有遇到的索引记录上设置共享的next-key锁。但是，对于使用唯一索引来搜索的语句，仅需要索引记录锁定。 </p></li><li><p>SELECT … FOR UPDATE在所有遇到的记录上设置排他的next-key锁。但是，对于使用唯一索引来搜索的语句，仅需要索引记录锁定。 </p><p>对于查询索引记录遇到的问题，SELECT … FOR UPDATE阻止其他会话执行SELECT … LOCK IN SHARE MODE。</p></li><li><p>UPDATE … WHERE …在搜索遇到的每条记录上设置排他的next-key锁。但是，对于使用唯一索引的语句，仅需要索引记录锁。 </p></li><li><p>当UPDATE修改聚簇索引记录时，将对受影响的辅助索引记录进行隐式锁定。在插入新的二级索引记录之前执行重复检查扫描时，以及在插入新的二级索引记录时，UPDATE操作还会在受影响的二级索引记录上获得共享锁。 </p></li><li><p>DELETE FROM … WHERE …在搜索遇到的每条记录上设置独占的next-key锁。但是，对于使用唯一索引的语句，仅需要索引记录锁定。 </p></li><li><p>INSERT在插入的行上设置排他锁。该锁是索引记录锁，不是next-key锁（即没有间隙锁），并且不会阻止其他事务插入到插入行之前的间隙中。 </p><p>在插入行之前，设置了一种称为插入意图间隙锁的间隙锁。此锁表示：如果插入到同一索引间隙中的多个事务不在间隙中的同一位置插入，则它们无需等待对方。假设有索引记录，其值为4和7，在插入行上获得排他锁之前，插入值5和6的事务都使用插入意图锁来锁定4和7之间的间隙，不会彼此阻塞。</p></li></ul><h2 id="死锁"><a href="#死锁" class="headerlink" title="死锁"></a>死锁</h2><h3 id="一个死锁例子"><a href="#一个死锁例子" class="headerlink" title="一个死锁例子"></a>一个死锁例子</h3><p>下面的示例说明了锁请求可能会导致死锁。 该示例涉及两个客户端A和B。</p><p>首先，客户端A创建一个包含一行的表，然后开始事务。 在事务中，A通过在共享模式下选择该行来获得该行的S锁：</p><pre class="language-mysql" data-language="mysql"><code class="language-mysql">mysql&gt; CREATE TABLE t (i INT) ENGINE &#x3D; InnoDB;Query OK, 0 rows affected (1.07 sec)mysql&gt; INSERT INTO t (i) VALUES(1);Query OK, 1 row affected (0.09 sec)mysql&gt; START TRANSACTION;Query OK, 0 rows affected (0.00 sec)mysql&gt; SELECT * FROM t WHERE i &#x3D; 1 LOCK IN SHARE MODE;+------+| i    |+------+|    1 |+------+</code></pre><p>客户端B开启一个事务并尝试删除一行：</p><pre class="language-mysql" data-language="mysql"><code class="language-mysql">mysql&gt; START TRANSACTION;Query OK, 0 rows affected (0.00 sec)mysql&gt; DELETE FROM t WHERE i &#x3D; 1;</code></pre><p>删除操作需要x锁，但由于客户端A持有s锁，不与x锁兼容，客户端请求不到x锁，发生阻塞，进入请求队列中。</p><p>最后，客户端A尝试删除该行：</p><pre class="language-mysql" data-language="mysql"><code class="language-mysql">mysql&gt; DELETE FROM t WHERE i &#x3D; 1;ERROR 1213 (40001): Deadlock found when trying to get lock; try restarting transaction</code></pre><p>此处发生了死锁，客户端A需要x锁才能删除该行，但不能授予x锁。因为B已经在申请x锁，并等待A释放s锁。由于B事先要求X锁，因此A持有的S锁也不能升级为X锁。结果就是InnoDB为其中 一个客户端生成错误并释放其锁，客户端返回错误。</p><h3 id="死锁检测"><a href="#死锁检测" class="headerlink" title="死锁检测"></a>死锁检测</h3><p>启用死锁检测（默认）后，InnoDB自动检测事务死锁并回滚一个或多个事务以打破死锁。 InnoDB会尝试选择一些小的事务以进行回滚，其中事务的大小取决于插入，更新或删除的行数。</p><p>如果innodb_table_locks = 1（默认值）且autocommit = 0，则InnoDB可以检测表锁，并且它上面的MySQL层可以检测行级锁。 否则，InnoDB无法检测到涉及MySQL LOCK TABLES语句设置的表锁或InnoDB以外的存储引擎设置的锁的死锁。 通过设置innodb_lock_wait_timeout系统变量的值来解决这些情况。</p><p>如果InnoDB Monitor输出的LATEST DETECTED DEADLOCK部分包含一条消息，指出<code>TOO DEEP OR LONG SEARCH IN THE LOCK TABLE WAITS-FOR GRAPH, WE WILL ROLL BACK FOLLOWING TRANSACTION,</code>，这表明等待的事务数 list已达到200的限制。超过200个事务的等待列表将被视为死锁，并且尝试检查等待列表的事务将回退。 如果锁定线程必须查看等待列表上的事务拥有的1,000,000个以上的锁，也可能发生相同的错误。</p><h4 id="禁用死锁检测"><a href="#禁用死锁检测" class="headerlink" title="禁用死锁检测"></a>禁用死锁检测</h4><p>在高并发系统上，当多个线程等待相同的锁时，死锁检测会导致速度变慢。 有时，当发生死锁时，禁用死锁检测并依靠innodb_lock_wait_timeout设置进行事务回滚可能会更有效。 可以使用innodb_deadlock_detect配置选项禁用死锁检测。</p><h3 id="如何减少和处理死锁"><a href="#如何减少和处理死锁" class="headerlink" title="如何减少和处理死锁"></a>如何减少和处理死锁</h3><p>死锁是含有事务的数据库的经典问题，但死锁并不危险，除非死锁发生很频繁以至于无法运行某些事务。通常需要编写应用程序，以便在由于死锁而使事务回滚时，可以准备重新启动事务。</p><p>InnoDB使用行级锁。 即使在仅插入或删除单行的事务中，可能会陷入死锁。 这是因为这些操作并不是真正的“原子”操作。 它们会自动对插入或删除的行的（可能是多个）索引记录设置锁。</p><p>您可以使用以下技术来处理死锁并减少发生死锁的可能性：</p><ul><li><p>在任何时候，发出SHOW ENGINE INNODB STATUS命令来确定最新死锁的原因。 这可以帮助您调整应用程序以避免死锁。</p></li><li><p>如果频繁出现死锁警告引起关注，请通过启用innodb_print_all_deadlocks配置选项来收集更广泛的调试信息。有关每个死锁的信息，而不仅仅是最新的死锁，都记录在MySQL错误日志中。 完成调试后，请禁用此选项。</p></li><li><p>如果由于死锁而失败，请始终准备重新发出事务。 死锁并不危险。 请再试一次。</p></li><li><p>保持事务小巧且持续时间短，以使事务不易发生冲突。</p></li><li><p>如果使用锁定读取（SELECT … FOR UPDATE或SELECT … LOCK IN SHARE MODE），请尝试使用较低的隔离级别，例如READ COMMITTED。</p></li><li><p>修改事务中的多个表或同一表中的不同行时，每次都要以一致的顺序执行这些操作。 然后，事务形成定义良好的队列，并且不会死锁。 例如，将数据库操作组织到应用程序内的函数中，或调用存储的例程，而不是在不同位置编码多个类似的INSERT，UPDATE和DELETE语句序列。</p></li><li><p>将索引添加到表中。然后，查询需要扫描更少的索引记录，并因此设置更少的锁。 使用EXPLAIN SELECT确定MySQL服务器认为哪个索引最适合需要的查询。</p></li><li><p>使用更少的锁定。 如果您有能力允许SELECT从旧快照返回数据，请不要在其中添加FOR UPDATE或LOCK IN SHARE MODE子句。在这里使用READ COMMITTED隔离级别是好的，因为在同一事务中的每个一致读取都从其自己的新快照读取。</p></li><li><p>如果没有其他帮助，请使用表级锁序列化事务。将LOCK TABLES与事务表（例如InnoDB表）一起使用的正确方法是，先以SET autocommit = 0（不是START TRANSACTION）加上LOCK TABLES开始事务，然后在明确提交事务之前不调用UNLOCK TABLES。 例如，如果您需要写入表t1并从表t2中读取，则可以执行以下操作：</p><pre class="language-mysql" data-language="mysql"><code class="language-mysql">SET autocommit&#x3D;0;LOCK TABLES t1 WRITE, t2 READ, ...;... do something with tables t1 and t2 here ...COMMIT;UNLOCK TABLES;</code></pre><p>表级锁可防止对表的并发更新，从而避免死锁，但代价是对繁忙系统的响应速度较慢。</p></li><li><p>序列化事务的另一种方法是创建一个仅包含一行的辅助“信号量”表。 在访问其他表之前，让每个事务更新该行。 这样，所有事务都以串行方式进行。 请注意，在这种情况下，InnoDB即时死锁检测算法也适用，因为序列化锁是行级锁。 对于MySQL表级锁，必须使用超时方法来解决死锁。</p></li></ul>]]></content>
    
    
    <summary type="html">InnoDB与MyISAM的最大不同有两点:一是支持事务(TRANSACTION);二是采用了行级锁。关于事务我们之前有专题介绍,这里就着重介绍下它的锁机制。 总的来说,InnoDB按照不同的分类...</summary>
    
    
    
    <category term="数据库" scheme="https://zzugzj.github.io/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"/>
    
    
    <category term="MySQL" scheme="https://zzugzj.github.io/tags/MySQL/"/>
    
  </entry>
  
  <entry>
    <title>MySQL幻读和可重复读</title>
    <link href="https://zzugzj.github.io/posts/9617db49/"/>
    <id>https://zzugzj.github.io/posts/9617db49/</id>
    <published>2021-04-12T13:50:26.530Z</published>
    <updated>2023-11-05T05:52:56.944Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><h3 id="幻读和可重复读"><a href="#幻读和可重复读" class="headerlink" title="幻读和可重复读"></a>幻读和可重复读</h3><ol><li>由于很多人容易搞混 <code>不可重复读</code> 和 <code>幻读</code>，这两者确实非常相似。<ul><li>但 <code>不可重复读</code> 主要是说多次读取一条记录, 发现该记录中某些列值被修改过。</li><li>而 <code>幻读</code> 主要是说多次读取一个范围内的记录(包括直接查询所有记录结果或者做聚合统计), 发现结果不一致(标准档案一般指记录增多, 记录的减少应该也算是幻读)。(可以参考<a href="https://dev.mysql.com/doc/refman/5.7/en/innodb-next-key-locking.html">MySQL官方文档对 Phantom Rows 的介绍</a>)</li></ul></li><li>其实对于 <code>幻读</code>, MySQL的InnoDB引擎默认的<code>RR</code>级别已经通过<code>MVCC自动帮我们解决了</code>, 所以该级别下, 你也模拟不出幻读的场景; 退回到 <code>RC</code> 隔离级别的话, 你又容易把<code>幻读</code>和<code>不可重复读</code>搞混淆, 所以这可能就是比较头痛的点吧!<br>具体可以参考《高性能MySQL》对 <code>RR</code> 隔离级别的描述, 理论上RR级别是无法解决幻读的问题, 但是由于InnoDB引擎的RR级别还使用了MVCC, 所以也就避免了幻读的出现!</li></ol><p>MVCC虽然解决了<code>幻读</code>问题, 但严格来说只是解决了<strong>部分</strong>幻读问题。</p><p>比如可能会发生这种情况：</p><p>事务A：</p><p><img src="https://raw.githubusercontent.com/zzugzj/blogImg/master/img/image-20210412220546067.png" alt="image-20210412220546067" loading="lazy"></p><p>另外一个直接执行：</p><p><img src="https://raw.githubusercontent.com/zzugzj/blogImg/master/img/image-20210412220604432.png" alt="image-20210412220604432" loading="lazy"></p><p>就会发生图片上的情况。</p><p>关于第5步可以读出最新数据而且第6步无法插入，是因为select分为当前读和快照读，普通select不加for update是快照读，insert、delete、update都是当前读。</p><h3 id="关于快照读和当前读"><a href="#关于快照读和当前读" class="headerlink" title="关于快照读和当前读"></a>关于快照读和当前读</h3><ul><li><p>快照读, 读取专门的快照</p><pre class="language-none"><code class="language-none">简单的select操作即可(不需要加锁,如: select ... lock in share mode, select ... for update)</code></pre><p>针对的也是select操作</p></li><li><p>当前读, 读取最新版本的记录</p><pre class="language-none"><code class="language-none">select ... lock in share modeselect ... for update</code></pre><p>针对如下操作, 会让如下操作阻塞:    </p><pre class="language-none"><code class="language-none">insertupdatedelete</code></pre></li><li><p>在RR级别下, 快照读是通过MVVC(多版本控制)和undo log来实现的, 当前读是通过手动加record lock(记录锁)和gap lock(间隙锁)来实现的。所以从上面的显示来看，如果需要实时显示数据，还是需要通过加锁来实现。这个时候会使用next-key技术来实现。</p></li></ul><h3 id="SERIALIZABLE隔离级别如何解决幻读"><a href="#SERIALIZABLE隔离级别如何解决幻读" class="headerlink" title="SERIALIZABLE隔离级别如何解决幻读"></a>SERIALIZABLE隔离级别如何解决幻读</h3><p>RR隔离级别可以使用对记录手动加 X锁 的方法消除幻读，比如select … for update等可以加锁，存在则会被加行（X）锁，如果不存在，则会加 next-lock key / gap 锁（范围行锁），即记录存在与否，mysql 都会对记录应该对应的索引加锁，其他事务是无法再获得做操作的。</p><p>另外，使用SERIALIZABLE 隔离级别也可以完全解决幻读，它是对所有事务都加 X锁，不过我们大部分事务都没必要，所以造成了性能浪费</p><p>在此级别下，我们便不需要对 SELECT 操作显式加锁，InnoDB会自动加锁，事务安全，但性能很低</p><h3 id="关于MySQL隔离级别为什么是RR"><a href="#关于MySQL隔离级别为什么是RR" class="headerlink" title="关于MySQL隔离级别为什么是RR"></a>关于MySQL隔离级别为什么是RR</h3><p>众所周知，常见的关系型数据库的默认事务隔离级别采用的是READ_COMMITED，例如PostgreSQL、ORACLE、SQL Server和DB2。但是使用InnoDB引擎的MySQL数据库默认事务隔离级别是REPEATABLE_READ。</p><p>那为什么MySQL要独树一帜的选用RR的隔离级别呢？</p><p>其实这是一个历史遗留问题。</p><p>我们都知道，MySQL的主从复制是基于binlog复制的，在MySQL 5.7.7之前，默认的格式是 <code>STATEMENT</code>，在 MySQL 5.7.7 及更高版本中，默认值是 <code>ROW</code>。日志格式通过 <code>binlog-format</code> 指定。</p><p>binlog目前有三种格式：statement、row、mixed：</p><ul><li><p>statement:记录的是修改SQL语句</p></li><li><p>row：记录的是每行实际数据的变更</p></li><li><p>mixed：statement和row模式的混合</p></li></ul><p>MySQL5.0以前只有statement格式，而这种格式在读已提交(Read Commited)这个隔离级别下主从复制是有bug的，因此Mysql将可重复读(Repeatable Read)作为默认的隔离级别。<br>接下来，就要说说当binlog为STATEMENT格式，且隔离级别为读已提交(Read Commited)时，有什么bug呢？如下图所示，在主(master)上执行如下事务:<br>  <img src="https://raw.githubusercontent.com/zzugzj/blogImg/master/img/c0243ecb466b6f3c7c30c26bb26c757d.png" alt="在这里插入图片描述" loading="lazy"><br> 此时在主库中查询：</p><pre class="language-none"><code class="language-none">select * from t;1</code></pre><p>输出结果：</p><pre class="language-none"><code class="language-none">+---+---+| c1 |c2+---+---+| 2 | 2+---+---+1 row in set</code></pre><p>从库中查询：</p><pre class="language-none"><code class="language-none">select * from t;1</code></pre><p>输出结果：</p><pre class="language-none"><code class="language-none">Empty set1</code></pre><p>这里出现了主从不一致性的问题！原因其实很简单，就是在master上执行的顺序为先删后插！而此时binlog为STATEMENT格式，它记录的顺序为先插后删！从(slave)同步的是binglog，因此从机执行的顺序和主机不一致！就会出现主从不一致！<br>如何解决？<br>解决方案有两种！<br>(1)隔离级别设为可重复读(Repeatable Read),在该隔离级别下引入间隙锁。当Session 1执行delete语句时，会锁住间隙。那么，Ssession 2执行插入语句就会阻塞住！<br>(2)将binglog的格式修改为row格式，此时是基于行的复制，自然就不会出现sql执行顺序不一样的问题！奈何这个格式在mysql5.1版本开始才引入。<br><strong>因此由于历史原因，mysql将默认的隔离级别设为可重复读(Repeatable Read)，保证主从复制不出问题！</strong></p><p>当前这个历史遗漏问题以及解决，大家可以将其设置为RC+ROW组合的方式（例如ORACLE等数据库隔离级别就是RC），而不是必须使用RR（会带来更多的锁等待），具体可以视情况选择。</p>]]></content>
    
    
    <summary type="html">当同一查询在不同时间产生不同的行集时，在事务内就会发生所谓的幻象问题。 例如，如果SELECT执行两次，但是第二次返回的行却不是第一次返回，则该行是“幻像”行，还有select没有的数据，insert时失</summary>
    
    
    
    <category term="数据库" scheme="https://zzugzj.github.io/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"/>
    
    
    <category term="MySQL" scheme="https://zzugzj.github.io/tags/MySQL/"/>
    
  </entry>
  
  <entry>
    <title>Java8实战笔记</title>
    <link href="https://zzugzj.github.io/posts/30888651/"/>
    <id>https://zzugzj.github.io/posts/30888651/</id>
    <published>2021-03-09T14:36:25.000Z</published>
    <updated>2023-11-05T05:48:34.128Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><h3 id="把Lambda付诸实践：环绕执行模式"><a href="#把Lambda付诸实践：环绕执行模式" class="headerlink" title="把Lambda付诸实践：环绕执行模式"></a>把Lambda付诸实践：环绕执行模式</h3><p>资源处理时常见的一个模式是打开一个资源，做一些处理，然后关闭资源，这个设置和清理阶段类似，并且会围绕着执行处理的业务逻辑。这就是环绕执行模式。</p><p>1）第一步，当需要更改逻辑代码是，需要重写代码，所以想到行为参数化</p><pre class="language-java" data-language="java"><code class="language-java"><span class="token keyword">public</span> <span class="token keyword">static</span> <span class="token class-name">String</span> <span class="token function">processFile</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">throws</span> <span class="token class-name">IOException</span> <span class="token punctuation">&#123;</span>    <span class="token keyword">try</span><span class="token punctuation">(</span><span class="token class-name">BufferedReader</span> bufferedReader <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">BufferedReader</span><span class="token punctuation">(</span><span class="token keyword">new</span> <span class="token class-name">FileReader</span><span class="token punctuation">(</span><span class="token string">"data.txt"</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">&#123;</span>       <span class="token comment">// return bufferedReader.readLine();</span>    <span class="token keyword">return</span> bufferedReader<span class="token punctuation">.</span><span class="token function">readLine</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">+</span> bufferedReader<span class="token punctuation">.</span><span class="token function">readLine</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token punctuation">&#125;</span><span class="token punctuation">&#125;</span></code></pre><p>2）第二步，使用函数式接口来传递一个行为</p><pre class="language-java" data-language="java"><code class="language-java"><span class="token annotation punctuation">@FunctionalInterface</span><span class="token keyword">public</span> <span class="token keyword">interface</span> <span class="token class-name">BufferReaderProcessFile</span> <span class="token punctuation">&#123;</span>    <span class="token comment">// 方法签名为 BufferReader -> String</span>    <span class="token class-name">String</span> <span class="token function">peocess</span><span class="token punctuation">(</span><span class="token class-name">BufferedReader</span> bufferedReader<span class="token punctuation">)</span><span class="token keyword">throws</span> <span class="token class-name">IOException</span><span class="token punctuation">;</span><span class="token punctuation">&#125;</span></code></pre><p>3）第三步，执一个行为，任何BufferReader -&gt; String的Lambda表达式都可以作为参数传入。只要符合peocess方法的签名即可。</p><pre class="language-java" data-language="java"><code class="language-java"><span class="token keyword">public</span> <span class="token keyword">static</span> <span class="token class-name">String</span> <span class="token function">processFiles</span><span class="token punctuation">(</span><span class="token class-name">BufferReaderProcessFile</span> bufferReaderProcessFile<span class="token punctuation">)</span><span class="token keyword">throws</span> <span class="token class-name">IOException</span> <span class="token punctuation">&#123;</span><span class="token keyword">try</span><span class="token punctuation">(</span><span class="token class-name">BufferedReader</span> bufferedReader <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">BufferedReader</span><span class="token punctuation">(</span><span class="token keyword">new</span> <span class="token class-name">FileReader</span><span class="token punctuation">(</span><span class="token string">"data.txt"</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">&#123;</span><span class="token keyword">return</span> bufferReaderProcessFile<span class="token punctuation">.</span><span class="token function">peocess</span><span class="token punctuation">(</span>bufferedReader<span class="token punctuation">)</span> <span class="token punctuation">;</span><span class="token punctuation">&#125;</span><span class="token punctuation">&#125;</span></code></pre><p>4）第四步，传递Lambda</p><pre class="language-java" data-language="java"><code class="language-java"><span class="token class-name">String</span> string <span class="token operator">=</span> <span class="token function">processFiles</span><span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token class-name">BufferedReader</span> bs<span class="token punctuation">)</span> <span class="token operator">-></span> bs<span class="token punctuation">.</span><span class="token function">readLine</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span></code></pre><p><img src="https://raw.githubusercontent.com/zzugzj/blogImg/master/img/image-20210310193142971.png" alt="image-20210310193142971" loading="lazy"></p><h3 id="使用函数式接口"><a href="#使用函数式接口" class="headerlink" title="使用函数式接口"></a>使用函数式接口</h3><p>函数式接口很有用，因为抽象方法的签名可以描述Lambda表达式的签名。函数式接口的抽象方法的签名称为函数描述符。所以为了应用不同的Lambda表达式，需要一套能够描述常见函数描述符的函数式接口。</p><p>Java 8的库设计师在java.util.function包中引入了几个新的函数式接口。</p><p>几个常用的函数式接口：</p><h4 id="Predicate"><a href="#Predicate" class="headerlink" title="Predicate"></a>Predicate</h4><p>java.util.function.Predicate&lt;T&gt;接口定义了一个名叫test的抽象方法，它接受泛型T对象，并返回一个boolean。这恰恰和你先前创建的一样，现在就可以直接使用了。在需要表示一个涉及类型T的布尔表达式时，就可以使用这个接口。</p><pre class="language-java" data-language="java"><code class="language-java"><span class="token annotation punctuation">@FunctionalInterface</span> <span class="token keyword">public</span> <span class="token keyword">interface</span> <span class="token class-name">Predicate</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">T</span><span class="token punctuation">></span></span><span class="token punctuation">&#123;</span>     <span class="token keyword">boolean</span> <span class="token function">test</span><span class="token punctuation">(</span><span class="token class-name">T</span> t<span class="token punctuation">)</span><span class="token punctuation">;</span> <span class="token punctuation">&#125;</span>  <span class="token keyword">public</span> <span class="token keyword">static</span> <span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">T</span><span class="token punctuation">></span></span> <span class="token class-name">List</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">T</span><span class="token punctuation">></span></span> <span class="token function">filter</span><span class="token punctuation">(</span><span class="token class-name">List</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">T</span><span class="token punctuation">></span></span> list<span class="token punctuation">,</span> <span class="token class-name">Predicate</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">T</span><span class="token punctuation">></span></span> p<span class="token punctuation">)</span> <span class="token punctuation">&#123;</span>     <span class="token class-name">List</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">T</span><span class="token punctuation">></span></span> results <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">ArrayList</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token punctuation">></span></span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>     <span class="token keyword">for</span><span class="token punctuation">(</span><span class="token class-name">T</span> s<span class="token operator">:</span> list<span class="token punctuation">)</span><span class="token punctuation">&#123;</span>         <span class="token keyword">if</span><span class="token punctuation">(</span>p<span class="token punctuation">.</span><span class="token function">test</span><span class="token punctuation">(</span>s<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">&#123;</span>             results<span class="token punctuation">.</span><span class="token function">add</span><span class="token punctuation">(</span>s<span class="token punctuation">)</span><span class="token punctuation">;</span>         <span class="token punctuation">&#125;</span>     <span class="token punctuation">&#125;</span>     <span class="token keyword">return</span> results<span class="token punctuation">;</span> <span class="token punctuation">&#125;</span>  <span class="token class-name">Predicate</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">String</span><span class="token punctuation">></span></span> nonEmptyStringPredicate <span class="token operator">=</span> <span class="token punctuation">(</span><span class="token class-name">String</span> s<span class="token punctuation">)</span> <span class="token operator">-></span> <span class="token operator">!</span>s<span class="token punctuation">.</span><span class="token function">isEmpty</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span> <span class="token class-name">List</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">String</span><span class="token punctuation">></span></span> nonEmpty <span class="token operator">=</span> <span class="token function">filter</span><span class="token punctuation">(</span>listOfStrings<span class="token punctuation">,</span> nonEmptyStringPredicate<span class="token punctuation">)</span><span class="token punctuation">;</span></code></pre><h4 id="Consumer"><a href="#Consumer" class="headerlink" title="Consumer"></a>Consumer</h4><p>java.util.function.Consumer&lt;T&gt;定义了一个名叫accept的抽象方法，它接受泛型T的对象，没有返回（void）。如果需要访问类型T的对象，并对其执行某些操作，就可以使用这个接口。比如，可以用它来创建一个forEach方法，接受一个Integers的列表，并对其中每个元素执行操作。</p><pre class="language-java" data-language="java"><code class="language-java"><span class="token annotation punctuation">@FunctionalInterface</span> <span class="token keyword">public</span> <span class="token keyword">interface</span> <span class="token class-name">Consumer</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">T</span><span class="token punctuation">></span></span><span class="token punctuation">&#123;</span>     <span class="token keyword">void</span> <span class="token function">accept</span><span class="token punctuation">(</span><span class="token class-name">T</span> t<span class="token punctuation">)</span><span class="token punctuation">;</span> <span class="token punctuation">&#125;</span> <span class="token keyword">public</span> <span class="token keyword">static</span> <span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">T</span><span class="token punctuation">></span></span> <span class="token keyword">void</span> <span class="token function">forEach</span><span class="token punctuation">(</span><span class="token class-name">List</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">T</span><span class="token punctuation">></span></span> list<span class="token punctuation">,</span> <span class="token class-name">Consumer</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">T</span><span class="token punctuation">></span></span> c<span class="token punctuation">)</span><span class="token punctuation">&#123;</span>    <span class="token keyword">for</span><span class="token punctuation">(</span><span class="token class-name">T</span> i<span class="token operator">:</span> list<span class="token punctuation">)</span><span class="token punctuation">&#123;</span>         c<span class="token punctuation">.</span><span class="token function">accept</span><span class="token punctuation">(</span>i<span class="token punctuation">)</span><span class="token punctuation">;</span>     <span class="token punctuation">&#125;</span> <span class="token punctuation">&#125;</span>  <span class="token function">forEach</span><span class="token punctuation">(</span>          <span class="token class-name">Arrays</span><span class="token punctuation">.</span><span class="token function">asList</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">4</span><span class="token punctuation">,</span><span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">,</span>         <span class="token punctuation">(</span><span class="token class-name">Integer</span> i<span class="token punctuation">)</span> <span class="token operator">-></span> <span class="token class-name">System</span><span class="token punctuation">.</span>out<span class="token punctuation">.</span><span class="token function">println</span><span class="token punctuation">(</span>i<span class="token punctuation">)</span>         <span class="token punctuation">)</span><span class="token punctuation">;</span></code></pre><h4 id="Function"><a href="#Function" class="headerlink" title="Function"></a>Function</h4><p>java.util.function.Function&lt;T, R&gt;接口定义了一个叫作apply的方法，它接受一个泛型T的对象，并返回一个泛型R的对象。如果需要定义一个Lambda，将输入对象的信息映射到输出，就可以使用这个接口（比如提取苹果的重量，或把字符串映射为它的长度）。</p><pre class="language-java" data-language="java"><code class="language-java"><span class="token annotation punctuation">@FunctionalInterface</span> <span class="token keyword">public</span> <span class="token keyword">interface</span> <span class="token class-name">Function</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">T</span><span class="token punctuation">,</span> <span class="token class-name">R</span><span class="token punctuation">></span></span><span class="token punctuation">&#123;</span>     <span class="token class-name">R</span> <span class="token function">apply</span><span class="token punctuation">(</span><span class="token class-name">T</span> t<span class="token punctuation">)</span><span class="token punctuation">;</span> <span class="token punctuation">&#125;</span> <span class="token keyword">public</span> <span class="token keyword">static</span> <span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">T</span><span class="token punctuation">,</span> <span class="token class-name">R</span><span class="token punctuation">></span></span> <span class="token class-name">List</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">R</span><span class="token punctuation">></span></span> <span class="token function">map</span><span class="token punctuation">(</span><span class="token class-name">List</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">T</span><span class="token punctuation">></span></span> list<span class="token punctuation">,</span> <span class="token class-name">Function</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">T</span><span class="token punctuation">,</span> <span class="token class-name">R</span><span class="token punctuation">></span></span> f<span class="token punctuation">)</span> <span class="token punctuation">&#123;</span>     <span class="token class-name">List</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">R</span><span class="token punctuation">></span></span> result <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">ArrayList</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token punctuation">></span></span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>     <span class="token keyword">for</span><span class="token punctuation">(</span><span class="token class-name">T</span> s<span class="token operator">:</span> list<span class="token punctuation">)</span><span class="token punctuation">&#123;</span>         result<span class="token punctuation">.</span><span class="token function">add</span><span class="token punctuation">(</span>f<span class="token punctuation">.</span><span class="token function">apply</span><span class="token punctuation">(</span>s<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>     <span class="token punctuation">&#125;</span>     <span class="token keyword">return</span> result<span class="token punctuation">;</span> <span class="token punctuation">&#125;</span> <span class="token comment">// [7, 2, 6] </span><span class="token class-name">List</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">Integer</span><span class="token punctuation">></span></span> l <span class="token operator">=</span> <span class="token function">map</span><span class="token punctuation">(</span>                        <span class="token class-name">Arrays</span><span class="token punctuation">.</span><span class="token function">asList</span><span class="token punctuation">(</span><span class="token string">"lambdas"</span><span class="token punctuation">,</span><span class="token string">"in"</span><span class="token punctuation">,</span><span class="token string">"action"</span><span class="token punctuation">)</span><span class="token punctuation">,</span>                        <span class="token punctuation">(</span><span class="token class-name">String</span> s<span class="token punctuation">)</span> <span class="token operator">-></span> s<span class="token punctuation">.</span><span class="token function">length</span><span class="token punctuation">(</span><span class="token punctuation">)</span>                <span class="token punctuation">)</span><span class="token punctuation">;</span></code></pre><h4 id="常用函数式接口"><a href="#常用函数式接口" class="headerlink" title="常用函数式接口"></a>常用函数式接口</h4><p><img src="https://raw.githubusercontent.com/zzugzj/blogImg/master/img/image-20210310223646991.png" alt="image-20210310223646991" loading="lazy"></p><p><img src="https://raw.githubusercontent.com/zzugzj/blogImg/master/img/image-20210310223702177.png" alt="image-20210310223702177" loading="lazy"></p><h4 id="一些使用案例"><a href="#一些使用案例" class="headerlink" title="一些使用案例"></a>一些使用案例</h4><p><img src="https://raw.githubusercontent.com/zzugzj/blogImg/master/img/image-20210310224129130.png" alt="image-20210310224129130" loading="lazy"></p><p><strong>异常，Lambda，还有函数式接口：</strong></p><p><strong>任何的函数式接口都不能抛出受检异常(check exception)，如果你需要lambda 表达式抛出异常，有两种方法：</strong></p><p><strong>定义一个自己的函数式接口，并申明受检异常，或者把Lambda包在一个try/catch块中。</strong></p><h3 id="类型推断、类型检查及限制"><a href="#类型推断、类型检查及限制" class="headerlink" title="类型推断、类型检查及限制"></a>类型推断、类型检查及限制</h3><h4 id="使用局部变量"><a href="#使用局部变量" class="headerlink" title="使用局部变量"></a>使用局部变量</h4><p>Lambda表达式也允许使用自由变量（不是参数，而是在外层作用域中定义的变量），就像匿名类一样。 它们被称作捕获Lambda。例如，下面的Lambda捕获了portNumber变量： </p><pre class="language-java" data-language="java"><code class="language-java"><span class="token keyword">int</span> portNumber <span class="token operator">=</span> <span class="token number">1337</span><span class="token punctuation">;</span> <span class="token class-name">Runnable</span> r <span class="token operator">=</span> <span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">-></span> <span class="token class-name">System</span><span class="token punctuation">.</span>out<span class="token punctuation">.</span><span class="token function">println</span><span class="token punctuation">(</span>portNumber<span class="token punctuation">)</span><span class="token punctuation">;</span> </code></pre><p>尽管如此，还有一点点小麻烦：关于能对这些变量做什么有一些限制。Lambda可以没有限制地捕获（也就是在其主体中引用）实例变量和静态变量。但局部变量必须显式声明为final，或事实上是final。换句话说，Lambda表达式只能捕获指派给它们的局部变量一次。（注：捕获实例变量可以被看作捕获最终局部变量this。） 例如，下面的代码无法编译，因为portNumber变量被赋值两次： </p><pre class="language-java" data-language="java"><code class="language-java"><span class="token keyword">int</span> portNumber <span class="token operator">=</span> <span class="token number">1337</span><span class="token punctuation">;</span> <span class="token class-name">Runnable</span> r <span class="token operator">=</span> <span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">-></span> <span class="token class-name">System</span><span class="token punctuation">.</span>out<span class="token punctuation">.</span><span class="token function">println</span><span class="token punctuation">(</span>portNumber<span class="token punctuation">)</span><span class="token punctuation">;</span>  portNumber <span class="token operator">=</span> <span class="token number">31337</span><span class="token punctuation">;</span></code></pre><p><strong>对局部变量的限制</strong> </p><p>你可能会问自己，为什么局部变量有这些限制。第一，实例变量和局部变量背后的实现有一个关键不同。实例变量都存储在堆中，而局部变量则保存在栈上。如果Lambda可以直接访问局部变量，而且Lambda是在一个线程中使用的，则使用Lambda的线程，可能会在分配该变量的线程将这个变量收回之后，去访问该变量。因此，Java在访问自由局部变量时，实际上是在访问它的副本，而不是访问原始变量。如果局部变量仅仅赋值一次那就没有什么区别了——因此就有了这个限制。 </p><p>在JDK8中如果我们在匿名内部类中需要访问局部变量，那么这个局部变量不需要用final修饰符修饰。看似是一种编译机制的改变，实际上就是一个语法糖（底层还是帮你加了final）。但通过反编译没有看到底层为我们加上final，但我们无法改变这个局部变量的引用值，如果改变就会编译报错。</p><h3 id="方法引用"><a href="#方法引用" class="headerlink" title="方法引用"></a>方法引用</h3><p>需要使用方法引用时，目标引用放在分隔符::前，方法的名称放在后面。</p><p><img src="https://raw.githubusercontent.com/zzugzj/blogImg/master/img/image-20210312103902789.png" alt="image-20210312103902789" loading="lazy"></p><h4 id="如何构建方法引用"><a href="#如何构建方法引用" class="headerlink" title="如何构建方法引用"></a>如何构建方法引用</h4><p>方法引用主要有三类。 </p><p>(1) 指向静态方法的方法引用（例如Integer的parseInt方法，写作Integer::parseInt）。</p><p>(2) 指 向 任 意 类 型 实 例 方 法 的 方 法 引 用 （ 例 如 String 的 length 方 法 ， 写 作String::length）。</p><p>(3) 指向现有对象的实例方法的方法引用（假设你有一个局部变量expensiveTransaction用于存放Transaction类型的对象，它支持实例方法getValue，那么你就可以写expensiveTransaction::getValue）。</p><p><img src="https://raw.githubusercontent.com/zzugzj/blogImg/master/img/image-20210312105030226.png" alt="image-20210312105030226" loading="lazy"></p><h3 id="复合-Lambda-表达式的有用方法"><a href="#复合-Lambda-表达式的有用方法" class="headerlink" title="复合 Lambda 表达式的有用方法"></a>复合 Lambda 表达式的有用方法</h3><h4 id="比较器复合"><a href="#比较器复合" class="headerlink" title="比较器复合"></a>比较器复合</h4><p>使用静态方法Comparator.comparing，根据提取用于比较的键值的Function来返回一个Comparator</p><pre class="language-java" data-language="java"><code class="language-java"><span class="token class-name">Comparator</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">Apple</span><span class="token punctuation">></span></span> c <span class="token operator">=</span> <span class="token class-name">Comparator</span><span class="token punctuation">.</span><span class="token function">comparing</span><span class="token punctuation">(</span><span class="token class-name">Apple</span><span class="token operator">::</span><span class="token function">getWeight</span><span class="token punctuation">)</span><span class="token punctuation">;</span></code></pre><ol><li><p>逆序<br> 接口有一个默认方法reversed可以使给定的比较器逆序。因此仍然用开始的那个比较器，只要修改一下前一个例子就可以对苹果按重量递减排序： </p><pre class="language-java" data-language="java"><code class="language-java">inventory<span class="token punctuation">.</span><span class="token function">sort</span><span class="token punctuation">(</span><span class="token function">comparing</span><span class="token punctuation">(</span><span class="token class-name">Apple</span><span class="token operator">::</span><span class="token function">getWeight</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">reversed</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span></code></pre></li><li><p>比较器链<br>如果发现有两个苹果一样重怎么办？哪个苹果应该排在前面呢？你可能需要再提供一个Comparator来进一步定义这个比较。thenComparing方法就是做这个用的。它接受一个函数作为参数（就像comparing方法一样），如果两个对象用第一个Comparator比较之后是一样的，就提供第二个Comparator。你又可以优雅地解决这个问题了： </p><pre class="language-java" data-language="java"><code class="language-java">inventory<span class="token punctuation">.</span><span class="token function">sort</span><span class="token punctuation">(</span><span class="token function">comparing</span><span class="token punctuation">(</span><span class="token class-name">Apple</span><span class="token operator">::</span><span class="token function">getWeight</span><span class="token punctuation">)</span>          <span class="token punctuation">.</span><span class="token function">reversed</span><span class="token punctuation">(</span><span class="token punctuation">)</span>           <span class="token punctuation">.</span><span class="token function">thenComparing</span><span class="token punctuation">(</span><span class="token class-name">Apple</span><span class="token operator">::</span><span class="token function">getCountry</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span></code></pre></li></ol><h4 id="谓词复合"><a href="#谓词复合" class="headerlink" title="谓词复合"></a>谓词复合</h4><p>谓词接口包括三个方法：negate、and和or，可以重用已有的Predicate来创建更复杂的谓词。</p><p>表达要么是重（150克以上）的苹果，要么是绿苹果： </p><pre class="language-java" data-language="java"><code class="language-java"><span class="token class-name">Predicate</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">Apple</span><span class="token punctuation">></span></span> redAndHeavyAppleOrGreen <span class="token operator">=</span>     redApple<span class="token punctuation">.</span><span class="token function">and</span><span class="token punctuation">(</span>a <span class="token operator">-></span> a<span class="token punctuation">.</span><span class="token function">getWeight</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">></span> <span class="token number">150</span><span class="token punctuation">)</span>             <span class="token punctuation">.</span><span class="token function">or</span><span class="token punctuation">(</span>a <span class="token operator">-></span> <span class="token string">"green"</span><span class="token punctuation">.</span><span class="token function">equals</span><span class="token punctuation">(</span>a<span class="token punctuation">.</span><span class="token function">getColor</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span> </code></pre><p>请注意，and和or方法是按照在表达式链中的位置，从左向右确定优先级的。因此，a.or(b).and(c)可以看作(a || b) &amp;&amp; c。</p><h4 id="函数复合"><a href="#函数复合" class="headerlink" title="函数复合"></a>函数复合</h4><p>Function接口为此配了andThen和compose两个默认方法，它们都会返回Function的一个实例。</p><p>andThen方法，会返回一个函数，它先对输入应用一个给定函数，再对输出应用另一个函数。</p><pre class="language-java" data-language="java"><code class="language-java"><span class="token class-name">Function</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">Integer</span><span class="token punctuation">,</span> <span class="token class-name">Integer</span><span class="token punctuation">></span></span> f <span class="token operator">=</span> x <span class="token operator">-></span> x <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">;</span>  <span class="token comment">//数学上会写作g(f(x))</span><span class="token class-name">Function</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">Integer</span><span class="token punctuation">,</span> <span class="token class-name">Integer</span><span class="token punctuation">></span></span> g <span class="token operator">=</span> x <span class="token operator">-></span> x <span class="token operator">*</span> <span class="token number">2</span><span class="token punctuation">;</span><span class="token class-name">Function</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">Integer</span><span class="token punctuation">,</span> <span class="token class-name">Integer</span><span class="token punctuation">></span></span> h <span class="token operator">=</span> f<span class="token punctuation">.</span><span class="token function">andThen</span><span class="token punctuation">(</span>g<span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token class-name">System</span><span class="token punctuation">.</span>out<span class="token punctuation">.</span><span class="token function">println</span><span class="token punctuation">(</span>h<span class="token punctuation">.</span><span class="token function">apply</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>  <span class="token comment">//输出4</span></code></pre><p>compose方法，先把给定的函数用作compose的参数里面给的那个函数，然后再把函数本身用于结果。</p><pre class="language-java" data-language="java"><code class="language-java"><span class="token class-name">Function</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">Integer</span><span class="token punctuation">,</span> <span class="token class-name">Integer</span><span class="token punctuation">></span></span> f <span class="token operator">=</span> x <span class="token operator">-></span> x <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">;</span>  <span class="token comment">//数学上会写作f(g(x))</span><span class="token class-name">Function</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">Integer</span><span class="token punctuation">,</span> <span class="token class-name">Integer</span><span class="token punctuation">></span></span> g <span class="token operator">=</span> x <span class="token operator">-></span> x <span class="token operator">*</span> <span class="token number">2</span><span class="token punctuation">;</span><span class="token class-name">Function</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">Integer</span><span class="token punctuation">,</span> <span class="token class-name">Integer</span><span class="token punctuation">></span></span> h <span class="token operator">=</span> f<span class="token punctuation">.</span><span class="token function">compose</span><span class="token punctuation">(</span>g<span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token class-name">System</span><span class="token punctuation">.</span>out<span class="token punctuation">.</span><span class="token function">println</span><span class="token punctuation">(</span>h<span class="token punctuation">.</span><span class="token function">apply</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>  <span class="token comment">//输出3</span></code></pre><h3 id="流与集合"><a href="#流与集合" class="headerlink" title="流与集合"></a>流与集合</h3><h4 id="只能遍历一次"><a href="#只能遍历一次" class="headerlink" title="只能遍历一次"></a>只能遍历一次</h4><p>流和迭代器类似，只能遍历一次。遍历完后，这个流已经被消费掉了。</p><p>可以从原始数据源那里再获得一个新的流来重新遍历一遍，就像迭代器一样（这里假设它是集<br>合之类的可重复的源，如果是I/O通道就没戏了）。</p><h4 id="外部迭代与内部迭代"><a href="#外部迭代与内部迭代" class="headerlink" title="外部迭代与内部迭代"></a>外部迭代与内部迭代</h4><p>使用Collection接口需要用户去做迭代（比如用for-each），这称为外部迭代。 相反， Streams库使用内部迭代，它帮你把迭代做了，还把得到的流值存在了某个地方，你只要给出一个函数说要干什么就可以了。</p><h4 id="流操作"><a href="#流操作" class="headerlink" title="流操作"></a>流操作</h4><p>可以连接起来的流操作称为中间操作，关闭流的操作称为终端操作。</p><p>1）中间操作：一般都可以合并起来，在终端操作时一次性全部处理。</p><p>2）终端操作：会从流的流水线生成结果。其结果是任何不是流的值，比如List、Integer，甚<br>至void。</p><p><img src="https://raw.githubusercontent.com/zzugzj/blogImg/master/img/image-20210313225757611.png" alt="image-20210313225757611" loading="lazy"></p><h3 id="使用流"><a href="#使用流" class="headerlink" title="使用流"></a>使用流</h3><p>基本的一些流操作：filter筛选，distinct去重，limit截断，skip跳过</p><h4 id="映射"><a href="#映射" class="headerlink" title="映射"></a>映射</h4><p>1）对流中每一个元素应用函数：流支持map方法，它会接受一个函数作为参数。这个函数会被应用到每个元素上，并将其映射成一个新的元素（使用映射一词，是因为它和转换类似，但其中的细微差别在于它是“创建一 个新版本“，而不是去“修改”）。</p><pre class="language-java" data-language="java"><code class="language-java"><span class="token class-name">List</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">String</span><span class="token punctuation">></span></span> dishname <span class="token operator">=</span> list<span class="token punctuation">.</span><span class="token function">stream</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">map</span><span class="token punctuation">(</span><span class="token class-name">Dish</span><span class="token operator">::</span><span class="token function">getName</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">collect</span><span class="token punctuation">(</span><span class="token class-name">Collectors</span><span class="token punctuation">.</span><span class="token function">toList</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span></code></pre><p>2）流的扁平化</p><p>flatMap方法的效果是，各个数组并不是分别映射成一个流，而是映射成流的内容。flatmap方法让你把一个流中的每个值都换成另一个流，然后把所有的流连接起来成为一个流。</p><pre class="language-java" data-language="java"><code class="language-java"><span class="token class-name">Stream</span><span class="token operator">&lt;</span><span class="token keyword">int</span><span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token operator">></span> stream <span class="token operator">=</span> list1<span class="token punctuation">.</span><span class="token function">stream</span><span class="token punctuation">(</span><span class="token punctuation">)</span>     <span class="token comment">//使用flatMap</span>    <span class="token punctuation">.</span><span class="token function">flatMap</span><span class="token punctuation">(</span>i <span class="token operator">-></span> list2<span class="token punctuation">.</span><span class="token function">stream</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">map</span><span class="token punctuation">(</span>j <span class="token operator">-></span> <span class="token keyword">new</span> <span class="token keyword">int</span><span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">&#123;</span>i<span class="token punctuation">,</span> j<span class="token punctuation">&#125;</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token class-name">Stream</span><span class="token operator">&lt;</span><span class="token class-name">Stream</span><span class="token operator">&lt;</span><span class="token keyword">int</span><span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token operator">>></span> stream <span class="token operator">=</span> list1<span class="token punctuation">.</span><span class="token function">stream</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token comment">//使用map</span>    <span class="token punctuation">.</span><span class="token function">map</span><span class="token punctuation">(</span>i <span class="token operator">-></span> list2<span class="token punctuation">.</span><span class="token function">stream</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">map</span><span class="token punctuation">(</span>j <span class="token operator">-></span> <span class="token keyword">new</span> <span class="token keyword">int</span><span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">&#123;</span>i<span class="token punctuation">,</span> j<span class="token punctuation">&#125;</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span></code></pre><h4 id="归约"><a href="#归约" class="headerlink" title="归约"></a>归约</h4><p>即把集合中的元素反复结合起来，得到一个值，即将流归约为一个值，用函数式编程语言叫折叠。</p><p>1）元素求和：reduce方法</p><p><strong>reduce接受两个参数：</strong> </p><ol><li>一个初始值，这里是0；</li><li>一个BinaryOperator&lt;T&gt;来将两个元素结合起来产生一个新值。</li></ol><p>在Java 8中，Integer类现在有了一个静态的sum方法来对两个数求和，这恰好是我们想要的，用不着反复用Lambda写同一段代码了： </p><pre class="language-java" data-language="java"><code class="language-java"><span class="token keyword">int</span> sum <span class="token operator">=</span> numbers<span class="token punctuation">.</span><span class="token function">stream</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">reduce</span><span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token class-name">Integer</span><span class="token operator">::</span><span class="token function">sum</span><span class="token punctuation">)</span><span class="token punctuation">;</span></code></pre><p><strong>无初始值</strong> </p><p>reduce还有一个重载的变体，它不接受初始值，但是会返回一个Optional对象： </p><pre class="language-java" data-language="java"><code class="language-java"><span class="token class-name">Optional</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">Integer</span><span class="token punctuation">></span></span> sum <span class="token operator">=</span> numbers<span class="token punctuation">.</span><span class="token function">stream</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">reduce</span><span class="token punctuation">(</span><span class="token punctuation">(</span>a<span class="token punctuation">,</span> b<span class="token punctuation">)</span> <span class="token operator">-></span> <span class="token punctuation">(</span>a <span class="token operator">+</span> b<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span> </code></pre><p>为什么它返回一个Optional&lt;Integer&gt;呢？考虑流中没有任何元素的情况。reduce操作无法返回其和，因为它没有初始值。这就是为什么结果被包裹在一个Optional对象里，以表明和可能不存在。</p><p><strong>map和reduce的连接通常称为map-reduce模式，因Google用它来进行网络搜索而出名，因为它很容易并行化。</strong></p><h4 id="流操作：无状态和有状态"><a href="#流操作：无状态和有状态" class="headerlink" title="流操作：无状态和有状态"></a>流操作：无状态和有状态</h4><ul><li><p>map或filter等操作会从输入流中获取每一个元素，并在输出流中得到0或1个结果。这些操作一般都是无状态无状态的：它们没有内部状态（假设用户提供的Lambda或方法引用没有内部可变状态）。</p></li><li><p>reduce、sum、max等操作需要内部状态来累积结果。在上面的情况下，内部状态很小。在我们的例子里就是一个int或double。不管流中有多少元素要处理，内部状态都是有界的。</p></li><li><p>sort或distinct等操作一开始都和filter和map差不多——都是接受一个流，再生成一个流（中间操作），但有一个关键的区别。从流中排序和删除重复项时都需要知道先前的历史。例如，排序要求所有元素都放入缓冲区后才能给输出流加入一个项目，这一操作的存储要求是无界的。要是流比较大或是无限的，就可能会有问题（把质数流倒序会做什么呢？它应当返回最大的质数，但数学告诉我们它不存在）。我们把这些操作叫作有状态操作。</p></li></ul><p><img src="https://raw.githubusercontent.com/zzugzj/blogImg/master/img/image-20210314011758437.png" alt="image-20210314011758437" loading="lazy"></p><h4 id="数值流"><a href="#数值流" class="headerlink" title="数值流"></a>数值流</h4><p>我们在前面看到了可以使用reduce方法计算流中元素的总和。例如，你可以像下面这样计算菜单的热量： </p><pre class="language-java" data-language="java"><code class="language-java"><span class="token keyword">int</span> calories <span class="token operator">=</span> menu<span class="token punctuation">.</span><span class="token function">stream</span><span class="token punctuation">(</span><span class="token punctuation">)</span>                    <span class="token punctuation">.</span><span class="token function">map</span><span class="token punctuation">(</span><span class="token class-name">Dish</span><span class="token operator">::</span><span class="token function">getCalories</span><span class="token punctuation">)</span>                    <span class="token punctuation">.</span><span class="token function">reduce</span><span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token class-name">Integer</span><span class="token operator">::</span><span class="token function">sum</span><span class="token punctuation">)</span><span class="token punctuation">;</span></code></pre><p>这段代码的问题是，它有一个暗含的装箱成本。每个Integer都必须拆箱成一个原始类型，再进行求和。但 Stream API还提供了原始类型流特化，专门支持处理数值流的方法。</p><h5 id="原始类型流特化"><a href="#原始类型流特化" class="headerlink" title="原始类型流特化"></a>原始类型流特化</h5><p>Java 8引入了三个原始类型特化流接口来解决这个问题：IntStream、DoubleStream和LongStream，分别将流中的元素特化为int、long和double，从而避免了暗含的装箱成本。每个接口都带来了进行常用数值归约的新方法，比如对数值流求和的sum，找到最大元素的max。此外还有在必要时再把它们转换回对象流的方法。</p><ol><li><p><strong>映射到数值流</strong></p><p>将流转换为特化版本的常用方法是mapToInt、mapToDouble和mapToLong。这些方法和前面说的map方法的工作方式一样，只是它们返回的是一个特化流，而不是Stream&lt;T&gt;。</p><pre class="language-java" data-language="java"><code class="language-java"><span class="token keyword">int</span> calories <span class="token operator">=</span> menu<span class="token punctuation">.</span><span class="token function">stream</span><span class="token punctuation">(</span><span class="token punctuation">)</span>                    <span class="token punctuation">.</span><span class="token function">mapToInt</span><span class="token punctuation">(</span><span class="token class-name">Dish</span><span class="token operator">::</span><span class="token function">getCalories</span><span class="token punctuation">)</span>                     <span class="token punctuation">.</span><span class="token function">sum</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span></code></pre><p>这里，mapToInt会从每道菜中提取热量（用一个Integer表示），并返回一个IntStream（而不是一个Stream&lt;Integer&gt;）。<strong>如果流是空的，sum默认返回0。</strong>IntStream还支持其他的方便方法，如max、min、average等。</p></li><li><p><strong>转换回对象流</strong></p><p>由于IntStream的map操作接受的Lambda必须接受int并返回int，那有时可能会想把数值流转换回非特化流。</p><p>要把原始流转换成一般流（每个int都会装箱成一个Integer），可以使用boxed方法。</p><pre class="language-java" data-language="java"><code class="language-java"><span class="token class-name">IntStream</span> intStream <span class="token operator">=</span> menu<span class="token punctuation">.</span><span class="token function">stream</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">mapToInt</span><span class="token punctuation">(</span><span class="token class-name">Dish</span><span class="token operator">::</span><span class="token function">getCalories</span><span class="token punctuation">)</span><span class="token punctuation">;</span> <span class="token class-name">Stream</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">Integer</span><span class="token punctuation">></span></span> stream <span class="token operator">=</span> intStream<span class="token punctuation">.</span><span class="token function">boxed</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span></code></pre><h5 id="数值范围-amp-生成数"><a href="#数值范围-amp-生成数" class="headerlink" title="数值范围&amp;生成数"></a>数值范围&amp;生成数</h5></li></ol><p>Java 8引入了两个可以用于IntStream和LongStream的静态方法，帮助生成这种范围：range和rangeClosed。这两个方法都是第一个参数接受起始值，第二个参数接受结束值。但range是不包含结束值的：<code>[l, r)</code>，而rangeClosed则包含结束值：<code>[l, r]</code>。</p><pre class="language-java" data-language="java"><code class="language-java"><span class="token class-name">IntStream</span> evenNumbers <span class="token operator">=</span> <span class="token class-name">IntStream</span><span class="token punctuation">.</span><span class="token function">rangeClosed</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">100</span><span class="token punctuation">)</span>   <span class="token comment">//表示范围[1, 100]</span>                <span class="token punctuation">.</span><span class="token function">filter</span><span class="token punctuation">(</span>n <span class="token operator">-></span> n <span class="token operator">%</span> <span class="token number">2</span> <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token class-name">System</span><span class="token punctuation">.</span>out<span class="token punctuation">.</span><span class="token function">println</span><span class="token punctuation">(</span>evenNumbers<span class="token punctuation">.</span><span class="token function">count</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>  <span class="token comment">//50</span></code></pre><h4 id="构建流"><a href="#构建流" class="headerlink" title="构建流"></a>构建流</h4><ul><li><p>由值创建流</p><p>使用静态方法Stream.of，通过显式值创建一个流。</p><pre class="language-java" data-language="java"><code class="language-java"><span class="token class-name">Stream</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">String</span><span class="token punctuation">></span></span> stream <span class="token operator">=</span> <span class="token class-name">Stream</span><span class="token punctuation">.</span><span class="token function">of</span><span class="token punctuation">(</span><span class="token string">"Java 8 "</span><span class="token punctuation">,</span> <span class="token string">"Lambdas "</span><span class="token punctuation">,</span> <span class="token string">"In "</span><span class="token punctuation">,</span> <span class="token string">"Action"</span><span class="token punctuation">)</span><span class="token punctuation">;</span> stream<span class="token punctuation">.</span><span class="token function">map</span><span class="token punctuation">(</span><span class="token class-name">String</span><span class="token operator">::</span><span class="token function">toUpperCase</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">forEach</span><span class="token punctuation">(</span><span class="token class-name">System</span><span class="token punctuation">.</span>out<span class="token operator">::</span><span class="token function">println</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token class-name">Stream</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">String</span><span class="token punctuation">></span></span> emptyStream <span class="token operator">=</span> <span class="token class-name">Stream</span><span class="token punctuation">.</span><span class="token function">empty</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token comment">//空流</span></code></pre></li><li><p>由数组创建流</p><p>Arrays.stream从数组创建一个流。</p><pre class="language-java" data-language="java"><code class="language-java"><span class="token keyword">int</span><span class="token punctuation">[</span><span class="token punctuation">]</span> numbers <span class="token operator">=</span> <span class="token punctuation">&#123;</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">,</span> <span class="token number">7</span><span class="token punctuation">,</span> <span class="token number">11</span><span class="token punctuation">,</span> <span class="token number">13</span><span class="token punctuation">&#125;</span><span class="token punctuation">;</span> <span class="token keyword">int</span> sum <span class="token operator">=</span> <span class="token class-name">Arrays</span><span class="token punctuation">.</span><span class="token function">stream</span><span class="token punctuation">(</span>numbers<span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">sum</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span></code></pre></li><li><p>由文件生成流</p><p>Java中用于处理文件等I/O操作的NIO API（非阻塞 I/O）已更新，以便利用Stream API。java.nio.file.Files中的很多静态方法都会返回一个流。比如：<code>Files.lines</code>，它会返回一个由指定文件中的各行构成的字符串流。</p><pre class="language-java" data-language="java"><code class="language-java"><span class="token class-name">Pattern</span> pattern <span class="token operator">=</span> <span class="token class-name">Pattern</span><span class="token punctuation">.</span><span class="token function">compile</span><span class="token punctuation">(</span><span class="token string">"[a-zA-Z]+"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>   <span class="token comment">//统计一个英文文件中各个单词出现的次数，并排序</span><span class="token keyword">try</span> <span class="token punctuation">(</span><span class="token class-name">Stream</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">String</span><span class="token punctuation">></span></span> lines <span class="token operator">=</span> <span class="token class-name">Files</span><span class="token punctuation">.</span><span class="token function">lines</span><span class="token punctuation">(</span><span class="token class-name">Paths</span><span class="token punctuation">.</span><span class="token function">get</span><span class="token punctuation">(</span><span class="token string">"D:/data.txt"</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token class-name">Charset</span><span class="token punctuation">.</span><span class="token function">defaultCharset</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token punctuation">&#123;</span>    <span class="token keyword">final</span> <span class="token class-name">Map</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">String</span><span class="token punctuation">,</span> <span class="token class-name">Long</span><span class="token punctuation">></span></span> collect <span class="token operator">=</span> lines<span class="token punctuation">.</span><span class="token function">flatMap</span><span class="token punctuation">(</span>i <span class="token operator">-></span> <span class="token punctuation">&#123;</span>        <span class="token keyword">final</span> <span class="token class-name">String</span><span class="token punctuation">[</span><span class="token punctuation">]</span> s1 <span class="token operator">=</span> i<span class="token punctuation">.</span><span class="token function">split</span><span class="token punctuation">(</span><span class="token string">" "</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token keyword">for</span> <span class="token punctuation">(</span><span class="token keyword">int</span> j <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">;</span> j <span class="token operator">&lt;</span> s1<span class="token punctuation">.</span>length<span class="token punctuation">;</span> j<span class="token operator">++</span><span class="token punctuation">)</span> <span class="token punctuation">&#123;</span>            <span class="token keyword">final</span> <span class="token class-name">Matcher</span> matcher <span class="token operator">=</span> pattern<span class="token punctuation">.</span><span class="token function">matcher</span><span class="token punctuation">(</span>s1<span class="token punctuation">[</span>j<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">;</span>            s1<span class="token punctuation">[</span>j<span class="token punctuation">]</span> <span class="token operator">=</span> matcher<span class="token punctuation">.</span><span class="token function">find</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">?</span> matcher<span class="token punctuation">.</span><span class="token function">group</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">:</span> <span class="token string">""</span><span class="token punctuation">;</span>        <span class="token punctuation">&#125;</span>        <span class="token keyword">return</span> <span class="token class-name">Arrays</span><span class="token punctuation">.</span><span class="token function">stream</span><span class="token punctuation">(</span>s1<span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token punctuation">&#125;</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">collect</span><span class="token punctuation">(</span><span class="token class-name">Collectors</span><span class="token punctuation">.</span><span class="token function">groupingBy</span><span class="token punctuation">(</span>i <span class="token operator">-></span> i<span class="token punctuation">,</span> <span class="token class-name">Collectors</span><span class="token punctuation">.</span><span class="token function">counting</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token keyword">final</span> <span class="token class-name">ArrayList</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">Map<span class="token punctuation">.</span>Entry</span><span class="token punctuation">&lt;</span><span class="token class-name">String</span><span class="token punctuation">,</span> <span class="token class-name">Long</span><span class="token punctuation">></span><span class="token punctuation">></span></span> entries <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">ArrayList</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token punctuation">></span></span><span class="token punctuation">(</span>collect<span class="token punctuation">.</span><span class="token function">entrySet</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    entries<span class="token punctuation">.</span><span class="token function">sort</span><span class="token punctuation">(</span><span class="token class-name">Map<span class="token punctuation">.</span>Entry</span><span class="token punctuation">.</span><span class="token function">comparingByValue</span><span class="token punctuation">(</span><span class="token class-name">Comparator</span><span class="token punctuation">.</span><span class="token function">reverseOrder</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token class-name">System</span><span class="token punctuation">.</span>out<span class="token punctuation">.</span><span class="token function">println</span><span class="token punctuation">(</span>entries<span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token class-name">System</span><span class="token punctuation">.</span>out<span class="token punctuation">.</span><span class="token function">println</span><span class="token punctuation">(</span>entries<span class="token punctuation">.</span><span class="token function">stream</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">mapToLong</span><span class="token punctuation">(</span><span class="token class-name">Map<span class="token punctuation">.</span>Entry</span><span class="token operator">::</span><span class="token function">getValue</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">sum</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token punctuation">&#125;</span> <span class="token keyword">catch</span> <span class="token punctuation">(</span><span class="token class-name">IOException</span> ignore<span class="token punctuation">)</span> <span class="token punctuation">&#123;</span> <span class="token punctuation">&#125;</span></code></pre></li><li><p>由函数生成流：创建无限流</p><p>Stream API提供了两个静态方法来从函数生成流：Stream.iterate和Stream.generate。 这两个操作可以创建所谓的无限流：不像从固定集合创建的流那样有固定大小的流。由iterate 和generate产生的流会用给定的函数按需创建值，因此可以无穷无尽地计算下去！<strong>必须使用limit(n)来对这种流加以限制。</strong></p><pre class="language-java" data-language="java"><code class="language-java"><span class="token class-name">IntStream</span><span class="token punctuation">.</span><span class="token function">iterate</span><span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> a <span class="token operator">-></span> a <span class="token operator">+</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">limit</span><span class="token punctuation">(</span><span class="token number">10</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">forEach</span><span class="token punctuation">(</span><span class="token class-name">System</span><span class="token punctuation">.</span>out<span class="token operator">::</span><span class="token function">println</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token class-name">IntStream</span><span class="token punctuation">.</span><span class="token function">generate</span><span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">-></span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">limit</span><span class="token punctuation">(</span><span class="token number">10</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">forEach</span><span class="token punctuation">(</span><span class="token class-name">System</span><span class="token punctuation">.</span>out<span class="token operator">::</span><span class="token function">println</span><span class="token punctuation">)</span><span class="token punctuation">;</span></code></pre><p>iterate方法接受一个初始值（在这里是0），还有一个依次应用在每个产生的新值上的Lambda（UnaryOperator&lt;t&gt;类型）。</p><p>generate接受一个Supplier&lt;T&gt;类型的Lambda提供新的值。</p></li></ul><h3 id="用流收集数据"><a href="#用流收集数据" class="headerlink" title="用流收集数据"></a>用流收集数据</h3><h4 id="归约和汇总"><a href="#归约和汇总" class="headerlink" title="归约和汇总"></a>归约和汇总</h4><p><strong>maxBy/minBy：</strong>计算流中的最大或最小值。</p><p><strong>summingInt/summingLong/summingDouble：</strong>生成一个用于求元素和的Collector，首先通过给定的mapper将元素转换类型，然后再求和。参数的作用就是将元素转换为指定的类型，最后结果与转换后类型一致。</p><pre class="language-java" data-language="java"><code class="language-java"><span class="token keyword">int</span> i <span class="token operator">=</span> list<span class="token punctuation">.</span><span class="token function">stream</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">limit</span><span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">collect</span><span class="token punctuation">(</span><span class="token class-name">Collectors</span><span class="token punctuation">.</span><span class="token function">summingInt</span><span class="token punctuation">(</span><span class="token class-name">Integer</span><span class="token operator">::</span><span class="token function">valueOf</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token comment">//list中String转为int求和</span><span class="token keyword">int</span> totalCalories <span class="token operator">=</span> menu<span class="token punctuation">.</span><span class="token function">stream</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">collect</span><span class="token punctuation">(</span><span class="token function">summingInt</span><span class="token punctuation">(</span><span class="token class-name">Dish</span><span class="token operator">::</span><span class="token function">getCalories</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token comment">//类获取属性求和</span></code></pre><p><strong>averagingInt/averagingLong/averagingDouble：</strong>生成一个用于求元素平均值的Collector，首选通过参数将元素转换为指定的类型。用法和上面差不多。</p><p><strong>joining：</strong>joining工厂方法返回的收集器会把对流中每一个对象应用toString方法得到的所有字符串连接成一个字符串。在内部使用了StringBuilder来把生成的字符串逐个追加起来。可以指定连接符，甚至是结果的前后缀。</p><pre class="language-java" data-language="java"><code class="language-java"><span class="token class-name">String</span> shortMenu <span class="token operator">=</span> menu<span class="token punctuation">.</span><span class="token function">stream</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">map</span><span class="token punctuation">(</span><span class="token class-name">Dish</span><span class="token operator">::</span><span class="token function">getName</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">collect</span><span class="token punctuation">(</span><span class="token function">joining</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token class-name">String</span> shortMenu <span class="token operator">=</span> menu<span class="token punctuation">.</span><span class="token function">stream</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">map</span><span class="token punctuation">(</span><span class="token class-name">Dish</span><span class="token operator">::</span><span class="token function">getName</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">collect</span><span class="token punctuation">(</span><span class="token function">joining</span><span class="token punctuation">(</span><span class="token string">", "</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token class-name">String</span> sss <span class="token operator">=</span> list<span class="token punctuation">.</span><span class="token function">stream</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">collect</span><span class="token punctuation">(</span><span class="token class-name">Collectors</span><span class="token punctuation">.</span><span class="token function">joining</span><span class="token punctuation">(</span><span class="token string">"-"</span><span class="token punctuation">,</span><span class="token string">"S"</span><span class="token punctuation">,</span><span class="token string">"E"</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span></code></pre><h4 id="reducing"><a href="#reducing" class="headerlink" title="reducing"></a>reducing</h4><p>我们已经讨论的所有收集器，都是一个可以用reducing工厂方法定义的归约过程的特殊情况而已。Collectors.reducing工厂方法是所有这些特殊情况的一般化。可以说，先前讨论的案例仅仅是为了方便程序员而已。</p><p>它需要三个参数。 </p><ul><li>第一个参数是归约操作的起始值，也是流中没有元素时的返回值，所以很显然对于数值和而言0是一个合适的值。 </li><li>第二个参数就是应用于每个输入值的映射函数。</li><li>第三个参数是一个BinaryOperator，将两个项目累积成一个同类型的值。这里它就是对两个int求和。</li></ul><h4 id="分组"><a href="#分组" class="headerlink" title="分组"></a>分组</h4><p>给groupingBy方法传递了一个Function（以方法引用的形式），它提取了流中每 一道Dish的Dish.Type。</p><p>我们把这个Function叫作分类函数，因为它用来把流中的元素分成不同的组。</p><p>分组操作的结果是一个Map，把分组函数返回的值作为映射的键，把流中所有具有这个分类值的项目的列表作为对应的映射值。</p><p><img src="https://raw.githubusercontent.com/zzugzj/blogImg/master/img/image-20210316090243757.png" alt="image-20210316090243757" loading="lazy"></p><pre class="language-java" data-language="java"><code class="language-java"><span class="token class-name">Map</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">Integer</span><span class="token punctuation">,</span> <span class="token class-name">List</span><span class="token punctuation">&lt;</span><span class="token class-name">String</span><span class="token punctuation">></span><span class="token punctuation">></span></span> collect <span class="token operator">=</span> lists<span class="token punctuation">.</span><span class="token function">stream</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">collect</span><span class="token punctuation">(</span><span class="token class-name">Collectors</span><span class="token punctuation">.</span><span class="token function">groupingBy</span><span class="token punctuation">(</span><span class="token class-name">String</span><span class="token operator">::</span><span class="token function">length</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span></code></pre><p><strong>多级分组</strong></p><p>要实现多级分组，我们可以使用一个由双参数版本的Collectors.groupingBy工厂方法创建的收集器，它除了普通的分类函数之外，还可以接受collector类型的第二个参数。那么要进行二级分组的话，我们可以把一个内层groupingBy传递给外层groupingBy，并定义一个为流<br>中项目分类的二级标准。</p><pre class="language-java" data-language="java"><code class="language-java">lists<span class="token punctuation">.</span><span class="token function">stream</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">collect</span><span class="token punctuation">(</span><span class="token class-name">Collectors</span><span class="token punctuation">.</span><span class="token function">groupingBy</span><span class="token punctuation">(</span><span class="token class-name">String</span><span class="token operator">::</span><span class="token function">hashCode</span><span class="token punctuation">,</span> <span class="token class-name">Collectors</span><span class="token punctuation">.</span><span class="token function">groupingBy</span><span class="token punctuation">(</span><span class="token class-name">String</span><span class="token operator">::</span><span class="token function">length</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span></code></pre><p><strong>按子组收集数据</strong></p><p>groupingBy的第二个参数可以是Collector，所以除了多级分组还有别的用处。</p><p>比如查询某种菜的数量：</p><pre class="language-java" data-language="java"><code class="language-java"><span class="token class-name">Map</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">Dish<span class="token punctuation">.</span>Type</span><span class="token punctuation">,</span> <span class="token class-name">Long</span><span class="token punctuation">></span></span> typesCount <span class="token operator">=</span> menu<span class="token punctuation">.</span><span class="token function">stream</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">collect</span><span class="token punctuation">(</span><span class="token function">groupingBy</span><span class="token punctuation">(</span><span class="token class-name">Dish</span><span class="token operator">::</span><span class="token function">getType</span><span class="token punctuation">,</span> <span class="token function">counting</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token comment">//返回：&#123;MEAT=3, FISH=2, OTHER=4&#125;</span></code></pre><p><strong>把收集器的结果转换为另一种类型</strong> </p><pre class="language-java" data-language="java"><code class="language-java"><span class="token class-name">Map</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">Dish<span class="token punctuation">.</span>Type</span><span class="token punctuation">,</span> <span class="token class-name">Dish</span><span class="token punctuation">></span></span> mostCaloricByType <span class="token operator">=</span> <span class="token class-name">Dish</span><span class="token punctuation">.</span>menu<span class="token punctuation">.</span><span class="token function">stream</span><span class="token punctuation">(</span><span class="token punctuation">)</span>                        <span class="token punctuation">.</span><span class="token function">collect</span><span class="token punctuation">(</span><span class="token function">groupingBy</span><span class="token punctuation">(</span><span class="token class-name">Dish</span><span class="token operator">::</span><span class="token function">getType</span><span class="token punctuation">,</span>                                <span class="token function">collectingAndThen</span><span class="token punctuation">(</span>                                        <span class="token function">maxBy</span><span class="token punctuation">(</span><span class="token function">comparingInt</span><span class="token punctuation">(</span><span class="token class-name">Dish</span><span class="token operator">::</span><span class="token function">getCalories</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span>                                        <span class="token class-name">Optional</span><span class="token operator">::</span><span class="token function">get</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span></code></pre><h4 id="分区"><a href="#分区" class="headerlink" title="分区"></a>分区</h4><p>分区是分组的特殊情况：由一个谓词（返回一个布尔值的函数）作为分类函数，它称分区函数。分区函数返回一个布尔值，这意味着得到的分组Map的键类型是Boolean，于是它最多可以分为两组——true是一组，false是一组。</p><pre class="language-java" data-language="java"><code class="language-java"><span class="token class-name">Map</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">Boolean</span><span class="token punctuation">,</span> <span class="token class-name">List</span><span class="token punctuation">&lt;</span><span class="token class-name">Dish</span><span class="token punctuation">></span><span class="token punctuation">></span></span> partitionedMenu <span class="token operator">=</span>              menu<span class="token punctuation">.</span><span class="token function">stream</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">collect</span><span class="token punctuation">(</span><span class="token function">partitioningBy</span><span class="token punctuation">(</span><span class="token class-name">Dish</span><span class="token operator">::</span><span class="token function">isVegetarian</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span></code></pre><h3 id="用Optinal取代null"><a href="#用Optinal取代null" class="headerlink" title="用Optinal取代null"></a>用Optinal取代null</h3><p>变量存在时，Optional类只是对类简单封装。变量不存在时，缺失的值会被建模成一个“空” 的Optional对象，由方法<code>Optional.empty()</code>返回。<br><code>Optional.empty()</code>方法是一个静态工厂 方法，它返回Optional类的特定单一实例。：如果你尝试引用一个null，一定会触发NullPointerException，不过使用<code>Optional.empty()</code>就完全没事儿，它是Optional类的一个有效对象，多种场景都能调用，非 常有用。</p><ol><li><p>创建Optional对象</p><ol><li><p>声明一个空的Optional ,可以通过静态工厂方法Optional.empty，创建一个空的Optional 对象： </p><pre class="language-java" data-language="java"><code class="language-java"><span class="token class-name">Optional</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">Car</span><span class="token punctuation">></span></span> optCar <span class="token operator">=</span> <span class="token class-name">Optional</span><span class="token punctuation">.</span><span class="token function">empty</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span></code></pre></li><li><p>依据一个非空值创建Optional :还可以使用静态工厂方法Optional.of，依据一个非空值创建一个Optional对象： </p><pre class="language-java" data-language="java"><code class="language-java"><span class="token class-name">Optional</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">Car</span><span class="token punctuation">></span></span> optCar <span class="token operator">=</span> <span class="token class-name">Optional</span><span class="token punctuation">.</span><span class="token function">of</span><span class="token punctuation">(</span>car<span class="token punctuation">)</span><span class="token punctuation">;</span></code></pre></li><li><p>可接受null的Optional ,使用静态工厂方法Optional.ofNullable，你可以创建一个允许null值的Optional 对象： </p><pre class="language-java" data-language="java"><code class="language-java"><span class="token class-name">Optional</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">Car</span><span class="token punctuation">></span></span> optCar <span class="token operator">=</span> <span class="token class-name">Optional</span><span class="token punctuation">.</span><span class="token function">ofNullable</span><span class="token punctuation">(</span>car<span class="token punctuation">)</span><span class="token punctuation">;</span></code></pre></li></ol></li><li><p>使用map 从 Optional 对象中提取和转换值 </p><pre class="language-java" data-language="java"><code class="language-java"><span class="token class-name">Optional</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">Insurance</span><span class="token punctuation">></span></span> optInsurance <span class="token operator">=</span> <span class="token class-name">Optional</span><span class="token punctuation">.</span><span class="token function">ofNullable</span><span class="token punctuation">(</span>insurance<span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token class-name">Optional</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">String</span><span class="token punctuation">></span></span> name <span class="token operator">=</span> optInsurance<span class="token punctuation">.</span><span class="token function">map</span><span class="token punctuation">(</span><span class="token class-name">Insurance</span><span class="token operator">::</span><span class="token function">getName</span><span class="token punctuation">)</span><span class="token punctuation">;</span></code></pre></li><li><p>默认行为即解引用的Optional对象</p><ol><li><code>get()</code>是这些方法中最简单但又最不安全的方法。如果变量存在，它直接返回封装的变量 值，否则就抛出一个NoSuchElementException异常。所以，除非你非常确定Optional 变量一定包含值，否则使用这个方法是个相当糟糕的主意。此外，这种方式即便相对于 嵌套式的null检查，也并未体现出多大的改进。</li><li><code>orElse(T other)</code>它允许你在 Optional对象不包含值时提供一个默认值。</li><li><code>orElseGet(Supplier&lt;? extends T&gt; other)</code>是orElse方法的延迟调用版，Supplier 方法只有在Optional对象不含值时才执行调用。如果创建默认值是件耗时费力的工作， 你应该考虑采用这种方式（借此提升程序的性能），或者你需要非常确定某个方法仅在 Optional为空时才进行调用，也可以考虑该方式（这种情况有严格的限制条件）。</li><li><code>orElseThrow(Supplier&lt;? extends X&gt; exceptionSupplier)</code>和get方法非常类似， 它们遭遇Optional对象为空时都会抛出一个异常，但是使用orElseThrow你可以定制希 望抛出的异常类型。</li><li><code>ifPresent(Consumer&lt;? super T&gt;)</code>让你能在变量值存在时执行一个作为参数传入的 方法，否则就不进行任何操作。 </li></ol></li></ol><h3 id="新的日期和时间API"><a href="#新的日期和时间API" class="headerlink" title="新的日期和时间API"></a>新的日期和时间API</h3><h4 id="LocalDate、LocalTime、Instant、Duration-以及-Period"><a href="#LocalDate、LocalTime、Instant、Duration-以及-Period" class="headerlink" title="LocalDate、LocalTime、Instant、Duration 以及 Period"></a>LocalDate、LocalTime、Instant、Duration 以及 Period</h4><p><strong>LocalDate、LocalTime</strong></p><p>通过静态工厂方法of创建一个实例。</p><pre class="language-java" data-language="java"><code class="language-java"><span class="token class-name">LocalDate</span> localDate <span class="token operator">=</span> <span class="token class-name">LocalDate</span><span class="token punctuation">.</span><span class="token function">of</span><span class="token punctuation">(</span><span class="token number">2021</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">16</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token class-name">LocalTime</span> localTime <span class="token operator">=</span> <span class="token class-name">LocalTime</span><span class="token punctuation">.</span><span class="token function">parse</span><span class="token punctuation">(</span><span class="token string">"21:55:32"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>  <span class="token comment">//LocalDate.parse("2021-12-12");</span><span class="token class-name">LocalDateTime</span> localDateTime1 <span class="token operator">=</span> localDate<span class="token punctuation">.</span><span class="token function">atTime</span><span class="token punctuation">(</span>localTime<span class="token punctuation">)</span><span class="token punctuation">;</span>  <span class="token comment">//也有：localTime.atDate(date)</span><span class="token class-name">LocalDateTime</span> localDateTime <span class="token operator">=</span> <span class="token class-name">LocalDateTime</span><span class="token punctuation">.</span><span class="token function">now</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token class-name">LocalDate</span> localDate1 <span class="token operator">=</span> localDateTime<span class="token punctuation">.</span><span class="token function">toLocalDate</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>  <span class="token comment">//获取LocalDate或LocalTime</span>localDateTime<span class="token punctuation">.</span><span class="token function">getYear</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>   <span class="token comment">//直接读取</span>localDateTime<span class="token punctuation">.</span><span class="token function">get</span><span class="token punctuation">(</span><span class="token class-name">ChronoField</span><span class="token punctuation">.</span>DAY_OF_WEEK<span class="token punctuation">)</span><span class="token punctuation">;</span>  <span class="token comment">//使用ChronoField读取值  可以读取到各种需要的值</span></code></pre><p><strong>机器的日期和时间格式：Instant</strong></p><p>你可以通过向静态工厂方法ofEpochSecond传递一个代表秒数的值创建一个该类的实例。</p><p>Instant类也支持静态工厂方法now，它能够帮你获取当前时刻的时间戳</p><pre class="language-java" data-language="java"><code class="language-java"><span class="token class-name">Instant</span><span class="token punctuation">.</span><span class="token function">ofEpochSecond</span><span class="token punctuation">(</span><span class="token number">12</span><span class="token punctuation">,</span> <span class="token number">32</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token comment">//从UNIX元年1970年1月1日，往后12秒，再加上32纳秒，第二个参数可以是负数，意思是减去</span></code></pre><p><strong>定义 Duration 或 Period</strong></p><p>Duration类的静态工厂方法between就是为求两个时间中间差而设计的。可以创建两个LocalTimes对象、两个LocalDateTimes对象，或者两个Instant对象之间的duration。但不能混着创建，比如求LocalDateTimes和Instant对象之间的duration。</p><pre class="language-java" data-language="java"><code class="language-java"><span class="token class-name">Duration</span> d1 <span class="token operator">=</span> <span class="token class-name">Duration</span><span class="token punctuation">.</span><span class="token function">between</span><span class="token punctuation">(</span>time1<span class="token punctuation">,</span> time2<span class="token punctuation">)</span><span class="token punctuation">;</span> <span class="token class-name">Duration</span> d1 <span class="token operator">=</span> <span class="token class-name">Duration</span><span class="token punctuation">.</span><span class="token function">between</span><span class="token punctuation">(</span>dateTime1<span class="token punctuation">,</span> dateTime2<span class="token punctuation">)</span><span class="token punctuation">;</span> <span class="token class-name">Duration</span> d2 <span class="token operator">=</span> <span class="token class-name">Duration</span><span class="token punctuation">.</span><span class="token function">between</span><span class="token punctuation">(</span>instant1<span class="token punctuation">,</span> instant2<span class="token punctuation">)</span><span class="token punctuation">;</span></code></pre><p>但Duration不能求两个LocalDate间的时差，如果你需要以年、月或者日的方式对多个时间单位建模，可以使用Period类。使用该类的工厂方法between，你可以使用得到两个LocalDate之间的时长。</p><pre class="language-java" data-language="java"><code class="language-java"><span class="token class-name">Period</span> tenDays <span class="token operator">=</span> <span class="token class-name">Period</span><span class="token punctuation">.</span><span class="token function">between</span><span class="token punctuation">(</span><span class="token class-name">LocalDate</span><span class="token punctuation">.</span><span class="token function">of</span><span class="token punctuation">(</span><span class="token number">2014</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">8</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token class-name">LocalDate</span><span class="token punctuation">.</span><span class="token function">of</span><span class="token punctuation">(</span><span class="token number">2014</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">18</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span></code></pre><p>Duration和Period类都提供了很多非常方便的工厂类，直接创建对应的实例：</p><pre class="language-java" data-language="java"><code class="language-java"><span class="token class-name">Duration</span> threeMinutes <span class="token operator">=</span> <span class="token class-name">Duration</span><span class="token punctuation">.</span><span class="token function">ofMinutes</span><span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token class-name">Duration</span> threeMinutes <span class="token operator">=</span> <span class="token class-name">Duration</span><span class="token punctuation">.</span><span class="token function">of</span><span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token class-name">ChronoUnit</span><span class="token punctuation">.</span>MINUTES<span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token class-name">Period</span> tenDays <span class="token operator">=</span> <span class="token class-name">Period</span><span class="token punctuation">.</span><span class="token function">ofDays</span><span class="token punctuation">(</span><span class="token number">10</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token class-name">Period</span> threeWeeks <span class="token operator">=</span> <span class="token class-name">Period</span><span class="token punctuation">.</span><span class="token function">ofWeeks</span><span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token class-name">Period</span> twoYearsSixMonthsOneDay <span class="token operator">=</span> <span class="token class-name">Period</span><span class="token punctuation">.</span><span class="token function">of</span><span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">6</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">;</span></code></pre><p><img src="https://raw.githubusercontent.com/zzugzj/blogImg/master/img/image-20210316222100864.png" alt="image-20210316222100864" loading="lazy"></p><p><img src="https://raw.githubusercontent.com/zzugzj/blogImg/master/img/image-20210316222143103.png" alt="image-20210316222143103" loading="lazy"></p><h4 id="操纵、解析和格式化日期"><a href="#操纵、解析和格式化日期" class="headerlink" title="操纵、解析和格式化日期"></a>操纵、解析和格式化日期</h4><p>这些日期对象比如LocalDate以及其内的年月日属性都是final的，也就是说要修改返回的肯定是一个新的对象，保证了线程安全。</p><pre class="language-java" data-language="java"><code class="language-java"><span class="token class-name">LocalDate</span> date1 <span class="token operator">=</span> <span class="token class-name">LocalDate</span><span class="token punctuation">.</span><span class="token function">of</span><span class="token punctuation">(</span><span class="token number">2014</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">18</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token class-name">LocalDate</span> date2 <span class="token operator">=</span> date1<span class="token punctuation">.</span><span class="token function">withYear</span><span class="token punctuation">(</span><span class="token number">2011</span><span class="token punctuation">)</span><span class="token punctuation">;</span>  <span class="token comment">//2011-03-18</span><span class="token class-name">LocalDate</span> date3 <span class="token operator">=</span> date2<span class="token punctuation">.</span><span class="token function">withDayOfMonth</span><span class="token punctuation">(</span><span class="token number">25</span><span class="token punctuation">)</span><span class="token punctuation">;</span>  <span class="token comment">//2011-03-25</span><span class="token class-name">LocalDate</span> date4 <span class="token operator">=</span> date3<span class="token punctuation">.</span><span class="token keyword">with</span><span class="token punctuation">(</span><span class="token class-name">ChronoField</span><span class="token punctuation">.</span>MONTH_OF_YEAR<span class="token punctuation">,</span> <span class="token number">9</span><span class="token punctuation">)</span><span class="token punctuation">;</span>  <span class="token comment">//2011-09-25</span><span class="token class-name">LocalDate</span> date5 <span class="token operator">=</span> date1<span class="token punctuation">.</span><span class="token function">plusWeeks</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">;</span>  <span class="token comment">//2014-3-25</span><span class="token class-name">LocalDate</span> date6 <span class="token operator">=</span> date2<span class="token punctuation">.</span><span class="token function">minusYears</span><span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">;</span>  <span class="token comment">//2011-03-25</span><span class="token class-name">LocalDate</span> date7 <span class="token operator">=</span> date3<span class="token punctuation">.</span><span class="token function">plus</span><span class="token punctuation">(</span><span class="token number">6</span><span class="token punctuation">,</span> <span class="token class-name">ChronoUnit</span><span class="token punctuation">.</span>MONTHS<span class="token punctuation">)</span><span class="token punctuation">;</span>  <span class="token comment">//2011-09-25</span></code></pre><p>像LocalDate、LocalTime、LocalDateTime以及Instant这样表示时间点的日期时间类提供了大量通用的方法的总结：</p><p><img src="https://raw.githubusercontent.com/zzugzj/blogImg/master/img/image-20210316222644795.png" alt="image-20210316222644795" loading="lazy"></p><p><strong>使用 TemporalAdjuster</strong></p><p>有的时候，你需要进行一些更加复杂的操作，比如，将日期调整到下个周日、下个工作日，或者是本月的最后一天。这时，使用重载版本的with方法，向其传递一个提供了更多定制化选择的TemporalAdjuster对象，更加灵活地处理日期。最常见的用例，日期和时间API已经提供了大量预定义的TemporalAdjuster。可以通过TemporalAdjuster类的静态工厂方法访问它们，如下所示：</p><pre class="language-java" data-language="java"><code class="language-java"><span class="token class-name">LocalDate</span> date1 <span class="token operator">=</span> <span class="token class-name">LocalDate</span><span class="token punctuation">.</span><span class="token function">of</span><span class="token punctuation">(</span><span class="token number">2014</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">18</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token class-name">LocalDate</span> date2 <span class="token operator">=</span> date1<span class="token punctuation">.</span><span class="token keyword">with</span><span class="token punctuation">(</span><span class="token class-name">TemporalAdjusters</span><span class="token punctuation">.</span><span class="token function">nextOrSame</span><span class="token punctuation">(</span><span class="token class-name">DayOfWeek</span><span class="token punctuation">.</span>SUNDAY<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>  <span class="token comment">//2014-03-23</span><span class="token class-name">LocalDate</span> date3 <span class="token operator">=</span> date2<span class="token punctuation">.</span><span class="token keyword">with</span><span class="token punctuation">(</span><span class="token class-name">TemporalAdjusters</span><span class="token punctuation">.</span><span class="token function">lastDayOfMonth</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>  <span class="token comment">//2014-03-31</span></code></pre><p><img src="https://raw.githubusercontent.com/zzugzj/blogImg/master/img/image-20210316223131490.png" alt="image-20210316223131490" loading="lazy"></p><p>若是没有从表中找到自己需要的方法，那也可以自己定义TemporalAdjuster。</p><p><strong>打印输出及解析日期-时间对象</strong></p><p>处理日期和时间对象时，格式化以及解析日期-时间对象是另一个非常重要的功能。新的<code>java.time.format</code>包就是特别为这个目的而设计的。这个包中，最重要的类是<code>DateTime- Formatter</code>。创建格式器最简单的方法是通过它的静态工厂方法以及常量。像<code>ASIC_ISO_DATE</code>和<code>ISO_LOCAL_DATE</code>这样的常量是<code>DateTimeFormatter</code>类的预定义实例。所有的<code>DateTimeFormatter</code>实例都能用于以一定的格式创建代表特定日期或时间的字符串。</p><pre class="language-java" data-language="java"><code class="language-java"><span class="token class-name">LocalDate</span> date <span class="token operator">=</span> <span class="token class-name">LocalDate</span><span class="token punctuation">.</span><span class="token function">of</span><span class="token punctuation">(</span><span class="token number">2014</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">18</span><span class="token punctuation">)</span><span class="token punctuation">;</span>  <span class="token class-name">String</span> s1 <span class="token operator">=</span> date<span class="token punctuation">.</span><span class="token function">format</span><span class="token punctuation">(</span><span class="token class-name">DateTimeFormatter</span><span class="token punctuation">.</span>BASIC_ISO_DATE<span class="token punctuation">)</span><span class="token punctuation">;</span> <span class="token comment">//20140318</span><span class="token class-name">String</span> s2 <span class="token operator">=</span> date<span class="token punctuation">.</span><span class="token function">format</span><span class="token punctuation">(</span><span class="token class-name">DateTimeFormatter</span><span class="token punctuation">.</span>ISO_LOCAL_DATE<span class="token punctuation">)</span><span class="token punctuation">;</span> <span class="token comment">//2014-03-18</span><span class="token class-name">LocalDate</span> date1 <span class="token operator">=</span> <span class="token class-name">LocalDate</span><span class="token punctuation">.</span><span class="token function">parse</span><span class="token punctuation">(</span><span class="token string">"20140318"</span><span class="token punctuation">,</span> <span class="token class-name">DateTimeFormatter</span><span class="token punctuation">.</span>BASIC_ISO_DATE<span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token class-name">LocalDate</span> date2 <span class="token operator">=</span> <span class="token class-name">LocalDate</span><span class="token punctuation">.</span><span class="token function">parse</span><span class="token punctuation">(</span><span class="token string">"2014-03-18"</span><span class="token punctuation">,</span> <span class="token class-name">DateTimeFormatter</span><span class="token punctuation">.</span>ISO_LOCAL_DATE<span class="token punctuation">)</span><span class="token punctuation">;</span></code></pre><p>所有的DateTimeFormatter实例都是线程安全的。所以，你能够以单例模式创建格式器实例，就像DateTimeFormatter所定义的那些常量，并能在多个线程间共享这些实例。</p><pre class="language-java" data-language="java"><code class="language-java"><span class="token class-name">DateTimeFormatter</span> formatter <span class="token operator">=</span> <span class="token class-name">DateTimeFormatter</span><span class="token punctuation">.</span><span class="token function">ofPattern</span><span class="token punctuation">(</span><span class="token string">"dd/MM/yyyy"</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token class-name">LocalDate</span> date1 <span class="token operator">=</span> <span class="token class-name">LocalDate</span><span class="token punctuation">.</span><span class="token function">of</span><span class="token punctuation">(</span><span class="token number">2014</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">18</span><span class="token punctuation">)</span><span class="token punctuation">;</span>  <span class="token comment">//  18/03/2014</span><span class="token class-name">String</span> formattedDate <span class="token operator">=</span> date1<span class="token punctuation">.</span><span class="token function">format</span><span class="token punctuation">(</span>formatter<span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token class-name">LocalDate</span> date2 <span class="token operator">=</span> <span class="token class-name">LocalDate</span><span class="token punctuation">.</span><span class="token function">parse</span><span class="token punctuation">(</span>formattedDate<span class="token punctuation">,</span> formatter<span class="token punctuation">)</span><span class="token punctuation">;</span>  <span class="token comment">//特殊格式转LocalDate  2014-03-18</span></code></pre>]]></content>
    
    
    <summary type="html">Java 8中的新增功能是自Java 1.0发布18年以来，Java发生的最大变化。没有去掉任何东西，因此你现有的Java代码都能工作，但新功能提供了强大的新语汇和新设计模式，能帮助你编写更清楚、更简洁的代码。</summary>
    
    
    
    <category term="Java基础" scheme="https://zzugzj.github.io/categories/Java%E5%9F%BA%E7%A1%80/"/>
    
    
    <category term="Java基础" scheme="https://zzugzj.github.io/tags/Java%E5%9F%BA%E7%A1%80/"/>
    
  </entry>
  
  <entry>
    <title>Maven实战笔记</title>
    <link href="https://zzugzj.github.io/posts/a0d99dad/"/>
    <id>https://zzugzj.github.io/posts/a0d99dad/</id>
    <published>2021-03-03T10:58:39.000Z</published>
    <updated>2021-03-09T00:30:17.904Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><h1 id="第二章-Maven使用入门"><a href="#第二章-Maven使用入门" class="headerlink" title="第二章 Maven使用入门"></a>第二章 Maven使用入门</h1><h2 id="编写POM"><a href="#编写POM" class="headerlink" title="编写POM"></a>编写POM</h2><p>POM(Project Object Model， 项目对象模型)定义了项目的基本信息，用于描述项目如何构建，声明项目依赖等等。</p><p>实例：</p><pre class="language-xml" data-language="xml"><code class="language-xml"><span class="token prolog">&lt;?xml version="1.0" encoding="utf-8" ?></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>project</span> <span class="token attr-name">xmlns</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>http://maven.apache.org/POM/4.0.0<span class="token punctuation">"</span></span>    <span class="token attr-name"><span class="token namespace">xmlns:</span>xsi</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>http://www.w3.org/2001/XMLSchema-instance<span class="token punctuation">"</span></span>    <span class="token attr-name"><span class="token namespace">xsi:</span>schemaLocation</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>http://maven.apache.org/POM/4.0.0    http://maven.apache.org/maven-v4_0_0.xsd<span class="token punctuation">"</span></span><span class="token punctuation">></span></span>        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>modelVersion</span><span class="token punctuation">></span></span>4.0.0<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>modelVersion</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>groupId</span><span class="token punctuation">></span></span>com.gzj.testMaven<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>groupId</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>artifactId</span><span class="token punctuation">></span></span>hello-world<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>artifactId</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>version</span><span class="token punctuation">></span></span>1.0-SNAPSHOT<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>version</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">></span></span>my maven project<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>project</span><span class="token punctuation">></span></span></code></pre><p>第一行是XML头，指定了文档版本和编码方式。后面的project是所有pom.xml的根元素，它还声明了一些POM相关的命名空间和xsd元素，可以帮助我们快速编辑POM。</p><p>modelVersion：指定当前POM模型的版本，对于Maven2和Maven3来说，它只能是4.0.0。</p><p>groupId，artifactId，version这三个元素定义了一个项目的基本坐标。</p><ul><li><p>groupId：定义了项目属于那个组，这个组和项目所在的组织或公司存在关联。</p></li><li><p>artifactId：定义了当前项目在组的唯一ID，因为可能有不同的子模块，所以要分配不同的artifactId。</p></li><li><p>version：指定了项目的当前版本。</p></li></ul><p>name：声明一个对用户更友好的项目名称，虽然不必须，但推荐写，方便信息交流。</p><h2 id="编写主代码"><a href="#编写主代码" class="headerlink" title="编写主代码"></a>编写主代码</h2><p>项目主代码和测试代码不同，项目的主代码会被打包，而测试代码只会在运行测试时用到，不会被打包。默认情况下，maven约定项目的主代码位于src/main/java目录。</p><p>代码编写完毕后，使用Maven编译，在项目根目录下运行mvn clean compile。</p><p>clean是告诉maven清除输出目录target/，compile告诉maven编译项目主代码。</p><h2 id="编写测试代码"><a href="#编写测试代码" class="headerlink" title="编写测试代码"></a>编写测试代码</h2><p>测试代码位于src/test/java目录。测试一般使用JUnit，需要在pom文件新增一个JUnit依赖。</p><pre class="language-xml" data-language="xml"><code class="language-xml">新增：<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>dependencies</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>dependency</span><span class="token punctuation">></span></span>        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>groupId</span><span class="token punctuation">></span></span>junit<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>groupId</span><span class="token punctuation">></span></span>        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>artifactId</span><span class="token punctuation">></span></span>junit<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>artifactId</span><span class="token punctuation">></span></span>        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>version</span><span class="token punctuation">></span></span>4.7<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>version</span><span class="token punctuation">></span></span>        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>scope</span><span class="token punctuation">></span></span>test<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>scope</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>dependency</span><span class="token punctuation">></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>dependencies</span><span class="token punctuation">></span></span></code></pre><p>dependencies元素下可以包含多个dependency元素以声明项目的依赖。前面我们提到通过groupId，artifactId，version是任何一个maven项目最基本的坐标，JUnit也是，有了这段声明，maven就能自动下载JUnit。</p><p>上述POM代码还有一个值为test的元素scope，代表依赖范围，若依赖范围是test表示该依赖只对测试有效，就是在测试代码用是没有问题，但在主代码用就会编译错误。如果不声明依赖范围，那么默认值就是compile，表示对主代码和测试代码都有效。</p><p>编写完毕后调用Maven执行测试，运行mvn clean test。</p><p>有时maven输出提示我们需要使用 -source 5或更高版本，这时可能是maven核心插件的compiler插件默认支持编译的Java版本低，要改成支持Java5的版本。</p><p>在pom文件添加：</p><pre class="language-xml" data-language="xml"><code class="language-xml"><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>build</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>plugins</span><span class="token punctuation">></span></span>        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>plugin</span><span class="token punctuation">></span></span>            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>groupId</span><span class="token punctuation">></span></span>org.apache.maven.plugins<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>groupId</span><span class="token punctuation">></span></span>            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>artifactId</span><span class="token punctuation">></span></span>maven-compiler-plugin<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>artifactId</span><span class="token punctuation">></span></span>            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>configuration</span><span class="token punctuation">></span></span>                <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>source</span><span class="token punctuation">></span></span>1.5<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>source</span><span class="token punctuation">></span></span>                <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>target</span><span class="token punctuation">></span></span>1.5<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>target</span><span class="token punctuation">></span></span>            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>configuration</span><span class="token punctuation">></span></span>        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>plugin</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>plugins</span><span class="token punctuation">></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>build</span><span class="token punctuation">></span></span></code></pre><h2 id="打包和运行"><a href="#打包和运行" class="headerlink" title="打包和运行"></a>打包和运行</h2><p>若没有指定打包类型的话，默认打包类型是jar，可以执行命令mvn clean package进行打包。</p><p>打包完毕后，可以在target/输出目录中看见，名称是根据artifactId-version.jar进行命名的。</p><p>如果想让其他的Maven项目直接引用这个jar，可以把它安装到maven仓库，执行mvn clean install就会把它安装到Maven本地仓库中。</p><p>虽然项目中有的类含有main方法，但默认打包生成的jar不能直接运行，因为带有main方法的类信息不会添加到manifest中(jar文件的<em>META-INF/MANIFEST.MF</em>文件)。</p><p>若要生成可执行的jar文件，需要借助maven-shade-plugin插件：</p><pre class="language-xml" data-language="xml"><code class="language-xml"><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>plugin</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>groupId</span><span class="token punctuation">></span></span>org.apache.maven.plugins<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>groupId</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>artifactId</span><span class="token punctuation">></span></span>maven-shade-plugin<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>artifactId</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>version</span><span class="token punctuation">></span></span>1.2.1<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>version</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>executions</span><span class="token punctuation">></span></span>        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>execution</span><span class="token punctuation">></span></span>            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>phase</span><span class="token punctuation">></span></span>package<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>phase</span><span class="token punctuation">></span></span>            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>goals</span><span class="token punctuation">></span></span>                <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>goal</span><span class="token punctuation">></span></span>shade<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>goal</span><span class="token punctuation">></span></span>            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>goals</span><span class="token punctuation">></span></span>            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>configuration</span><span class="token punctuation">></span></span>                <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>transformers</span><span class="token punctuation">></span></span>                    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>transformer</span> <span class="token attr-name">implementation</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>org.apache.maven.plugins.shade.resource.ManifestResourceTransformer<span class="token punctuation">"</span></span><span class="token punctuation">></span></span>                        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>mainClass</span><span class="token punctuation">></span></span>com.gzj.testMaven.Main<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>mainClass</span><span class="token punctuation">></span></span>                    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>transformer</span><span class="token punctuation">></span></span>                <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>transformers</span><span class="token punctuation">></span></span>            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>configuration</span><span class="token punctuation">></span></span>        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>execution</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>executions</span><span class="token punctuation">></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>plugin</span><span class="token punctuation">></span></span></code></pre><p>配置mainClass为com.gzj.testMaven.Main，项目打包时就会把信息放到MANIFEST中。执行mvn clean install，构建完成后打开target/目录，可以看到hello-world-1.0-SNAPSHOT.jar和original-hello-world-1.0-SNAPSHOT.jar两个文件，前者是带有Main-Class信息的可运行jar，后者是原始的jar，打开hello-world-1.0-SNAPSHOT.jar的MANIFEST.MF可以看到多了<code>Main-Class: com.gzj.testMaven.Main</code>这一行信息。</p><h2 id="使用Archetype生成项目骨架"><a href="#使用Archetype生成项目骨架" class="headerlink" title="使用Archetype生成项目骨架"></a>使用Archetype生成项目骨架</h2><p>每次构建项目时都要自己创建pom文件和src/main/java等一些固定的包，会让我们感到很繁琐，通过maven archetype可以快速创建项目的骨架。</p><p>输入maven archetype后，会先让我们选择archetype，然后输入项目的groupId、artifactId、version和package，完了后确认就生成成功了。</p><p>默认生成的pom.xml包含一个junit依赖，主代码和测试代码已被创建。</p><h1 id="第三章-坐标和依赖"><a href="#第三章-坐标和依赖" class="headerlink" title="第三章 坐标和依赖"></a>第三章 坐标和依赖</h1><h2 id="何为Maven坐标"><a href="#何为Maven坐标" class="headerlink" title="何为Maven坐标"></a>何为Maven坐标</h2><p>界上任何一个JAR包或者WAR包都可以使用Maven坐标唯一标识，Maven坐标的元素包括groupId、artifactId、version和classifier等。只要我们提供了正确的坐标元素，Maven就能找到对应的JAR包或者WAR包。</p><h2 id="坐标详解"><a href="#坐标详解" class="headerlink" title="坐标详解"></a>坐标详解</h2><p>groupId：定义当前Maven项目隶属的实际项目；我们要明白的是Maven项目和实际项目不一定是一对一的关系。这是由于Maven中模块的概念，因此实际项目往往会被划分成很多模块。groupId和我们在Java中定义顶级包名的规则是一样的，通常与公司或者组织的域名反向一一对应。</p><p>artifactId：该元素定义实际项目中的一个Maven项目（模块），一般推荐的做法是使用实际项目名称作为artifactId的前缀，比如spring-core的前缀是spring一样。</p><p>version：该元素定义Maven项目当前所处的版本。</p><p>packaging：定义Maven项目的打包方式，打包方式会影响到构建的生命周期，jar打包和war打包使用不同的命令。不定义packaging的时候，Maven默认使用jar。</p><p>classifier：该元素帮助定义构建输出的一些附属构件。比如主构件是nexus-indexer-2.0.0.jar，可能使用插件生成nexus-indexer-2.0.0-javadoc.jar，nexus-indexer-2.0.0-sources.jar等附属构件。javadoc和sources就是这两个附属构件的classifier。这样附属构件也有了自己唯一的坐标。</p><p>在项目中，groupId、artifactId、version是必须定义的，packaging是可选的（默认jar），而classifier是不能直接定义的。</p><p>同时，项目构件的文件名是与坐标相对应的，一般是artifactId-version[-classifier].packaging，[-classifier]表示可选。</p><h2 id="依赖范围"><a href="#依赖范围" class="headerlink" title="依赖范围"></a>依赖范围</h2><p>Maven在编译项目主代码的时候要使用一套classpath，在编译和执行测试时会使用另外一套classpath，实际运行Maven项目的时候，又会使用一套classpath。</p><p>依赖范围就是控制依赖与这三种classpath的关系，Maven有以下几种依赖范围：</p><ul><li>Compile：编译依赖范围。如果没有指定，就会默认使用该依赖范围。该依赖范围的依赖，对于编译、测试、运行这三种classpath都有效。</li><li>Test：测试依赖范围。使用此依赖范围的Maven依赖，只对测试calsspath有效，在编译主代码或运行项目时无法使用。</li><li>Provided：已提供依赖范围。使用此依赖范围的Maven依赖，对于编译和测试classpath有效，但运行时无效。比如servlet-api，编译测试用，但运行时容器已经提供，不需要Maven再导入。</li><li>Runtime：运行时依赖范围。使用此依赖范围的Maven依赖，对于测试和运行classpath有效，但编译主代码无效。比如JDBC驱动实现，主代码只需要JDK提供的JDBC接口，只有在执行测试或运行实际项目的时候才需要实现上述接口的具体JDBC驱动。</li><li>Ststem：系统依赖范围。该依赖与三种classpath的关系和Provided依赖范围完全一致。但使用System范围的依赖必须通过systemPath元素显式指定依赖文件的路径。此类依赖不是通过Maven仓库解析，往往与本机系统绑定，可能造成构建的不可移植，谨慎使用。systemPath元素可以引用环境变量。</li><li>Import（Maven2.0.9及以上）：导入依赖范围。该依赖范围不会test、compile、runtime的 classpath 产生实际的影响。它的作用是将其他模块定义好的 dependencyManagement 导入当前 Maven 项目 pom 的 dependencyManagement 中。</li></ul><h2 id="传递性依赖"><a href="#传递性依赖" class="headerlink" title="传递性依赖"></a>传递性依赖</h2><h3 id="何为传递性依赖"><a href="#何为传递性依赖" class="headerlink" title="何为传递性依赖"></a>何为传递性依赖</h3><p>例如：A.jar依赖于B.jar，而B.jar依赖于C.jar，那要使A.jar 依赖于C.jar 当且仅当C.jar的范围是compile。</p><p>有了Maven的传递性依赖机制，不用担心引入多余的依赖。 Maven会解析各个直接依赖的POM, 将那些必要的间接依赖，以传递性依赖的形式引入到当前的项目中。</p><h3 id="传递性依赖和依赖范围"><a href="#传递性依赖和依赖范围" class="headerlink" title="传递性依赖和依赖范围"></a>传递性依赖和依赖范围</h3><p>假设A依赖于B，B依赖于C，那么A对于B是第一直接依赖，B对于C是第二直接依赖，A对于C是传递性依赖。第一直接依赖的范围和第二直接依赖的范围决定了传递性依赖的范围。</p><p> 如下图： 最左边一列表示第一直接依赖范围， 最上面一行表示第二直接依赖范围， 中间交叉单元格则表示传递性依赖的范围。</p><table><thead><tr><th></th><th>compile</th><th>test</th><th>provided</th><th>runtime</th></tr></thead><tbody><tr><td>compile</td><td>compile</td><td>—</td><td>—</td><td>runtime</td></tr><tr><td>test</td><td>test</td><td>—</td><td>—</td><td>test</td></tr><tr><td>provided</td><td>provided</td><td>—</td><td>provided</td><td>provided</td></tr><tr><td>runtime</td><td>runtime</td><td>—</td><td>—</td><td>runtime</td></tr></tbody></table><p>通过上表可以发现规律：当第二直接依赖的范围是compile的时候，传递性依赖与第一直接依赖的范围一致； 当第二直接依赖的范围是test的时候，依赖不会得以传递；当第二直接依赖是provided的时候，值传递第一直接依赖范围也为provided的依赖，且传递性依赖范围同样为provided; 当第二依赖的范围是runtime的时候，传递性范围与第一直接依赖的范围一致，但compile例外，此时传递性依赖的范围为runtime。</p><h3 id="依赖调解"><a href="#依赖调解" class="headerlink" title="依赖调解"></a>依赖调解</h3><p>大部分情况下，通过Maven的依赖传递机制，我们只需要关心项目的直接依赖是什么，但有时候，传递性依赖也会造成一些问题。</p><p>比如项目A有这样的依赖关系：A-&gt;B-&gt;C-&gt;X(1.0), A-&gt;D-&gt;X(2.0), X是A的传递性依赖，但是两条依赖路径上有两个版本的X，这时，Maven会进行依赖调解，根据==路径最近者优先==的调解原则，该例中X(1.0)的路径长度为3，而X(2.0)的路径长度为2，因此X(2.0)会被解析使用。</p><p>但这种情况不能解决所有问题，如果路径长度一样的情况下，在Maven2.0.8及之前的版本中，这时不确定的，但从Maven2.0.9版本开始，Maven定义了依赖调解的第二原则：==第一声明者优先==。在依赖路径长度相同的情况下，在POM中依赖声明的顺序决定了谁会被解析使用，顺序最靠前的那个依赖优胜。</p><h3 id="可选依赖"><a href="#可选依赖" class="headerlink" title="可选依赖"></a>可选依赖</h3><p>假设有这样一个依赖关系，项目A依赖于项目B,项目B依赖于项目X和Y, B对于X和Y的依赖都是可选依赖： A-&gt;B, B-&gt;X(可选)，B-&gt;Y(可选)。 根据传递性依赖的定义，如果所有这三个依赖的范围都是compile,那么X, Y就是A的compile范围传递性依赖。然而，由于这里X,Y是可选依赖，依赖将不会得以传递。换句话说，X,Y将不会对A有任何影响。</p><p>可选依赖可以解决如下情况，如果项目B实现了两个特性，一个特性依赖于X，另一个依赖于Y，这两个特性互斥，比如B是一个持久层工具包，支持X和Y数据库，那构建B工具包时需要这两个依赖，但使用时只会用到一个。</p><p>可选依赖配置：</p><pre class="language-xml" data-language="xml"><code class="language-xml"><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>dependencies</span><span class="token punctuation">></span></span>   <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>dependency</span><span class="token punctuation">></span></span>      <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>groupId</span><span class="token punctuation">></span></span>mysql<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>groupId</span><span class="token punctuation">></span></span>      <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>artifactId</span><span class="token punctuation">></span></span>mysql-connector-java<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>artifactId</span><span class="token punctuation">></span></span>      <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>version</span><span class="token punctuation">></span></span>5.1.10<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>version</span><span class="token punctuation">></span></span>      <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>optional</span><span class="token punctuation">></span></span>true<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>optional</span><span class="token punctuation">></span></span>   <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>dependency</span><span class="token punctuation">></span></span>   <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>dependency</span><span class="token punctuation">></span></span>      <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>groupId</span><span class="token punctuation">></span></span>postgresql<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>groupId</span><span class="token punctuation">></span></span>      <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>artifactId</span><span class="token punctuation">></span></span>postgresql<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>artifactId</span><span class="token punctuation">></span></span>      <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>version</span><span class="token punctuation">></span></span>8.4-701.jgbc3<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>version</span><span class="token punctuation">></span></span>      <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>optional</span><span class="token punctuation">></span></span>true<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>optional</span><span class="token punctuation">></span></span>   <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>dependency</span><span class="token punctuation">></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>dependencies</span><span class="token punctuation">></span></span></code></pre><p>optional：这个元素表示mysql-connector-java和postgresql这两个依赖为可选依赖，它们只会对当前项目B产生影响，当其他项目依赖于B的时候，这两个依赖不会被传递。</p><p>因此，当项目A依赖于项目B的时候，如果其实际使用基于MySQL数据，那么项目A中就需要显示的声明mysql-connetor-java这一依赖，如下：</p><pre class="language-html" data-language="html"><code class="language-html"><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>dependencies</span><span class="token punctuation">></span></span>   <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>dependency</span><span class="token punctuation">></span></span>      <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>groupId</span><span class="token punctuation">></span></span>org.rogueq.mvnbook<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>groupId</span><span class="token punctuation">></span></span>      <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>artifactId</span><span class="token punctuation">></span></span>project-b<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>artifactId</span><span class="token punctuation">></span></span>      <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>version</span><span class="token punctuation">></span></span>1.0.0<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>version</span><span class="token punctuation">></span></span>   <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>dependency</span><span class="token punctuation">></span></span>   <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>dependency</span><span class="token punctuation">></span></span>      <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>groupId</span><span class="token punctuation">></span></span>mysql<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>groupId</span><span class="token punctuation">></span></span>      <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>artifactId</span><span class="token punctuation">></span></span>mysql-connector-java<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>artifactId</span><span class="token punctuation">></span></span>      <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>version</span><span class="token punctuation">></span></span>5.1.10<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>version</span><span class="token punctuation">></span></span>   <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>dependency</span><span class="token punctuation">></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>dependencies</span><span class="token punctuation">></span></span></code></pre><p>但理想情况不应该使用可选依赖，根据单一职责原则，在上述例子中，最好是根据Mysql和PostgreSQL分别创建Maven项目，分配不同artifactId，直接声明JDBC驱动依赖，不使用可选依赖。</p>]]></content>
    
    
    <summary type="html">Maven 翻译为&quot;专家&quot;、&quot;内行&quot;，是 Apache 下的一个纯 Java 开发的开源项目。基于项目对象模型（缩写：POM）概念，Maven利用一个中央信息片断能管理一个项目的构建、报告和文档等步骤。</summary>
    
    
    
    <category term="Java基础" scheme="https://zzugzj.github.io/categories/Java%E5%9F%BA%E7%A1%80/"/>
    
    
    <category term="Java基础" scheme="https://zzugzj.github.io/tags/Java%E5%9F%BA%E7%A1%80/"/>
    
  </entry>
  
  <entry>
    <title>mybatisPlus笔记</title>
    <link href="https://zzugzj.github.io/posts/13667b25/"/>
    <id>https://zzugzj.github.io/posts/13667b25/</id>
    <published>2021-01-12T08:16:58.000Z</published>
    <updated>2023-11-05T05:50:40.901Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>版本：3.4.1</p><h2 id="mybatis-plus的yml常用配置"><a href="#mybatis-plus的yml常用配置" class="headerlink" title="mybatis-plus的yml常用配置"></a>mybatis-plus的yml常用配置</h2><pre class="language-yaml" data-language="yaml"><code class="language-yaml"><span class="token key atrule">mybatis-plus</span><span class="token punctuation">:</span>  <span class="token comment"># Mapper.xml 文件位置 Maven 多模块项目的扫描路径需以 classpath*: 开头</span>  <span class="token key atrule">mapperLocations</span><span class="token punctuation">:</span> classpath<span class="token important">*:com/vanhr/**/xml/*Mapper.xml</span><span class="token comment">#  #通过父类（或实现接口）的方式来限定扫描实体</span><span class="token comment">#  typeAliasesSuperType: com.vanhr.user.dao.entity.baseEntity</span><span class="token comment">#  #枚举类 扫描路径 如果配置了该属性，会将路径下的枚举类进行注入，让实体类字段能够简单快捷的使用枚举属性</span><span class="token comment">#  typeEnumsPackage: com.vanhr.user.dao.enums</span><span class="token comment">#  #通过该属性可指定 MyBatis 的执行器，MyBatis 的执行器总共有三种：</span><span class="token comment">#  # ExecutorType.SIMPLE：该执行器类型不做特殊的事情，为每个语句的执行创建一个新的预处理语句（PreparedStatement）</span><span class="token comment">#  # ExecutorType.REUSE：该执行器类型会复用预处理语句（PreparedStatement）</span><span class="token comment">#  # ExecutorType.BATCH：该执行器类型会批量执行所有的更新语句</span><span class="token comment">#  executorType: SIMPLE</span><span class="token comment">#  # 指定外部化 MyBatis Properties 配置，通过该配置可以抽离配置，实现不同环境的配置部署</span><span class="token comment">#  configurationProperties:</span>  <span class="token key atrule">configuration</span><span class="token punctuation">:</span> <span class="token comment"># MyBatis 原生支持的配置</span>    <span class="token key atrule">log-impl</span><span class="token punctuation">:</span> org.apache.ibatis.logging.stdout.StdOutImpl <span class="token comment">#日志输出</span>    <span class="token comment"># 是否开启自动驼峰命名规则（camel case）映射</span>    <span class="token key atrule">mapUnderscoreToCamelCase</span><span class="token punctuation">:</span> <span class="token boolean important">true</span>    <span class="token comment"># 枚举处理类,如果配置了该属性,枚举将统一使用指定处理器进行处理</span>    <span class="token comment">#   org.apache.ibatis.type.EnumTypeHandler : 存储枚举的名称</span>    <span class="token comment">#   org.apache.ibatis.type.EnumOrdinalTypeHandler : 存储枚举的索引</span>    <span class="token comment">#   com.baomidou.mybatisplus.extension.handlers.MybatisEnumTypeHandler : 枚举类需要实现IEnum接口或字段标记@EnumValue注解.(3.1.2以下版本为EnumTypeHandler)</span><span class="token comment">#    defaultEnumTypeHandler: com.baomidou.mybatisplus.extension.handlers.MybatisEnumTypeHandler</span>    <span class="token comment"># 配置JdbcTypeForNull, oracle数据库必须配置</span>    <span class="token key atrule">jdbc-type-for-null</span><span class="token punctuation">:</span> <span class="token null important">null</span>  <span class="token key atrule">global-config</span><span class="token punctuation">:</span> <span class="token comment"># 全局策略配置</span>    <span class="token comment"># 是否控制台 print mybatis-plus 的 LOGO</span>    <span class="token key atrule">banner</span><span class="token punctuation">:</span> <span class="token boolean important">false</span>    <span class="token key atrule">db-config</span><span class="token punctuation">:</span>      <span class="token comment"># id类型</span>      <span class="token key atrule">id-type</span><span class="token punctuation">:</span> auto      <span class="token comment"># 表名是否使用下划线命名，默认数据库表使用下划线命名</span>      <span class="token key atrule">table-underline</span><span class="token punctuation">:</span> <span class="token boolean important">true</span>      <span class="token comment">#是否开启大写命名，默认不开启</span><span class="token comment">#      capital-mode: false</span><span class="token comment">#      #逻辑已删除值,(逻辑删除下有效) 需要注入逻辑策略LogicSqlInjector 以@Bean方式注入</span><span class="token comment">#      logic-not-delete-value: 0</span><span class="token comment">#      #逻辑未删除值,(逻辑删除下有效)</span><span class="token comment">#      logic-delete-value: 1</span></code></pre><h2 id="crud操作"><a href="#crud操作" class="headerlink" title="crud操作"></a>crud操作</h2><h3 id="插入操作"><a href="#插入操作" class="headerlink" title="插入操作"></a>插入操作</h3><pre class="language-none"><code class="language-none">@SpringBootTestpublic class CRUDTests &#123;    @Autowired    private UserMapper userMapper;    @Test    public void testInsert()&#123;        User user &#x3D; new User();        user.setName(&quot;Helen&quot;);        user.setAge(18);        user.setEmail(&quot;55317332@qq.com&quot;);        int result &#x3D; userMapper.insert(user);        System.out.println(result); &#x2F;&#x2F;影响的行数        System.out.println(user); &#x2F;&#x2F;id自动回填    &#125;&#125;</code></pre><h4 id="插入时的主键策略"><a href="#插入时的主键策略" class="headerlink" title="插入时的主键策略"></a>插入时的主键策略</h4><p>MP 支持多种主键策略 默认是推特的“雪花算法“ ，也可以设置其他策略。</p><p><strong>IdType</strong></p><table><thead><tr><th align="center">值</th><th align="center">描述</th></tr></thead><tbody><tr><td align="center">AUTO</td><td align="center">数据库ID自增</td></tr><tr><td align="center">NONE</td><td align="center">无状态,该类型为未设置主键类型(注解里等于跟随全局,全局里约等于 INPUT)，默认根据雪花算法生成</td></tr><tr><td align="center">INPUT</td><td align="center">insert前自行set主键值</td></tr><tr><td align="center">ASSIGN_ID</td><td align="center">分配ID(主键类型为Number(Long和Integer)或String)(since 3.3.0),使用接口<code>IdentifierGenerator</code>的方法<code>nextId</code>(默认实现类为<code>DefaultIdentifierGenerator</code>雪花算法)</td></tr><tr><td align="center">ASSIGN_UUID</td><td align="center">分配UUID,主键类型为String(since 3.3.0),使用接口<code>IdentifierGenerator</code>的方法<code>nextUUID</code>(默认default方法)</td></tr></tbody></table><p><strong>相关资料：分布式系统唯一ID生成方案汇总：</strong><a href="https://www.cnblogs.com/haoxinyue/p/5208136.html">https://www.cnblogs.com/haoxinyue/p/5208136.html</a></p><p>要想影响所有实体的配置，可以设置全局主键配置</p><pre class="language-none"><code class="language-none">#全局设置主键生成策略mybatis-plus.global-config.db-config.id-type&#x3D;auto</code></pre><h3 id="更新操作"><a href="#更新操作" class="headerlink" title="更新操作"></a>更新操作</h3><h4 id="根据Id更新操作"><a href="#根据Id更新操作" class="headerlink" title="根据Id更新操作"></a>根据Id更新操作</h4><p><strong>注意：</strong>update时生成的sql自动是动态sql：UPDATE user SET age=? WHERE id=? </p><pre class="language-none"><code class="language-none">@Testpublic void testUpdateById()&#123;    User user &#x3D; new User();    user.setId(1L);    user.setAge(28);    int result &#x3D; userMapper.updateById(user);    System.out.println(result);&#125;</code></pre><h4 id="自动填充"><a href="#自动填充" class="headerlink" title="自动填充"></a>自动填充</h4><p>项目中经常会遇到一些数据，每次都使用相同的方式填充，例如记录的创建时间，更新时间等。</p><p>我们可以使用MyBatis Plus的自动填充功能，完成这些字段的赋值工作：</p><p>首先在实体上添加注解<code>@TableField(fill = FieldFill.INSERT)</code>，然后实现元对象处理器接口，不要在类上忘记添加 @Component 注解。</p><pre class="language-java" data-language="java"><code class="language-java"><span class="token annotation punctuation">@Component</span><span class="token keyword">public</span> <span class="token keyword">class</span> <span class="token class-name">MyMetaObjectHandler</span> <span class="token keyword">implements</span> <span class="token class-name">MetaObjectHandler</span> <span class="token punctuation">&#123;</span>    <span class="token annotation punctuation">@Override</span>    <span class="token keyword">public</span> <span class="token keyword">void</span> <span class="token function">insertFill</span><span class="token punctuation">(</span><span class="token class-name">MetaObject</span> metaObject<span class="token punctuation">)</span> <span class="token punctuation">&#123;</span><span class="token comment">//插入操作</span>        <span class="token keyword">this</span><span class="token punctuation">.</span><span class="token function">setFieldValByName</span><span class="token punctuation">(</span><span class="token string">"createTime"</span><span class="token punctuation">,</span> <span class="token keyword">new</span> <span class="token class-name">Date</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> metaObject<span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token keyword">this</span><span class="token punctuation">.</span><span class="token function">setFieldValByName</span><span class="token punctuation">(</span><span class="token string">"updateTime"</span><span class="token punctuation">,</span> <span class="token keyword">new</span> <span class="token class-name">Date</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> metaObject<span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token punctuation">&#125;</span>    <span class="token annotation punctuation">@Override</span>    <span class="token keyword">public</span> <span class="token keyword">void</span> <span class="token function">updateFill</span><span class="token punctuation">(</span><span class="token class-name">MetaObject</span> metaObject<span class="token punctuation">)</span> <span class="token punctuation">&#123;</span><span class="token comment">//更新操作</span>        <span class="token keyword">this</span><span class="token punctuation">.</span><span class="token function">setFieldValByName</span><span class="token punctuation">(</span><span class="token string">"updateTime"</span><span class="token punctuation">,</span> <span class="token keyword">new</span> <span class="token class-name">Date</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> metaObject<span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token punctuation">&#125;</span><span class="token punctuation">&#125;</span></code></pre><p>FieldFill类的一些属性：</p><pre class="language-none"><code class="language-none">&#x2F;*** 默认不处理*&#x2F;DEFAULT,&#x2F;*** 插入时填充字段*&#x2F;INSERT,&#x2F;*** 更新时填充字段*&#x2F;UPDATE,&#x2F;*** 插入和更新时填充字段*&#x2F;INSERT_UPDATE</code></pre><h4 id="乐观锁"><a href="#乐观锁" class="headerlink" title="乐观锁"></a>乐观锁</h4><p><strong>OptimisticLockerInnerInterceptor</strong></p><blockquote><p>当要更新一条记录的时候，希望这条记录没有被别人更新<br>乐观锁实现方式：</p><blockquote><ul><li>取出记录时，获取当前version</li><li>更新时，带上这个version</li><li>执行更新时， set version = newVersion where version = oldVersion</li><li>如果version不对，就更新失败</li></ul></blockquote></blockquote><p>首先数据库表要加version字段，然后字段上加上<code>@Version</code>注解，然后元对象处理器接口添加version的insert默认值。</p><pre class="language-java" data-language="java"><code class="language-java"><span class="token annotation punctuation">@Version</span><span class="token annotation punctuation">@TableField</span><span class="token punctuation">(</span>fill <span class="token operator">=</span> <span class="token class-name">FieldFill</span><span class="token punctuation">.</span>INSERT<span class="token punctuation">)</span><span class="token comment">//也可以设置数据库default值</span><span class="token keyword">private</span> <span class="token class-name">Integer</span> version<span class="token punctuation">;</span><span class="token comment">//version要有初始值，可以使用自动填充</span></code></pre><p>说明:</p><ul><li><strong>支持的数据类型只有:int,Integer,long,Long,Date,Timestamp,LocalDateTime</strong></li><li>整数类型下 <code>newVersion = oldVersion + 1</code></li><li><code>newVersion</code> 会回写到 <code>entity</code> 中</li><li>仅支持 <code>updateById(id)</code> 与 <code>update(entity, wrapper)</code> 方法</li><li><strong>在 <code>update(entity, wrapper)</code> 方法下, <code>wrapper</code> 不能复用!!!</strong></li></ul><p><strong>3.4版本后的配置写法：（如果对多个插件进行配置(本例是乐观锁和分页)，要写在一个方法内）</strong></p><pre class="language-none"><code class="language-none">@Beanpublic MybatisPlusInterceptor mybatisPlusInterceptor() &#123;    MybatisPlusInterceptor interceptor &#x3D; new MybatisPlusInterceptor();    interceptor.addInnerInterceptor(new OptimisticLockerInnerInterceptor()); &#x2F;&#x2F; 乐观锁插件    &#x2F;&#x2F; DbType：数据库类型(根据类型获取应使用的分页方言)    interceptor.addInnerInterceptor(new PaginationInnerInterceptor(DbType.MYSQL)); &#x2F;&#x2F; 分页插件    return interceptor;&#125;</code></pre><h3 id="查询操作"><a href="#查询操作" class="headerlink" title="查询操作"></a>查询操作</h3><h4 id="通过多个id批量查询"><a href="#通过多个id批量查询" class="headerlink" title="通过多个id批量查询"></a><strong>通过多个id批量查询</strong></h4><p>完成了动态sql的foreach的功能</p><pre class="language-java" data-language="java"><code class="language-java"><span class="token annotation punctuation">@Test</span><span class="token keyword">public</span> <span class="token keyword">void</span> <span class="token function">testSelectBatchIds</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">&#123;</span>    <span class="token class-name">System</span><span class="token punctuation">.</span>out<span class="token punctuation">.</span><span class="token function">println</span><span class="token punctuation">(</span>userMapper<span class="token punctuation">.</span><span class="token function">selectBatchIds</span><span class="token punctuation">(</span><span class="token class-name">Arrays</span><span class="token punctuation">.</span><span class="token function">asList</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token punctuation">&#125;</span></code></pre><h4 id="简单的条件查询"><a href="#简单的条件查询" class="headerlink" title="简单的条件查询"></a><strong>简单的条件查询</strong></h4><p>通过Wrapper封装查询条件</p><pre class="language-java" data-language="java"><code class="language-java"><span class="token annotation punctuation">@Test</span><span class="token keyword">public</span> <span class="token keyword">void</span> <span class="token function">testSelectByMap</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">&#123;</span>    <span class="token comment">//通过lambda</span>    <span class="token class-name">System</span><span class="token punctuation">.</span>out<span class="token punctuation">.</span><span class="token function">println</span><span class="token punctuation">(</span>userMapper<span class="token punctuation">.</span><span class="token function">selectList</span><span class="token punctuation">(</span><span class="token class-name">Wrappers</span><span class="token punctuation">.</span><span class="token function">lambdaQuery</span><span class="token punctuation">(</span><span class="token class-name">User</span><span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">)</span>                <span class="token punctuation">.</span><span class="token function">eq</span><span class="token punctuation">(</span><span class="token class-name">User</span><span class="token operator">::</span><span class="token function">getName</span><span class="token punctuation">,</span> <span class="token string">"Jone"</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">eq</span><span class="token punctuation">(</span><span class="token class-name">User</span><span class="token operator">::</span><span class="token function">getAge</span><span class="token punctuation">,</span> <span class="token number">18</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token comment">//不用lambda</span>    <span class="token class-name">System</span><span class="token punctuation">.</span>out<span class="token punctuation">.</span><span class="token function">println</span><span class="token punctuation">(</span>userMapper<span class="token punctuation">.</span><span class="token function">selectList</span><span class="token punctuation">(</span><span class="token class-name">Wrappers</span><span class="token punctuation">.</span><span class="token function">query</span><span class="token punctuation">(</span><span class="token keyword">new</span> <span class="token class-name">User</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>                <span class="token punctuation">.</span><span class="token function">eq</span><span class="token punctuation">(</span><span class="token string">"name"</span><span class="token punctuation">,</span> <span class="token string">"Jone"</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">eq</span><span class="token punctuation">(</span><span class="token string">"age"</span><span class="token punctuation">,</span> <span class="token number">18</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token punctuation">&#125;</span></code></pre><p><strong>注意：</strong>map中的key对应的是数据库中的列名。例如数据库user_id，实体类是userId，这时map的key需要填写user_id</p><h4 id="分页查询"><a href="#分页查询" class="headerlink" title="分页查询"></a>分页查询</h4><p>MyBatis Plus自带分页插件，只要简单的配置即可实现分页功能</p><p><strong>（1）创建配置类</strong></p><pre class="language-java" data-language="java"><code class="language-java"><span class="token comment">/** * 新的分页插件,一缓和二缓遵循mybatis的规则,需要设置  * MybatisConfiguration#useDeprecatedExecutor = false  * 避免缓存出现问题(该属性会在旧插件移除后一同移除) */</span> <span class="token annotation punctuation">@Bean</span> <span class="token keyword">public</span> <span class="token class-name">MybatisPlusInterceptor</span> <span class="token function">mybatisPlusInterceptor</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">&#123;</span>     <span class="token class-name">PaginationInnerInterceptor</span> paginationInnerInterceptor <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">PaginationInnerInterceptor</span><span class="token punctuation">(</span><span class="token class-name">DbType</span><span class="token punctuation">.</span>MYSQL<span class="token punctuation">)</span><span class="token punctuation">;</span>        paginationInnerInterceptor<span class="token punctuation">.</span><span class="token function">setMaxLimit</span><span class="token punctuation">(</span><span class="token number">500L</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token comment">//单页分页条数限制</span>        interceptor<span class="token punctuation">.</span><span class="token function">addInnerInterceptor</span><span class="token punctuation">(</span>paginationInnerInterceptor<span class="token punctuation">)</span><span class="token punctuation">;</span> <span class="token comment">// 分页插件</span>     <span class="token keyword">return</span> interceptor<span class="token punctuation">;</span> <span class="token punctuation">&#125;</span><span class="token comment">//不知道为什么加这个，但官网示例加了，我也加</span><span class="token annotation punctuation">@Bean</span><span class="token keyword">public</span> <span class="token class-name">ConfigurationCustomizer</span> <span class="token function">configurationCustomizer</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">&#123;</span>    <span class="token keyword">return</span> configuration <span class="token operator">-></span> configuration<span class="token punctuation">.</span><span class="token function">setUseDeprecatedExecutor</span><span class="token punctuation">(</span><span class="token boolean">false</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token punctuation">&#125;</span></code></pre><p><strong>（2）测试selectPage分页</strong></p><p><strong>测试：</strong>最终通过page对象获取相关数据</p><pre class="language-java" data-language="java"><code class="language-java"><span class="token annotation punctuation">@Test</span><span class="token keyword">public</span> <span class="token keyword">void</span> <span class="token function">testSelectPage</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">&#123;</span>    <span class="token class-name">Page</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">User</span><span class="token punctuation">></span></span> page <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">Page</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token punctuation">></span></span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    userMapper<span class="token punctuation">.</span><span class="token function">selectPage</span><span class="token punctuation">(</span>page<span class="token punctuation">,</span> <span class="token keyword">null</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    page<span class="token punctuation">.</span><span class="token function">getRecords</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">forEach</span><span class="token punctuation">(</span><span class="token class-name">System</span><span class="token punctuation">.</span>out<span class="token operator">::</span><span class="token function">println</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token class-name">System</span><span class="token punctuation">.</span>out<span class="token punctuation">.</span><span class="token function">println</span><span class="token punctuation">(</span>page<span class="token punctuation">.</span><span class="token function">getCurrent</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token class-name">System</span><span class="token punctuation">.</span>out<span class="token punctuation">.</span><span class="token function">println</span><span class="token punctuation">(</span>page<span class="token punctuation">.</span><span class="token function">getPages</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token class-name">System</span><span class="token punctuation">.</span>out<span class="token punctuation">.</span><span class="token function">println</span><span class="token punctuation">(</span>page<span class="token punctuation">.</span><span class="token function">getSize</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token class-name">System</span><span class="token punctuation">.</span>out<span class="token punctuation">.</span><span class="token function">println</span><span class="token punctuation">(</span>page<span class="token punctuation">.</span><span class="token function">getTotal</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token class-name">System</span><span class="token punctuation">.</span>out<span class="token punctuation">.</span><span class="token function">println</span><span class="token punctuation">(</span>page<span class="token punctuation">.</span><span class="token function">hasNext</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token class-name">System</span><span class="token punctuation">.</span>out<span class="token punctuation">.</span><span class="token function">println</span><span class="token punctuation">(</span>page<span class="token punctuation">.</span><span class="token function">hasPrevious</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token punctuation">&#125;</span></code></pre><p>控制台sql语句打印：SELECT id,name,age,email,create_time,update_time FROM user LIMIT 0,5 </p><p><strong>（3）测试selectMapsPage分页：结果集是Map</strong></p><pre class="language-java" data-language="java"><code class="language-java"><span class="token annotation punctuation">@Test</span><span class="token keyword">public</span> <span class="token keyword">void</span> <span class="token function">testSelectMapsPage</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">&#123;</span>    <span class="token class-name">Page</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">Map</span><span class="token punctuation">&lt;</span><span class="token class-name">String</span><span class="token punctuation">,</span> <span class="token class-name">Object</span><span class="token punctuation">></span><span class="token punctuation">></span></span> page <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">Page</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token punctuation">></span></span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token class-name">IPage</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">Map</span><span class="token punctuation">&lt;</span><span class="token class-name">String</span><span class="token punctuation">,</span> <span class="token class-name">Object</span><span class="token punctuation">></span><span class="token punctuation">></span></span> mapIPage <span class="token operator">=</span> userMapper<span class="token punctuation">.</span><span class="token function">selectMapsPage</span><span class="token punctuation">(</span>page<span class="token punctuation">,</span> <span class="token keyword">null</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token comment">//注意：此行必须使用 mapIPage 获取记录列表，否则会有数据类型转换错误</span>    mapIPage<span class="token punctuation">.</span><span class="token function">getRecords</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">forEach</span><span class="token punctuation">(</span><span class="token class-name">System</span><span class="token punctuation">.</span>out<span class="token operator">::</span><span class="token function">println</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token class-name">System</span><span class="token punctuation">.</span>out<span class="token punctuation">.</span><span class="token function">println</span><span class="token punctuation">(</span>page<span class="token punctuation">.</span><span class="token function">getCurrent</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token class-name">System</span><span class="token punctuation">.</span>out<span class="token punctuation">.</span><span class="token function">println</span><span class="token punctuation">(</span>page<span class="token punctuation">.</span><span class="token function">getPages</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token class-name">System</span><span class="token punctuation">.</span>out<span class="token punctuation">.</span><span class="token function">println</span><span class="token punctuation">(</span>page<span class="token punctuation">.</span><span class="token function">getSize</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token class-name">System</span><span class="token punctuation">.</span>out<span class="token punctuation">.</span><span class="token function">println</span><span class="token punctuation">(</span>page<span class="token punctuation">.</span><span class="token function">getTotal</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token class-name">System</span><span class="token punctuation">.</span>out<span class="token punctuation">.</span><span class="token function">println</span><span class="token punctuation">(</span>page<span class="token punctuation">.</span><span class="token function">hasNext</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token class-name">System</span><span class="token punctuation">.</span>out<span class="token punctuation">.</span><span class="token function">println</span><span class="token punctuation">(</span>page<span class="token punctuation">.</span><span class="token function">hasPrevious</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token punctuation">&#125;</span></code></pre><h3 id="删除操作"><a href="#删除操作" class="headerlink" title="删除操作"></a>删除操作</h3><h4 id="根据id删除记录"><a href="#根据id删除记录" class="headerlink" title="根据id删除记录"></a>根据id删除记录</h4><pre class="language-java" data-language="java"><code class="language-java"><span class="token annotation punctuation">@Test</span><span class="token keyword">public</span> <span class="token keyword">void</span> <span class="token function">testDeleteById</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">&#123;</span>    <span class="token keyword">int</span> result <span class="token operator">=</span> userMapper<span class="token punctuation">.</span><span class="token function">deleteById</span><span class="token punctuation">(</span><span class="token number">8L</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token class-name">System</span><span class="token punctuation">.</span>out<span class="token punctuation">.</span><span class="token function">println</span><span class="token punctuation">(</span>result<span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token punctuation">&#125;</span></code></pre><h4 id="批量删除"><a href="#批量删除" class="headerlink" title="批量删除"></a>批量删除</h4><pre class="language-java" data-language="java"><code class="language-java"><span class="token annotation punctuation">@Test</span><span class="token keyword">public</span> <span class="token keyword">void</span> <span class="token function">testDeleteBatchIds</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">&#123;</span>    <span class="token keyword">int</span> result <span class="token operator">=</span> userMapper<span class="token punctuation">.</span><span class="token function">deleteBatchIds</span><span class="token punctuation">(</span><span class="token class-name">Arrays</span><span class="token punctuation">.</span><span class="token function">asList</span><span class="token punctuation">(</span><span class="token number">8</span><span class="token punctuation">,</span> <span class="token number">9</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token class-name">System</span><span class="token punctuation">.</span>out<span class="token punctuation">.</span><span class="token function">println</span><span class="token punctuation">(</span>result<span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token punctuation">&#125;</span></code></pre><h4 id="逻辑删除"><a href="#逻辑删除" class="headerlink" title="逻辑删除"></a>逻辑删除</h4><blockquote><p>说明:</p><p>只对自动注入的sql起效:</p><ul><li><p>插入: 不作限制</p></li><li><p>查找: 追加where条件过滤掉已删除数据,且使用 wrapper.entity 生成的where条件会忽略该字段</p><blockquote><p> 使用 QueryWrapper 进行查询时的sql，我们发现前面的<code>deleted=0</code>条件会让后面我们自己加的deleted条件失效</p><p>SELECT * FROM test.user WHERE deleted=0 AND (deleted = ?)</p></blockquote></li><li><p>更新: 追加where条件防止更新到已删除数据,且使用 wrapper.entity 生成的where条件会忽略该字段</p></li><li><p>删除: 转变为 更新</p></li></ul><p>例如:</p><ul><li>删除: <code>update user set deleted=1 where id = 1 and deleted=0</code></li><li>查找: <code>select id,name,deleted from user where deleted=0</code></li></ul><p>字段类型支持说明:</p><ul><li>支持所有数据类型(推荐使用 <code>Integer</code>,<code>Boolean</code>,<code>LocalDateTime</code>)</li><li>如果数据库字段使用<code>datetime</code>,逻辑未删除值和已删除值支持配置为字符串<code>null</code>,另一个值支持配置为函数来获取值如<code>now()</code></li></ul><p>附录:</p><ul><li>如果要恢复删除的数据，可以使用mybatis手写sql来实现，绕过mybatis-plus</li><li>逻辑删除是为了方便数据恢复和保护数据本身价值等等的一种方案，但实际就是删除。</li><li>如果你需要频繁查出来看就不应使用逻辑删除，而是以一个状态去表示。</li></ul></blockquote><p><strong>数据库中添加 deleted字段</strong></p><pre class="language-none"><code class="language-none">ALTER TABLE &#96;user&#96; ADD COLUMN &#96;deleted&#96; boolean</code></pre><p><img src="https://raw.githubusercontent.com/zzugzj/blogImg/master/img/bc4cbff4-c2b8-45d5-ae8d-53439dd2330c.png" alt="img" loading="lazy"></p><p><strong>实体类添加deleted 字段</strong></p><p>并加上 @TableLogic 注解 和 @TableField(fill = FieldFill.INSERT) 注解</p><pre class="language-none"><code class="language-none">@TableLogic@TableField(fill &#x3D; FieldFill.INSERT)&#x2F;&#x2F;也可以设置数据库default值private Integer deleted;</code></pre><p><strong>元对象处理器接口添加deleted的insert默认值</strong></p><pre class="language-none"><code class="language-none">@Overridepublic void insertFill(MetaObject metaObject) &#123;    this.setFieldValByName(&quot;deleted&quot;, 0, metaObject);&#125;</code></pre><p><strong>application.properties 加入配置</strong></p><p>此为默认值，如果你的默认值和mp默认的一样,该配置可无</p><pre class="language-none"><code class="language-none">mybatis-plus:  global-config:    db-config:      logic-delete-field: flag  # 全局逻辑删除的实体字段名(since 3.3.0,配置后可以不用往flag字段上加@TableLogic注解)      logic-delete-value: 1 # 逻辑已删除值(默认为 1)      logic-not-delete-value: 0 # 逻辑未删除值(默认为 0)</code></pre><p><strong>在 MybatisPlusConfig 中注册 Bean</strong></p><pre class="language-none"><code class="language-none">@Beanpublic ISqlInjector sqlInjector() &#123;    return new LogicSqlInjector();&#125;</code></pre><h2 id="性能分析"><a href="#性能分析" class="headerlink" title="性能分析"></a>性能分析</h2><blockquote><p> 该功能依赖 <code>p6spy</code> 组件，完美的输出打印 SQL 及执行时长 <code>3.1.0</code> 以上版本</p></blockquote><ul><li>p6spy 依赖引入</li></ul><p>Maven：</p><pre class="language-xml" data-language="xml"><code class="language-xml"><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>dependency</span><span class="token punctuation">></span></span>  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>groupId</span><span class="token punctuation">></span></span>p6spy<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>groupId</span><span class="token punctuation">></span></span>  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>artifactId</span><span class="token punctuation">></span></span>p6spy<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>artifactId</span><span class="token punctuation">></span></span>  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>version</span><span class="token punctuation">></span></span>最新版本<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>version</span><span class="token punctuation">></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>dependency</span><span class="token punctuation">></span></span></code></pre><ul><li>application.yml 配置：</li></ul><pre class="language-yaml" data-language="yaml"><code class="language-yaml"><span class="token key atrule">spring</span><span class="token punctuation">:</span>  <span class="token key atrule">datasource</span><span class="token punctuation">:</span>    <span class="token key atrule">driver-class-name</span><span class="token punctuation">:</span> com.p6spy.engine.spy.P6SpyDriver    <span class="token key atrule">url</span><span class="token punctuation">:</span> jdbc<span class="token punctuation">:</span>p6spy<span class="token punctuation">:</span>mysql<span class="token punctuation">:</span>//localhost<span class="token punctuation">:</span>3306/数据库名    <span class="token punctuation">...</span></code></pre><ul><li>spy.properties 配置：</li></ul><pre class="language-properties" data-language="properties"><code class="language-properties"><span class="token comment">#3.2.1以上使用</span><span class="token attr-name">modulelist</span><span class="token punctuation">=</span><span class="token attr-value">com.baomidou.mybatisplus.extension.p6spy.MybatisPlusLogFactory,com.p6spy.engine.outage.P6OutageFactory</span><span class="token comment">#3.2.1以下使用或者不配置</span><span class="token comment">#modulelist=com.p6spy.engine.logging.P6LogFactory,com.p6spy.engine.outage.P6OutageFactory</span><span class="token comment"># 自定义日志打印</span><span class="token attr-name">logMessageFormat</span><span class="token punctuation">=</span><span class="token attr-value">com.baomidou.mybatisplus.extension.p6spy.P6SpyLogger</span><span class="token comment">#日志输出到控制台</span><span class="token attr-name">appender</span><span class="token punctuation">=</span><span class="token attr-value">com.baomidou.mybatisplus.extension.p6spy.StdoutLogger</span><span class="token comment"># 使用日志系统记录 sql</span><span class="token comment">#appender=com.p6spy.engine.spy.appender.Slf4JLogger</span><span class="token comment"># 设置 p6spy driver 代理</span><span class="token attr-name">deregisterdrivers</span><span class="token punctuation">=</span><span class="token attr-value">true</span><span class="token comment"># 取消JDBC URL前缀</span><span class="token attr-name">useprefix</span><span class="token punctuation">=</span><span class="token attr-value">true</span><span class="token comment"># 配置记录 Log 例外,可去掉的结果集有error,info,batch,debug,statement,commit,rollback,result,resultset.</span><span class="token attr-name">excludecategories</span><span class="token punctuation">=</span><span class="token attr-value">info,debug,result,commit,resultset</span><span class="token comment"># 日期格式</span><span class="token attr-name">dateformat</span><span class="token punctuation">=</span><span class="token attr-value">yyyy-MM-dd HH:mm:ss</span><span class="token comment"># 实际驱动可多个</span><span class="token comment">#driverlist=org.h2.Driver</span><span class="token comment"># 是否开启慢SQL记录</span><span class="token attr-name">outagedetection</span><span class="token punctuation">=</span><span class="token attr-value">true</span><span class="token comment"># 慢SQL记录标准 2 秒</span><span class="token attr-name">outagedetectioninterval</span><span class="token punctuation">=</span><span class="token attr-value">2</span></code></pre><blockquote><p>注意！</p><ul><li>driver-class-name 为 p6spy 提供的驱动类</li><li>url 前缀为 jdbc:p6spy 跟着冒号为对应数据库连接地址</li><li>打印出sql为null,在excludecategories增加commit</li><li>批量操作不打印sql,去除excludecategories中的batch</li><li>批量操作打印重复的问题请使用MybatisPlusLogFactory (3.2.1新增）</li><li>该插件有性能损耗，不建议生产环境使用。</li></ul></blockquote>]]></content>
    
    
    <summary type="html">MyBatis-Plus（简称 MP）是一个 MyBatis 的增强工具，在 MyBatis 的基础上只做增强不做改变，为简化开发、提高效率而生。</summary>
    
    
    
    <category term="mybatis" scheme="https://zzugzj.github.io/categories/mybatis/"/>
    
    
    <category term="学习笔记" scheme="https://zzugzj.github.io/tags/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    
    <category term="mybatisPlus" scheme="https://zzugzj.github.io/tags/mybatisPlus/"/>
    
  </entry>
  
  <entry>
    <title>Git分支</title>
    <link href="https://zzugzj.github.io/posts/7a7ff038/"/>
    <id>https://zzugzj.github.io/posts/7a7ff038/</id>
    <published>2021-01-05T01:14:09.000Z</published>
    <updated>2023-11-05T05:45:20.319Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><h2 id="分支简介"><a href="#分支简介" class="headerlink" title="分支简介"></a>分支简介</h2><p>Git 保存的不是文件差异或者变化量，而只是一系列文件快照。</p><p>在 Git 中提交时，会保存一个提交（commit）对象，该对象包含一个指向暂存内容快照的指针，包含本次提交的作者等相关附属信息，包含零个或多个指向该提交对象的父对象指针：首次提交是没有直接祖先的，普通提交有一个祖先，由两个或多个分支合并产生的提交则有多个祖先。</p><p>当使用 <code>git commit</code> 新建一个提交对象前，Git 会先计算每一个子目录（本例中就是项目根目录）的校验和，然后在 Git 仓库中将这些目录保存为树（tree）对象。之后 Git 创建的提交对象，除了包含相关提交信息以外，还包含着指向这个树对象（项目根目录）的指针，如此它就可以在将来需要的时候，重现此次快照的内容了。</p><p>使用<code>git commit</code>创建一个提交对象后，仓库中各个对象保存的数据和相互关系如图所示：</p><p><img src="https://raw.githubusercontent.com/zzugzj/blogImg/master/img/2015-10-12_561bcb5aaaabe.png" alt="首次提交对象及其树结构." loading="lazy"></p><p>作些修改后再次提交，那么这次的提交对象会包含一个指向上次提交对象的指针（译注：即下图中的 parent 对象）。两次提交后，仓库历史会变成 的样子：</p><p><img src="https://raw.githubusercontent.com/zzugzj/blogImg/master/img/2015-10-12_561bcb5ac6fec.png" alt="提交对象及其父对象." loading="lazy"></p><p>Git 中的分支，其实本质上仅仅是个指向 commit 对象的可变指针。Git 会使用 master 作为分支的默认名字。在若干次提交后，你其实已经有了一个指向最后一次提交对象的 master 分支，它在每次提交的时候都会自动向前移动。</p><p><img src="https://raw.githubusercontent.com/zzugzj/blogImg/master/img/2015-10-12_561bcb5adcb57.png" alt="分支及其提交历史." loading="lazy"></p><p>新建一个 testing 分支，可以使用 <code>git branch</code> 命令：</p><pre class="language-none"><code class="language-none">$ git branch testing</code></pre><p>这会在当前 commit 对象上新建一个分支指针。</p><p><img src="https://raw.githubusercontent.com/zzugzj/blogImg/master/img/2015-10-12_561bcb5aee442.png" alt="两个指向相同提交历史的分支。" loading="lazy"></p><p>Git通过保存一个名为HEAD的特别指针来知道当前在哪个分支上工作，HEAD是一个指向你正在工作中的本地分支的指针。运行 <code>git branch</code> 命令，仅仅是建立了一个新的分支，但不会自动切换到这个分支中去，所以在这个例子中，我们依然还在 master 分支里工作。</p><p><img src="https://raw.githubusercontent.com/zzugzj/blogImg/master/img/2015-10-12_561bcb5b0bb09.png" alt="HEAD 指向当前所在的分支." loading="lazy"></p><p>要切换到其他分支，可以执行 <code>git checkout</code> 命令。我们现在转换到新建的 testing 分支：</p><pre class="language-none"><code class="language-none">$ git checkout testing</code></pre><p>这样 HEAD 就指向了 testing 分支。</p><p><img src="https://raw.githubusercontent.com/zzugzj/blogImg/master/img/2015-10-12_561bcb5b1b5c1.png" alt="HEAD 指向当前所在的分支." loading="lazy"></p><p>如果现在再提交一次，就会变成如下图所示：</p><p><img src="https://raw.githubusercontent.com/zzugzj/blogImg/master/img/2015-10-12_561bcb5b31055.png" alt="HEAD 分支随着提交操作自动向前移动." loading="lazy"></p><p>现在testing 分支向前移动了一格，而 master 分支仍然指向原先 <code>git checkout</code> 时所在的 commit 对象。现在我们回到 master 分支看看：</p><pre class="language-none"><code class="language-none">$ git checkout master</code></pre><p>这条命令做了两件事。它把 HEAD 指针移回到 master 分支，并把工作目录中的文件换成了 master 分支所指向的快照内容。</p><p>我们作些修改后再次提交的话，项目的提交历史就会产生分叉。刚才我们创建了一个分支，转换到其中进行了一些工作，然后又回到原来的主分支进行了另外一些工作。这些改变分别孤立在不同的分支里：我们可以在不同分支里反复切换，并在时机成熟时把它们合并到一起。</p><p><img src="https://raw.githubusercontent.com/zzugzj/blogImg/master/img/2015-10-12_561bcb5b52163.png" alt="项目分叉历史." loading="lazy"></p><p>Git 中的分支实际上仅是一个包含所指对象校验和（40 个字符长度 SHA-1 字串）的文件，所以创建和销毁一个分支就变得非常廉价。</p><h2 id="分支的新建与合并"><a href="#分支的新建与合并" class="headerlink" title="分支的新建与合并"></a>分支的新建与合并</h2><h3 id="分支的新建与切换"><a href="#分支的新建与切换" class="headerlink" title="分支的新建与切换"></a>分支的新建与切换</h3><p>要新建并切换到该分支，运行 <code>git checkout</code> 并加上 <code>-b</code> 参数：</p><pre class="language-none"><code class="language-none">$ git checkout -b iss53Switched to a new branch &quot;iss53&quot;</code></pre><p>这相当于执行下面这两条命令：</p><pre class="language-none"><code class="language-none">$ git branch iss53$ git checkout iss53</code></pre><p>不过在此之前，暂存区或者工作目录里那些还没有提交的修改会和即将检出的分支产生冲突从而阻止 Git 切换分支。切换分支的时候最好保持一个清洁的工作区域。</p><p>分支如果要进行合并可以使用<code>git merge</code> 命令来进行合并：</p><p><img src="https://raw.githubusercontent.com/zzugzj/blogImg/master/img/2015-10-12_561bcb5ccb01a.png" alt="基于  分支的紧急问题分支（hotfix branch）。" loading="lazy"></p><pre class="language-none"><code class="language-none">$ git checkout master$ git merge hotfixUpdating 5c2482d..15dcd1cFast-forward qwe.txt | 1 + 1 file changed, 1 insertion(+)</code></pre><p>合并时出现了“Fast forward”的提示。由于当前 <code>master</code> 分支所在的提交对象是要并入的 <code>hotfix</code> 分支的直接上游，Git 只需把 <code>master</code> 分支指针直接右移。换句话说，如果顺着一个分支走下去可以到达另一个分支的话，那么 Git 在合并两者时，只会简单地把指针右移，因为这种单线的历史分支不存在任何需要解决的分歧，所以这种合并过程可以称为快进（Fast forward）。</p><p>由于当前 <code>hotfix</code> 分支和 <code>master</code> 都指向相同的提交对象，所以 <code>hotfix</code> 已经完成了历史使命，可以删掉了。使用 <code>git branch</code> 的 <code>-d</code> 选项执行删除操作：</p><pre class="language-none"><code class="language-none">$ git branch -d hotfixDeleted branch hotfix (was 15dcd1c).</code></pre><h3 id="分支的合并"><a href="#分支的合并" class="headerlink" title="分支的合并"></a>分支的合并</h3><p>在问题 #53 相关的工作完成之后，可以合并回 <code>master</code> 分支。实际操作同前面合并 <code>hotfix</code> 分支差不多，只需回到 <code>master</code> 分支，运行 <code>git merge</code> 命令指定要合并进来的分支：</p><pre class="language-none"><code class="language-none">$ git checkout master$ git merge iss53Merge made by the &#39;recursive&#39; strategy. pom.xml | 2 +- 1 file changed, 1 insertion(+), 1 deletion(-)</code></pre><p>这次合并操作的底层实现，并不同于之前 <code>hotfix</code> 的并入方式。因为这次你的开发历史是从更早的地方开始分叉的。由于当前 <code>master</code> 分支所指向的提交对象（C4）并不是 <code>iss53</code> 分支的直接祖先，Git 不得不进行一些额外处理。就此例而言，Git 会用两个分支的末端（C4 和 C5）以及它们的共同祖先（C2）进行一次简单的三方合并计算。图 3-16 用红框标出了 Git 用于合并的三个提交对象：</p><p><img src="https://raw.githubusercontent.com/zzugzj/blogImg/master/img/18333fig0316-tn.png" alt="img" loading="lazy"></p><p>这次，Git 没有简单地把分支指针右移，而是对三方合并后的结果重新做一个新的快照，并自动创建一个指向它的提交对象（C6）（见图 3-17）。这个提交对象比较特殊，它有两个祖先（C4 和 C5）。</p><p><img src="https://raw.githubusercontent.com/zzugzj/blogImg/master/img/18333fig0317-tn.png" alt="img" loading="lazy"></p><h3 id="遇到冲突时的分支合并"><a href="#遇到冲突时的分支合并" class="headerlink" title="遇到冲突时的分支合并"></a>遇到冲突时的分支合并</h3><p>有时候合并操作并不会如此顺利。如果在不同的分支中都修改了同一个文件的同一部分，Git 就无法干净地把两者合到一起（译注：逻辑上说，这种问题只能由人来裁决。）。如果你在解决问题 #53 的过程中修改了 <code>hotfix</code> 中修改的部分，将得到类似下面的结果：</p><pre class="language-none"><code class="language-none">$ git merge iss54Auto-merging qwe.txtCONFLICT (content): Merge conflict in qwe.txtAutomatic merge failed; fix conflicts and then commit the result.</code></pre><p>Git 作了合并，但没有提交，它会停下来等你解决冲突。要看看哪些文件在合并时发生冲突，可以用 <code>git status</code> 查阅:</p><pre class="language-none"><code class="language-none">$ git statusOn branch masterYour branch is ahead of &#39;origin&#x2F;master&#39; by 5 commits.  (use &quot;git push&quot; to publish your local commits)You have unmerged paths.  (fix conflicts and run &quot;git commit&quot;)  (use &quot;git merge --abort&quot; to abort the merge)Unmerged paths:  (use &quot;git add &lt;file&gt;...&quot; to mark resolution)        both modified:   qwe.txtno changes added to commit (use &quot;git add&quot; and&#x2F;or &quot;git commit -a&quot;)</code></pre><p>在Unmerged paths里列出所有冲突文件。</p><p>打开qwe.txt可以看到：</p><pre class="language-none"><code class="language-none">啊啊啊啊啊啊啊啊啊啊啊啊啊啊啊&lt;&lt;&lt;&lt;&lt;&lt;&lt; HEAD亲委&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;士大夫撒旦&gt;&gt;&gt;&gt;&gt;&gt;&gt; iss54</code></pre><p>可以看到 <code>=======</code> 隔开的上半部分，是 <code>HEAD</code>（即 <code>master</code> 分支，在运行 <code>merge</code> 命令时所切换到的分支）中的内容，下半部分是在 <code>iss54</code> 分支中的内容。解决冲突的办法无非是二者选其一或者由你亲自整合到一起。比如你可以通过把这段内容替换为下面这样来解决：</p><pre class="language-none"><code class="language-none">啊啊啊啊啊啊啊啊啊啊啊啊啊啊啊亲委士大夫撒旦</code></pre><p>然后执行git add和git commit完成合并提交。</p><h2 id="分支管理"><a href="#分支管理" class="headerlink" title="分支管理"></a>分支管理</h2><p><code>git branch</code> 命令不仅仅能创建和删除分支，如果不加任何参数，它会给出当前所有分支的清单：</p><pre class="language-none"><code class="language-none">$ git branch  iss53  iss54* master</code></pre><p>注意看 <code>master</code> 分支前的 <code>*</code> 字符：它表示当前所在的分支。也就是说，如果现在提交更新，<code>master</code> 分支将随着开发进度前移。若要查看各个分支最后一个提交对象的信息，运行 <code>git branch -v</code>：</p><pre class="language-none"><code class="language-none">$ git branch -v  iss53  a87e37d qw  iss54  d121dae qw* master 1ebd4d5 [ahead 7] up</code></pre><p>要从该清单中筛选出你已经（或尚未）与当前分支合并的分支，可以用 <code>--merge</code> 和 <code>--no-merged</code> 选项。比如用 <code>git branch --merge</code> 查看哪些分支已被并入当前分支：</p><pre class="language-none"><code class="language-none">$ git branch --merged  iss53  iss54* master</code></pre><p>一般来说，列表中没有 <code>*</code> 的分支通常都可以用 <code>git branch -d</code> 来删掉。原因很简单，既然已经把它们所包含的工作整合到了其他分支，删掉也不会损失什么。</p><p>另外可以用 <code>git branch --no-merged</code> 查看尚未合并的工作：</p><pre class="language-none"><code class="language-none">$ git branch --no-merged    testing</code></pre><p>它会显示还未合并进来的分支。由于这些分支中还包含着尚未合并进来的工作成果，所以简单地用 <code>git branch -d</code> 删除该分支会提示错误，因为那样做会丢失数据：</p><pre class="language-none"><code class="language-none">$ git branch -d testingerror: The branch &#39;testing&#39; is not fully merged.If you are sure you want to delete it, run &#39;git branch -D testing&#39;.</code></pre><p>不过，如果你确实想要删除该分支上的改动，可以用大写的删除选项 <code>-D</code> 强制执行，就像上面提示信息中给出的那样。</p><h2 id="利用分支进行开发的工作流程"><a href="#利用分支进行开发的工作流程" class="headerlink" title="利用分支进行开发的工作流程"></a>利用分支进行开发的工作流程</h2><h3 id="长期分支"><a href="#长期分支" class="headerlink" title="长期分支"></a>长期分支</h3><p>许多使用 Git 的开发者都喜欢用这种方式来开展工作，比如仅在 <code>master</code> 分支中保留完全稳定的代码，即已经发布或即将发布的代码。与此同时，他们还有一个名为 <code>develop</code> 或 <code>next</code> 的平行分支，专门用于后续的开发，或仅用于稳定性测试 — 当然并不是说一定要绝对稳定，不过一旦进入某种稳定状态，便可以把它合并到 <code>master</code> 里。</p><p><img src="https://raw.githubusercontent.com/zzugzj/blogImg/master/img/2015-10-12_561bcb5de1972.png" alt="渐进稳定分支的工作流（“silo”）视图。" loading="lazy"></p><h3 id="特性分支"><a href="#特性分支" class="headerlink" title="特性分支"></a>特性分支</h3><p>在任何规模的项目中都可以使用特性（Topic）分支。一个特性分支是指一个短期的，用来实现单一特性或与其相关工作的分支。</p><p>现在我们来看一个实际的例子。请看图 ，由下往上，起先我们在 <code>master</code> 工作到 C1，然后开始一个新分支 <code>iss91</code> 尝试修复 91 号缺陷，提交到 C6 的时候，又冒出一个解决该问题的新办法，于是从之前 C4 的地方又分出一个分支 <code>iss91v2</code>，干到 C8 的时候，又回到主干 <code>master</code> 中提交了 C9 和 C10，再回到 <code>iss91v2</code> 继续工作，提交 C11，接着，又冒出个不太确定的想法，从 <code>master</code> 的最新提交 C10 处开了个新的分支 <code>dumbidea</code> 做些试验。</p><p><img src="https://raw.githubusercontent.com/zzugzj/blogImg/master/img/2015-10-12_561bcb5df1ada.png" alt="拥有多个特性分支的提交历史。" loading="lazy"></p><p>现在，假定两件事情：我们最终决定使用第二个解决方案，即 <code>iss91v2</code> 中的办法；另外，我们把 <code>dumbidea</code> 分支拿给同事们看了以后，发现它竟然是个天才之作。所以接下来，我们准备抛弃原来的 <code>iss91</code> 分支（实际上会丢弃 C5 和 C6），直接在主干中并入另外两个分支。最终的提交历史将变成下图这样：</p><p><img src="https://raw.githubusercontent.com/zzugzj/blogImg/master/img/2015-10-12_561bcb5e18de5.png" alt="合并了  和  分支之后的提交历史。" loading="lazy"></p><p>请务必牢记这些分支全部都是本地分支，这一点很重要。当你在使用分支及合并的时候，一切都是在你自己的 Git 仓库中进行的 — 完全不涉及与服务器的交互。</p><h2 id="远程分支"><a href="#远程分支" class="headerlink" title="远程分支"></a>远程分支</h2><p>远程分支（remote branch）是对远程仓库中的分支的索引。它们是一些无法移动的本地分支；只有在 Git 进行网络交互时才会更新。</p><p>远程引用是对远程仓库的引用（指针），包括分支、标签等等。你可以通过 <code>git ls-remote (remote)</code> 来显式地获得远程引用的完整列表，或者通过 <code>git remote show (remote)</code> 获得远程分支的更多信息。然而，一个更常见的做法是利用远程跟踪分支。</p><p>我们用 <code>(远程仓库名)/(分支名)</code> 这样的形式表示远程分支。比如我们想看看上次同 <code>origin</code> 仓库通讯时 <code>master</code> 分支的样子，就应该查看 <code>origin/master</code> 分支。如果你和同伴一起修复某个问题，但他们先推送了一个 <code>iss53</code> 分支到远程仓库，虽然你可能也有一个本地的 <code>iss53</code> 分支，但指向服务器上最新更新的却应该是 <code>origin/iss53</code> 分支。</p><blockquote><h3 id="“origin”-并无特殊含义"><a href="#“origin”-并无特殊含义" class="headerlink" title="“origin” 并无特殊含义"></a>“origin” 并无特殊含义</h3></blockquote><blockquote><p>远程仓库名字 “origin” 与分支名字 “master” 一样，在 Git 中并没有任何特别的含义一样。同时 “master” 是当你运行 <code>git init</code> 时默认的起始分支名字，原因仅仅是它的广泛使用，“origin” 是当你运行 <code>git clone</code> 时默认的远程仓库名字。如果你运行 <code>git clone -o booyah</code>，那么你默认的远程分支名字将会是 <code>booyah/master</code>。</p></blockquote><p>如果你在本地 <code>master</code> 分支做了些改动，与此同时，其他人向 <code>git.ourcompany.com</code> 推送了他们的更新，那么服务器上的 <code>master</code> 分支就会向前推进，而于此同时，你在本地的提交历史正朝向不同方向发展。不过只要你不和服务器通讯，你的 <code>origin/master</code> 指针仍然保持原位不会移动。</p><p><img src="https://raw.githubusercontent.com/zzugzj/blogImg/master/img/2015-10-12_561bcb5f813c8.png" alt="本地与远程的工作可以分叉。" loading="lazy"></p><p>可以运行 <code>git fetch origin</code> 来同步远程服务器上的数据到本地。该命令首先找到 <code>origin</code> 是哪个服务器（本例为 <code>git.ourcompany.com</code>），从上面获取你尚未拥有的数据，更新你本地的数据库，然后把 <code>origin/master</code> 的指针移到它最新的位置上。</p><p><img src="https://raw.githubusercontent.com/zzugzj/blogImg/master/img/2015-10-12_561bcb5f98f62.png" alt=" 更新你的远程仓库引用。" loading="lazy"></p><h3 id="推送本地分支"><a href="#推送本地分支" class="headerlink" title="推送本地分支"></a>推送本地分支</h3><p>把本地分支推送到远程仓库<code>git push (远程仓库名) (分支名)</code>。</p><p>运行 <code>git push origin serverfix:serverfix</code> ，它的意思是“上传我本地的 serverfix 分支到远程仓库中去，仍旧称它为 serverfix 分支”。通过此语法，你可以把本地分支推送到某个命名不同的远程分支：若想把远程分支叫作 <code>awesomebranch</code>，可以用 <code>git push origin serverfix:awesomebranch</code> 来推送数据。</p><p><code>git checkout -b serverfix origin/serverfix</code>是会切换到新建的 <code>serverfix</code> 本地分支，其内容同远程分支 <code>origin/serverfix</code> 一致。</p><h3 id="跟踪远程分支"><a href="#跟踪远程分支" class="headerlink" title="跟踪远程分支"></a>跟踪远程分支</h3><p>在克隆仓库时，Git 通常会自动创建一个名为 <code>master</code> 的分支来跟踪 <code>origin/master</code>。这正是 <code>git push</code> 和 <code>git pull</code> 一开始就能正常工作的原因。当然，你可以随心所欲地设定为其它跟踪分支，比如 <code>origin</code> 上除了 <code>master</code> 之外的其它分支。刚才我们已经看到了这样的一个例子：<code>git checkout -b [分支名] [远程名]/[分支名]</code>。如果你有 1.6.2 以上版本的 Git，还可以用 <code>--track</code> 选项简化：</p><pre class="language-none"><code class="language-none">$ git checkout --track origin&#x2F;serverfix</code></pre><p>要为本地分支设定不同于远程分支的名字，只需在第一个版本的命令里换个名字：</p><pre class="language-none"><code class="language-none">$ git checkout -b sf origin&#x2F;serverfix</code></pre><p>现在你的本地分支 <code>sf</code> 会自动将推送和抓取数据的位置定位到 <code>origin/serverfix</code> 了。</p><p>如果想要查看设置的所有跟踪分支，可以使用 <code>git branch</code> 的 <code>-vv</code> 选项。这会将所有的本地分支列出来并且包含更多的信息，如每一个分支正在跟踪哪个远程分支与本地分支是否是领先、落后或是都有。</p><pre class="language-none"><code class="language-none">$ git branch -vv* master  df81349 [origin&#x2F;master: ahead 8] as  testing 22add77 qwe</code></pre><p>这里可以看到<code> master</code>分支正在跟踪 <code>origin/master</code>并且 “ahead” 是 8，意味着本地有两个提交还没有推送到服务器上。</p><p>如果想要统计最新的领先与落后数字，需要在运行此命令前抓取所有的远程仓库。可以像这样做：<code>$ git fetch --all; git branch -vv</code></p><h3 id="删除远程分支"><a href="#删除远程分支" class="headerlink" title="删除远程分支"></a>删除远程分支</h3><p><code>git push origin --delete 分支名</code></p><p>在删除远程分支时，同名的本地分支并不会被删除，所以还需要单独删除本地同名分支。</p><h2 id="变基"><a href="#变基" class="headerlink" title="变基"></a>变基</h2><p>在 Git 中整合来自不同分支的修改主要有两种方法：<code>merge</code> 以及 <code>rebase</code>。</p><h3 id="变基的基本操作"><a href="#变基的基本操作" class="headerlink" title="变基的基本操作"></a>变基的基本操作</h3><p>假设分支提交历史如下：</p><p><img src="https://raw.githubusercontent.com/zzugzj/blogImg/master/img/2015-10-12_561bcb6162ea5.png" alt="分叉的提交历史" loading="lazy"></p><p>如果使用merge命令，它会把两个分支的最新快照C3和C4以及二者共同祖先C2合并，生成一个新的快照并提交。</p><p>其实，还有一种方法：你可以提取在 <code>C4</code> 中引入的补丁和修改，然后在 <code>C3</code> 的基础上再应用一次。在 Git 中，这种操作就叫做 <em>变基</em>。你可以使用 <code>rebase</code> 命令将提交到某一分支上的所有修改都移至另一分支上，就好像“重新播放”一样。</p><p>在上面这个例子中，运行：</p><pre class="language-none"><code class="language-none">$ git checkout experiment$ git rebase masterSuccessfully rebased and updated refs&#x2F;heads&#x2F;experiment.</code></pre><p>它的原理是首先找到这两个分支（即当前分支 <code>experiment</code>、变基操作的目标基底分支 <code>master</code>）的最近共同祖先 <code>C2</code>，然后对比当前分支相对于该祖先的历次提交，提取相应的修改并存为临时文件，然后将当前分支指向目标基底 <code>C3</code>, 最后以此将之前另存为临时文件的修改依序应用。</p><p><img src="https://raw.githubusercontent.com/zzugzj/blogImg/master/img/2015-10-12_561bcb6189bbc.png" alt="将  中的修改变基到  上" loading="lazy"></p><p>现在回到 <code>master</code> 分支，进行一次快进合并。</p><pre class="language-none"><code class="language-none">$ git checkout master$ git merge experiment</code></pre><p><img src="https://raw.githubusercontent.com/zzugzj/blogImg/master/img/2015-10-12_561bcb619d7bf.png" alt="master 分支的快进合并" loading="lazy"></p><h3 id="变基的风险"><a href="#变基的风险" class="headerlink" title="变基的风险"></a>变基的风险</h3><p><strong>不要对在你的仓库外有副本的分支执行变基。</strong></p><p>变基操作的实质是丢弃一些现有的提交，然后相应地新建一些内容一样但实际上不同的提交。如果你已经将提交推送至某个仓库，而其他人也已经从该仓库拉取提交并进行了后续工作，此时，如果你用 <code>git rebase</code> 命令重新整理了提交并再次推送，你的同伴因此将不得不再次将他们手头的工作与你的提交进行整合，如果接下来你还要拉取并整合他们修改过的提交，事情就会变得一团糟。</p>]]></content>
    
    
    <summary type="html">几乎每一种版本控制系统都以某种形式支持分支。使用分支意味着你可以从开发主线上分离开来，然后在不影响主线的同时继续工作。在很多版本控制系统中，这是个昂贵的过程，常常需要创建一个源代码目录的完整副本，对大型项目来说会花费很长时间。</summary>
    
    
    
    <category term="git" scheme="https://zzugzj.github.io/categories/git/"/>
    
    
    <category term="学习笔记" scheme="https://zzugzj.github.io/tags/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    
    <category term="git" scheme="https://zzugzj.github.io/tags/git/"/>
    
  </entry>
  
  <entry>
    <title>Git基础</title>
    <link href="https://zzugzj.github.io/posts/1a60696b/"/>
    <id>https://zzugzj.github.io/posts/1a60696b/</id>
    <published>2021-01-04T02:34:56.000Z</published>
    <updated>2023-11-05T05:46:51.825Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><h2 id="取得项目的Git仓库"><a href="#取得项目的Git仓库" class="headerlink" title="取得项目的Git仓库"></a>取得项目的Git仓库</h2><p>有两种取得 Git 项目仓库的方法。第一种是在现存的目录下，通过导入所有文件来创建新的 Git 仓库。第二种是从已有的 Git 仓库克隆出一个新的镜像仓库来。</p><h3 id="在工作目录中初始化新仓库"><a href="#在工作目录中初始化新仓库" class="headerlink" title="在工作目录中初始化新仓库"></a>在工作目录中初始化新仓库</h3><p>要对现有的某个项目开始用 Git 管理，只需到此项目所在的目录，执行：</p><pre class="language-none"><code class="language-none">$ git init</code></pre><p>初始化后，在当前目录下会出现一个名为 .git 的目录，所有 Git 需要的数据和资源都存放在这个目录中。</p><p>如果当前目录下有几个文件想要纳入版本控制，需要先用 <code>git add</code> 命令告诉 Git 开始对这些文件进行跟踪，然后提交：</p><pre class="language-none"><code class="language-none">$ git add *.c$ git add README$ git commit -m &#39;initial project version&#39;</code></pre><h3 id="克隆现有的仓库"><a href="#克隆现有的仓库" class="headerlink" title="克隆现有的仓库"></a>克隆现有的仓库</h3><p>如果想对某个开源项目出一份力，可以先把该项目的 Git 仓库复制一份出来，这就需要用到 <code>git clone</code> 命令。实际上，即便服务器的磁盘发生故障，用任何一个克隆出来的客户端都可以重建服务器上的仓库，回到当初克隆时的状态。</p><p>克隆仓库的命令格式为 <code>git clone [url]</code>。比如，要克隆 Ruby 语言的 Git 代码仓库 Grit，可以用下面的命令：</p><pre class="language-none"><code class="language-none">$ git clone git:&#x2F;&#x2F;github.com&#x2F;schacon&#x2F;grit.git</code></pre><p>这会在当前目录下创建一个名为<code>grit</code>的目录，其中包含一个 <code>.git</code> 的目录，用于保存下载下来的所有版本记录，然后从中取出最新版本的文件拷贝。如果希望在克隆的时候，自己定义要新建的项目目录名称，可以在上面的命令末尾指定新的名字：</p><pre class="language-none"><code class="language-none">$ git clone git:&#x2F;&#x2F;github.com&#x2F;schacon&#x2F;grit.git mygrit</code></pre><p>唯一的差别就是，现在新建的目录成了 <code>mygrit</code>，其他的都和上边的一样。</p><p>Git 支持许多数据传输协议。之前的例子使用的是 <code>git://</code> 协议，不过你也可以用 <code>http(s)://</code> 或者 <code>user@server:/path.git</code> 表示的 SSH 传输协议。</p><h2 id="记录每次更新到仓库"><a href="#记录每次更新到仓库" class="headerlink" title="记录每次更新到仓库"></a>记录每次更新到仓库</h2><p>工作目录下面的所有文件都不外乎这两种状态：已跟踪或未跟踪。已跟踪的文件是指本来就被纳入版本控制管理的文件，在上次快照中有它们的记录，工作一段时间后，它们的状态可能是未更新，已修改或者已放入暂存区。而所有其他文件都属于未跟踪文件。它们既没有上次更新时的快照，也不在当前的暂存区域。初次克隆某个仓库时，工作目录中的所有文件都属于已跟踪文件，且状态为未修改。</p><p>在编辑过某些文件之后，Git 将这些文件标为已修改。我们逐步把这些修改过的文件放到暂存区域，直到最后一次性提交所有这些暂存起来的文件，如此重复。</p><p><img src="https://raw.githubusercontent.com/zzugzj/blogImg/master/img/2015-10-12_561bcb568ace5.png" alt="Git 下文件生命周期图。" loading="lazy"></p><h3 id="检查当前文件状态"><a href="#检查当前文件状态" class="headerlink" title="检查当前文件状态"></a>检查当前文件状态</h3><p>要确定哪些文件当前处于什么状态，可以用 <code>git status</code> 命令。如果在克隆仓库之后立即执行此命令，会看到类似这样的输出：</p><pre class="language-shell" data-language="shell"><code class="language-shell">$ <span class="token function">git</span> statusOn branch masternothing to commit, working tree clean</code></pre><h3 id="跟踪新文件"><a href="#跟踪新文件" class="headerlink" title="跟踪新文件"></a>跟踪新文件</h3><p>使用命令 <code>git add</code> 开始跟踪一个新文件。</p><p>所以，要跟踪 README 文件，运行：</p><pre class="language-none"><code class="language-none">$ git add README</code></pre><p>此时再运行 <code>git status</code> 命令，会看到 README 文件已被跟踪，并处于暂存状态：</p><pre class="language-shell" data-language="shell"><code class="language-shell">$ <span class="token function">git</span> statusOn branch masterYour branch is up to <span class="token function">date</span> with <span class="token string">'origin/master'</span><span class="token builtin class-name">.</span>Changes to be committed:  <span class="token punctuation">(</span>use <span class="token string">"git restore --staged &lt;file>..."</span> to unstage<span class="token punctuation">)</span>        modified:   README</code></pre><p>只要在 “Changes to be committed” 这行下面的，就说明是已暂存状态。如果此时提交，那么该文件此时此刻的版本将被留存在历史记录中。</p><h3 id="暂存已修改文件"><a href="#暂存已修改文件" class="headerlink" title="暂存已修改文件"></a>暂存已修改文件</h3><p>现在我们修改下之前已跟踪过的文件 <code>README.md</code>，然后再次运行 <code>status</code> 命令，会看到这样的状态报告：</p><pre class="language-shell" data-language="shell"><code class="language-shell">$ <span class="token function">git</span> statusOn branch masterYour branch is up to <span class="token function">date</span> with <span class="token string">'origin/master'</span><span class="token builtin class-name">.</span>Changes not staged <span class="token keyword">for</span> commit:  <span class="token punctuation">(</span>use <span class="token string">"git add &lt;file>..."</span> to update what will be committed<span class="token punctuation">)</span>  <span class="token punctuation">(</span>use <span class="token string">"git restore &lt;file>..."</span> to discard changes <span class="token keyword">in</span> working directory<span class="token punctuation">)</span>        modified:   README.mdno changes added to commit <span class="token punctuation">(</span>use <span class="token string">"git add"</span> and/or <span class="token string">"git commit -a"</span><span class="token punctuation">)</span></code></pre><p>文件 <code>README.md</code> 出现在 “Changes not staged for commit” 这行下面，说明已跟踪文件的内容发生了变化，但还没有放到暂存区。要暂存这次更新，需要运行 <code>git add</code> 命令（这是个多功能命令，根据目标文件的状态不同，此命令的效果也不同：可以用它开始跟踪新文件，或者把已跟踪的文件放到暂存区，还能用于合并时把有冲突的文件标记为已解决状态等）。现在让我们运行 <code>git add</code> 将<code>README.md</code> 放到暂存区，然后再看看 <code>git status</code> 的输出：</p><pre class="language-none"><code class="language-none">$ git statusOn branch masterYour branch is up to date with &#39;origin&#x2F;master&#39;.Changes to be committed:  (use &quot;git restore --staged &lt;file&gt;...&quot; to unstage)        modified:   README.md</code></pre><h3 id="状态简览"><a href="#状态简览" class="headerlink" title="状态简览"></a>状态简览</h3><p><code>git status</code> 命令的输出十分详细，但其用语有些繁琐。如果你使用 <code>git status -s</code> 命令或 <code>git status --short</code> 命令，你将得到一种更为紧凑的格式输出。运行 <code>git status -s</code> ，状态报告输出如下：</p><pre class="language-none"><code class="language-none">$ git status -s M READMEMM RakefileA  lib&#x2F;git.rbM  lib&#x2F;simplegit.rb?? LICENSE.txt</code></pre><p>新添加的未跟踪文件前面有 <code>??</code> 标记。</p><p>新添加到暂存区中的文件前面有 <code>A</code> 标记。</p><p>修改过的文件前面有 <code>M</code> 标记。</p><p> <code>M</code> 有两个可以出现的位置，出现在右边的 <code>M</code> 表示该文件被修改了但是还没放入暂存区，出现在靠左边的 <code>M</code> 表示该文件被修改了并放入了暂存区。</p><h3 id="忽略文件"><a href="#忽略文件" class="headerlink" title="忽略文件"></a>忽略文件</h3><p>一般我们总会有些文件无需纳入 Git 的管理，也不希望它们总出现在未跟踪文件列表。通常都是些自动生成的文件，比如日志文件，或者编译过程中创建的临时文件等。我们可以创建一个名为 <code>.gitignore</code> 的文件，列出要忽略的文件模式。来看一个实际的例子：</p><pre class="language-none"><code class="language-none">$ cat .gitignore# Compiled class file*.class</code></pre><p>第一行告诉 Git 忽略所有以 <code>.class</code> 结尾的文件。一般这类对象文件和存档文件都是编译过程中出现的，我们用不着跟踪它们的版本。要养成一开始就设置好 <code>.gitignore</code> 文件的习惯，以免将来误提交这类无用的文件。</p><p>文件 <code>.gitignore</code> 的格式规范如下：</p><ul><li>所有空行或者以注释符号 <code>＃</code> 开头的行都会被 Git 忽略。</li><li>可以使用标准的 glob 模式匹配。</li><li>匹配模式最后跟反斜杠（<code>/</code>）说明要忽略的是目录。</li><li>要忽略指定模式以外的文件或目录，可以在模式前加上惊叹号（<code>!</code>）取反。</li></ul><p>所谓的 glob 模式是指 shell 所使用的简化了的正则表达式。星号（<code>*</code>）匹配零个或多个任意字符；<code>[abc]</code> 匹配任何一个列在方括号中的字符（这个例子要么匹配一个 a，要么匹配一个 b，要么匹配一个 c）；问号（<code>?</code>）只匹配一个任意字符；如果在方括号中使用短划线分隔两个字符，表示所有在这两个字符范围内的都可以匹配（比如 <code>[0-9]</code> 表示匹配所有 0 到 9 的数字）。使用两个星号（<code>*</code>) 表示匹配任意中间目录，比如<code>a/**/z</code> 可以匹配 <code>a/z</code>, <code>a/b/z</code> 或 <code>a/b/c/z</code>等。</p><p>我们再看一个 <code>.gitignore</code> 文件的例子：</p><pre class="language-shell" data-language="shell"><code class="language-shell"><span class="token comment"># 此为注释 – 将被 Git 忽略</span><span class="token comment"># 忽略所有 .a 结尾的文件</span>*.a<span class="token comment"># 但 lib.a 除外</span><span class="token operator">!</span>lib.a<span class="token comment"># 仅仅忽略项目根目录下的 TODO 文件，不包括 subdir/TODO</span>/TODO<span class="token comment"># 忽略 build/ 目录下的所有文件</span>build/<span class="token comment"># 会忽略 doc/notes.txt 但不包括 doc/server/arch.txt</span>doc/*.txt</code></pre><h3 id="查看已暂存和未暂存的更新"><a href="#查看已暂存和未暂存的更新" class="headerlink" title="查看已暂存和未暂存的更新"></a>查看已暂存和未暂存的更新</h3><p>实际上 <code>git status</code> 的显示比较简单，仅仅是列出了修改过的文件，如果要查看具体修改了什么地方，可以用 <code>git diff</code> 命令。<code>git diff</code> 会使用文件补丁的格式显示具体添加和删除的行。</p><p>要查看尚未暂存的文件更新了哪些部分，不加参数直接输入 <code>git diff</code>：</p><pre class="language-none"><code class="language-none">$ git diffdiff --git a&#x2F;README.md b&#x2F;README.mdindex e69de29..f2ba8f8 100644--- a&#x2F;README.md+++ b&#x2F;README.md@@ -0,0 +1 @@+abc\ No newline at end of file</code></pre><p>此命令比较的是工作目录中当前文件和暂存区域快照之间的差异，也就是修改之后还没有暂存起来的变化内容。</p><p>若要看已经暂存起来的文件和上次提交时的快照之间的差异，可以用 <code>git diff --cached</code> 命令。（Git 1.6.1 及更高版本还允许使用 <code>git diff --staged</code>，效果是相同的，但更好记些。）来看看实际的效果：</p><pre class="language-none"><code class="language-none">$ git diff --stageddiff --git a&#x2F;README.md b&#x2F;README.mdindex e69de29..f2ba8f8 100644--- a&#x2F;README.md+++ b&#x2F;README.md@@ -0,0 +1 @@+abc\ No newline at end of file</code></pre><h3 id="提交更新"><a href="#提交更新" class="headerlink" title="提交更新"></a>提交更新</h3><p>每次准备提交前，先用 <code>git status</code> 看下，是不是都已暂存起来了，然后再运行提交命令 <code>git commit</code>。</p><p>这种方式会启动文本编辑器以便输入本次提交的说明。另外也可以用 -m 参数后跟提交说明的方式，在一行命令中提交更新。</p><pre class="language-none"><code class="language-none">$ git commit[master ee80182] test 1 file changed, 1 insertion(+)</code></pre><p>可以看到，提交后它会告诉你，当前是在哪个分支（master）提交的，本次提交的完整 SHA-1 校验和是什么（ee80182），以及在本次提交中，有多少文件修订过，多少行添改和删改过。</p><p>提交时记录的是放在暂存区域的快照，任何还未暂存的仍然保持已修改状态，可以在下次提交时纳入版本管理。每一次运行提交操作，都是对你项目作一次快照，以后可以回到这个状态，或者进行比较。</p><h3 id="跳过使用暂存区域"><a href="#跳过使用暂存区域" class="headerlink" title="跳过使用暂存区域"></a>跳过使用暂存区域</h3><p>使用暂存区域的方式可以精心准备要提交的细节，但有时候这么做略显繁琐。Git 提供了一个跳过使用暂存区域的方式，只要在提交的时候，给 <code>git commit</code> 加上 <code>-a</code> 选项，Git 就会自动把所有已经跟踪过的文件暂存起来一并提交，从而跳过 <code>git add</code> 步骤：</p><pre class="language-shell" data-language="shell"><code class="language-shell">$ <span class="token function">git</span> commit -a -m <span class="token string">"test"</span><span class="token punctuation">[</span>master 70da55d<span class="token punctuation">]</span> <span class="token builtin class-name">test</span> <span class="token number">1</span> <span class="token function">file</span> changed, <span class="token number">2</span> insertions<span class="token punctuation">(</span>+<span class="token punctuation">)</span>, <span class="token number">1</span> deletion<span class="token punctuation">(</span>-<span class="token punctuation">)</span></code></pre><h3 id="移除文件"><a href="#移除文件" class="headerlink" title="移除文件"></a>移除文件</h3><p>要从已跟踪文件清单中移除（确切地说，是从暂存区域移除），然后提交。可以用 <code>git rm</code> 命令完成此项工作，并连带从工作目录中删除指定的文件，这样以后就不会出现在未跟踪文件清单中了。</p><p>如果删除之前已经放到暂存区域后又修改了的话，则必须要用强制删除选项 <code>-f</code>（译注：即 force 的首字母），以防误删除文件后丢失修改的内容。</p><pre class="language-shell" data-language="shell"><code class="language-shell">$ <span class="token function">git</span> <span class="token function">rm</span> qwe.txterror: the following <span class="token function">file</span> has staged content different from both the<span class="token function">file</span> and the HEAD:    qwe.txt<span class="token punctuation">(</span>use -f to force removal<span class="token punctuation">)</span>Mr.Gzj@DESKTOP-GNL5LT6 MINGW64 /d/gitProject/offer <span class="token punctuation">(</span>master<span class="token punctuation">)</span>$ <span class="token function">git</span> <span class="token function">rm</span> -f qwe.txt<span class="token function">rm</span> <span class="token string">'qwe.txt'</span></code></pre><p>另外一种情况是，我们想把文件从 Git 仓库中删除（亦即从暂存区域移除），但仍然希望保留在当前工作目录中。换句话说，仅是从跟踪清单中删除。比如一些大型日志文件或者一堆 <code>.a</code> 编译文件，不小心纳入仓库后，要移除跟踪但不删除文件，以便稍后在 <code>.gitignore</code> 文件中补上，用 <code>--cached</code> 选项即可：</p><pre class="language-none"><code class="language-none">$ git rm --cached readme.txt</code></pre><p>后面可以列出文件或者目录的名字，也可以使用 glob 模式。比方说：</p><pre class="language-none"><code class="language-none">$ git rm log&#x2F;\*.log</code></pre><p>注意到星号 <code>*</code> 之前的反斜杠 <code>\</code>，因为 Git 有它自己的文件模式扩展匹配方式，所以我们不用 shell 来帮忙展开（译注：实际上不加反斜杠也可以运行，只不过按照 shell 扩展的话，仅仅删除指定目录下的文件而不会递归匹配。上面的例子本来就指定了目录，所以效果等同，但下面的例子就会用递归方式匹配，所以必须加反斜杠。）。此命令删除所有 <code>log/</code> 目录下扩展名为 <code>.log</code> 的文件。类似的比如：</p><pre class="language-none"><code class="language-none">$ git rm \*~</code></pre><p>会递归删除当前目录及其子目录中所有 <code>~</code> 结尾的文件。</p><h3 id="移动文件"><a href="#移动文件" class="headerlink" title="移动文件"></a>移动文件</h3><p>Git 并不跟踪文件移动操作。如果在 Git 中重命名了某个文件，仓库中存储的元数据并不会体现出这是一次改名操作。</p><p>要在 Git 中对文件改名，可以这么做：</p><pre class="language-none"><code class="language-none">$ git mv file_from file_to</code></pre><h2 id="查看提交历史"><a href="#查看提交历史" class="headerlink" title="查看提交历史"></a>查看提交历史</h2><p>在提交了若干更新之后，又或者克隆了某个项目，想回顾下提交历史，可以使用 <code>git log</code> 命令查看。</p><pre class="language-shell" data-language="shell"><code class="language-shell">$ <span class="token function">git</span> logcommit 015436195b0a7e55123792425fb8213249d0b07d <span class="token punctuation">(</span>HEAD -<span class="token operator">></span> master<span class="token punctuation">)</span>Author: gzj1999 <span class="token operator">&lt;</span><span class="token number">1045643052</span>@qq.com<span class="token operator">></span>Date:   Sat Jul <span class="token number">18</span> <span class="token number">11</span>:10:21 <span class="token number">2020</span> +0800    修改删除订单commit b578cd1a0a917e5b975917d3f95c5ce692f6538fMerge: ab86b7a 4a5964fAuthor: gzj1999 <span class="token operator">&lt;</span><span class="token number">1045643052</span>@qq.com<span class="token operator">></span>Date:   Fri Jul <span class="token number">17</span> <span class="token number">22</span>:04:48 <span class="token number">2020</span> +0800</code></pre><p>默认不用任何参数的话，<code>git log</code> 会按提交时间列出所有的更新，最近的更新排在最上面。每次更新都有一个 SHA-1 校验和、作者的名字和电子邮件地址、提交时间，最后缩进一个段落显示提交说明。</p><p>我们常用 <code>-p</code> 选项展开显示每次提交的内容差异，用 <code>-2</code> 则仅显示最近的两次更新：</p><pre class="language-none"><code class="language-none">$ git log -p -2commit 015436195b0a7e55123792425fb8213249d0b07d (HEAD -&gt; master)Author: gzj1999 &lt;1045643052@qq.com&gt;Date:   Sat Jul 18 11:10:21 2020 +0800    修改删除订单diff --git a&#x2F;src&#x2F;main&#x2F;java&#x2F;com&#x2F;clothes&#x2F;controller&#x2F;OrderController.java b&#x2F;src&#x2F;main&#x2F;java&#x2F;com&#x2F;clothes&#x2F;controller&#x2F;OrderController.javaindex 87295b1..d0f4c77 100644--- a&#x2F;src&#x2F;main&#x2F;java&#x2F;com&#x2F;clothes&#x2F;controller&#x2F;OrderController.java+++ b&#x2F;src&#x2F;main&#x2F;java&#x2F;com&#x2F;clothes&#x2F;controller&#x2F;OrderController.java@@ -92,10 +92,14 @@ public class OrderController &#123;             return new Response(&quot;400&quot;, &quot;没有此订单！&quot;);         &#125;</code></pre><p>在做代码审查，或者要快速浏览其他协作者提交的更新都作了哪些改动时，就可以用这个选项。此外，还有许多摘要选项可以用，比如 <code>--stat</code>，仅显示简要的增改行数统计：</p><pre class="language-none"><code class="language-none">$ git log --statcommit 015436195b0a7e55123792425fb8213249d0b07d (HEAD -&gt; master)Author: gzj1999 &lt;1045643052@qq.com&gt;Date:   Sat Jul 18 11:10:21 2020 +0800    修改删除订单 src&#x2F;main&#x2F;java&#x2F;com&#x2F;clothes&#x2F;controller&#x2F;OrderController.java   | 4 ++++ src&#x2F;main&#x2F;java&#x2F;com&#x2F;clothes&#x2F;service&#x2F;UserService.java          | 7 +++++++ src&#x2F;main&#x2F;java&#x2F;com&#x2F;clothes&#x2F;service&#x2F;impl&#x2F;UserServiceImpl.java | 7 +++++++ 3 files changed, 18 insertions(+)</code></pre><p>还有个常用的 <code>--pretty</code> 选项，可以指定使用完全不同于默认格式的方式展示提交历史。比如用 <code>oneline</code> 将每个提交放在一行显示，这在提交数很大时非常有用。</p><p>一些其他常用的选项及其释义:</p><pre class="language-none"><code class="language-none">选项 说明    -p 按补丁格式显示每个更新之间的差异。    --stat 显示每次更新的文件修改统计信息。    --shortstat 只显示 --stat 中最后的行数修改添加移除统计。    --name-only 仅在提交信息后显示已修改的文件清单。    --name-status 显示新增、修改、删除的文件清单。    --abbrev-commit 仅显示 SHA-1 的前几个字符，而非所有的 40 个字符。    --relative-date 使用较短的相对时间显示（比如，“2 weeks ago”）。    --graph 显示 ASCII 图形表示的分支合并历史。    --pretty 使用其他格式显示历史提交信息。可用的选项包括 oneline，short，full，fuller 和 format（后跟指定格式）。</code></pre><p>当 oneline 或 format 与另一个 <code>log</code> 选项 <code>--graph</code> 结合使用时尤其有用。这个选项添加了一些ASCII字符串来形象地展示你的分支、合并历史：</p><pre class="language-none"><code class="language-none">$ git log --pretty&#x3D;format:&quot;%h %s&quot; --graph*   1ebd4d5 up|\| * d121dae qw* | a87e37d qw|&#x2F;*   6c3f1d7 Merge branch &#39;iss53&#39;|\| * 2519576 l* | c7badcf up</code></pre><h3 id="限制输出长度"><a href="#限制输出长度" class="headerlink" title="限制输出长度"></a>限制输出长度</h3><p> <code>-&lt;n&gt;</code> 选项，其中的 <code>n</code> 可以是任何自然数，表示仅显示最近的若干条提交。不过实践中我们是不太用这个选项的，Git 在输出所有提交时会自动调用分页程序（less），要看更早的更新只需翻到下页即可。</p><p>另外还有按照时间作限制的选项，比如 <code>--since</code> 和 <code>--until</code>。下面的命令列出所有最近两周内的提交：</p><pre class="language-none"><code class="language-none">$ git log --since&#x3D;2.weeks</code></pre><p>你可以给出各种时间格式，比如说具体的某一天（“2008-01-15”），或者是多久以前（“2 years 1 day 3 minutes ago”）。</p><p>另一个真正实用的<code>git log</code>选项是路径(path)，如果只关心某些文件或者目录的历史提交，可以在 <code>git log</code> 选项的最后指定它们的路径。因为是放在最后位置上的选项，所以用两个短划线（<code>--</code>）隔开之前的选项和后面限定的路径名。</p><p>其他常用的类似选项。</p><pre class="language-none"><code class="language-none">选项 说明-(n) 仅显示最近的 n 条提交--since, --after 仅显示指定时间之后的提交。--until, --before 仅显示指定时间之前的提交。--author 仅显示指定作者相关的提交。--committer 仅显示指定提交者相关的提交。</code></pre><h2 id="撤销操作"><a href="#撤销操作" class="headerlink" title="撤销操作"></a>撤销操作</h2><h3 id="修改最后一次提交"><a href="#修改最后一次提交" class="headerlink" title="修改最后一次提交"></a>修改最后一次提交</h3><p>有时候我们提交完了才发现漏掉了几个文件没有加，或者提交信息写错了。想要撤消刚才的提交操作，可以使用 <code>--amend</code> 选项重新提交：</p><pre class="language-shell" data-language="shell"><code class="language-shell">$ <span class="token function">git</span> commit --amend <span class="token comment">#也可以 git commit --amend -m ""</span></code></pre><p>此命令将使用当前的暂存区域快照提交。如果刚才提交完没有作任何改动，直接运行此命令的话，相当于有机会重新编辑提交说明，但将要提交的文件快照和之前的一样。</p><h3 id="取消已经暂存的文件"><a href="#取消已经暂存的文件" class="headerlink" title="取消已经暂存的文件"></a>取消已经暂存的文件</h3><p>有两个修改过的文件，我们想要分开提交，但不小心用 <code>git add .</code> 全加到了暂存区域。可以使用<code>git reset HEAD &lt;file&gt;...</code>的方式取消暂存。</p><ul><li><code>git reset -–hard</code>：<strong>彻底回退到某个版本</strong>，本地的源码也会变为上一个版本的内容，撤销的commit中所包含的更改被冲掉。</li></ul><h3 id="取消对文件的修改"><a href="#取消对文件的修改" class="headerlink" title="取消对文件的修改"></a>取消对文件的修改</h3><p><code>git checkout -- &lt;file&gt;...</code>命令可以使文件恢复到修改前的版本，这条命令有些危险，所有对文件的修改都没有了，因为我们刚刚把之前版本的文件复制过来重写了此文件。所以在用这条命令前，请务必确定真的不再需要保留刚才的修改。</p><h2 id="远程仓库的使用"><a href="#远程仓库的使用" class="headerlink" title="远程仓库的使用"></a>远程仓库的使用</h2><p>远程仓库是指托管在网络上的项目仓库，可能会有好多个，其中有些你只能读，另外有些可以写。同他人协作开发某个项目时，需要管理这些远程仓库，以便推送或拉取数据，分享各自的工作进展。管理远程仓库的工作，包括添加远程库，移除废弃的远程库，管理各式远程库分支，定义是否跟踪这些分支，等等。</p><h3 id="查看当前的远程库"><a href="#查看当前的远程库" class="headerlink" title="查看当前的远程库"></a>查看当前的远程库</h3><p>要查看当前配置有哪些远程仓库，可以用 <code>git remote</code> 命令，它会列出每个远程库的简短名字。在克隆完某个项目后，至少可以看到一个名为 origin 的远程库，Git 默认使用这个名字来标识你所克隆的原始仓库：</p><pre class="language-none"><code class="language-none">$ git remoteorigin</code></pre><p>也可以加上 <code>-v</code> 选项（译注：此为 <code>--verbose</code> 的简写，取首字母），显示对应的克隆地址：</p><pre class="language-none"><code class="language-none">$ git remote -vorigin  https:&#x2F;&#x2F;gitee.com&#x2F;gzj1999&#x2F;test.git (fetch)origin  https:&#x2F;&#x2F;gitee.com&#x2F;gzj1999&#x2F;test.git (push)</code></pre><h3 id="添加远程仓库"><a href="#添加远程仓库" class="headerlink" title="添加远程仓库"></a>添加远程仓库</h3><p>有时候可能在GitHub建一个仓库，Gitee建一个仓库。</p><p>要添加一个新的远程仓库，可以指定一个简单的名字，以便将来引用，运行 <code>git remote add [shortname] [url]</code>：</p><pre class="language-none"><code class="language-none">$ git remote add pb git@gitee.com:gzj1999&#x2F;testgzj.git</code></pre><p>现在可以用字符串 <code>pb</code> 指代对应的仓库地址了。比如说，要抓取所有 Paul 有的，但本地仓库没有的信息，可以运行 <code>git fetch pb</code>：</p><pre class="language-none"><code class="language-none">$ git fetch pbwarning: no common commitsremote: Enumerating objects: 3, done.remote: Counting objects: 100% (3&#x2F;3), done.remote: Compressing objects: 100% (2&#x2F;2), done.remote: Total 3 (delta 0), reused 0 (delta 0), pack-reused 0Unpacking objects: 100% (3&#x2F;3), 948 bytes | 4.00 KiB&#x2F;s, done.From gitee.com:gzj1999&#x2F;testgzj * [new branch]      master     -&gt; pb&#x2F;master</code></pre><p>现在，testgzj的主干分支（master）已经完全可以在本地访问了，对应的名字是 <code>pb/master</code>。</p><h3 id="从远程仓库抓取数据"><a href="#从远程仓库抓取数据" class="headerlink" title="从远程仓库抓取数据"></a>从远程仓库抓取数据</h3><p>正如之前所看到的，可以用下面的命令从远程仓库抓取数据到本地：</p><pre class="language-none"><code class="language-none">$ git fetch [remote-name]</code></pre><p>此命令会到远程仓库中拉取所有你本地仓库中还没有的数据。运行完成后，你就可以在本地访问该远程仓库中的所有分支，将其中某个分支合并到本地，或者只是取出某个分支，一探究竟。</p><p>如果是克隆了一个仓库，此命令会自动将远程仓库归于 origin 名下。所以，<code>git fetch origin</code> 会抓取从你上次克隆以来别人上传到此远程仓库中的所有更新（或是上次 fetch 以来别人提交的更新）。有一点很重要，需要记住，<strong>fetch 命令只是将远端的数据拉到本地仓库，并不自动合并到当前工作分支，只有当你确实准备好了，才能手工合并。</strong></p><h3 id="推送数据到远程仓库"><a href="#推送数据到远程仓库" class="headerlink" title="推送数据到远程仓库"></a>推送数据到远程仓库</h3><p>将本地仓库中的数据推送到远程仓库。实现这个任务的命令很简单： <code>git push [remote-name] [branch-name]</code>。如果要把本地的 master 分支推送到 <code>origin</code> 服务器上（再次说明下，克隆操作会自动使用默认的 master 和 origin 名字），可以运行下面的命令：</p><pre class="language-none"><code class="language-none">$ git push origin master</code></pre><p>只有在所克隆的服务器上有写权限，或者同一时刻没有其他人在推数据，这条命令才会如期完成任务。如果在你推数据前，已经有其他人推送了若干更新，那你的推送操作就会被驳回。你必须先把他们的更新抓取到本地，合并到自己的项目中，然后才可以再次推送。</p><h3 id="使用git的squash减少commit记录"><a href="#使用git的squash减少commit记录" class="headerlink" title="使用git的squash减少commit记录"></a>使用git的squash减少commit记录</h3><p>假如git log如下：</p><p><img src="https://raw.githubusercontent.com/zzugzj/blogImg/master/img/e7cd7b899e510fb35476621c2881b291d0430c00.png" alt="img" loading="lazy"></p><p>现在，我们希望将最后三个commit压缩为一个，这样push的时候也不至于太多无用的commit，可以使用<code>git rebase -i HEAD~3</code>来修改，这时候我们会发现进入编辑界面，并且显示内容如下：</p><p><img src="https://raw.githubusercontent.com/zzugzj/blogImg/master/img/908fa0ec08fa513d73252bd4cddf2fffb3fbd960.png" alt="img" loading="lazy"></p><p>这个界面是让我们告诉git该如何处理每个commit。这里我们想保留f392171这个commit，所以我们需要做的就是将以下两个commit合并到第一个上，我们将编辑界面的内容改成这样即可：</p><p><img src="https://raw.githubusercontent.com/zzugzj/blogImg/master/img/63d0f703918fa0ec7d9f01cbd62523ea3f6ddbd7.png" alt="img" loading="lazy"></p><p>ok了，接下来esc，:wq保存即可了。</p><p>注意：不要合并已经push的commit。</p><h3 id="查看远程仓库信息"><a href="#查看远程仓库信息" class="headerlink" title="查看远程仓库信息"></a>查看远程仓库信息</h3><p>我们可以通过命令 <code>git remote show [remote-name]</code> 查看某个远程仓库的详细信息，比如要看所克隆的 <code>origin</code> 仓库，可以运行：</p><pre class="language-none"><code class="language-none">$ git remote show origin* remote origin  Fetch URL: https:&#x2F;&#x2F;gitee.com&#x2F;gzj1999&#x2F;test.git  Push  URL: https:&#x2F;&#x2F;gitee.com&#x2F;gzj1999&#x2F;test.git  HEAD branch: master  Remote branches:    feature&#x2F;sss                      new (next fetch will store in remotes&#x2F;origin)    master                           tracked    refs&#x2F;remotes&#x2F;origin&#x2F;feature&#x2F;test stale (use &#39;git remote prune&#39; to remove)  Local branch configured for &#39;git pull&#39;:    master merges with remote master  Local ref configured for &#39;git push&#39;:    master pushes to master (up to date)</code></pre><p>它显示了有哪些远端分支还没有同步到本地（译注：feature/sss 分支），哪些已同步到本地的远端分支在远端服务器上已被删除（译注：refs/remotes/origin/feature/test分支），Local branch configured for ‘git pull’意思是git pull默认拉取remote master分支，Local ref configured for ‘git push’:意思是默认push到master。</p><h3 id="远程仓库的删除和重命名"><a href="#远程仓库的删除和重命名" class="headerlink" title="远程仓库的删除和重命名"></a>远程仓库的删除和重命名</h3><p>Git 中可以用 <code>git remote rename</code> 命令修改某个远程仓库在本地的简称，比如想把 <code>pb</code> 改成 <code>paul</code>，可以这么运行：</p><pre class="language-none"><code class="language-none">$ git remote rename pb phub$ git remoteoriginphub</code></pre><p>注意，对远程仓库的重命名，也会使对应的分支名称发生变化，原来的 <code>pb/master</code> 分支现在成了 <code>phub/master</code>。</p><p>碰到远端仓库服务器迁移，或者原来的克隆镜像不再使用，又或者某个参与者不再贡献代码，那么需要移除对应的远端仓库，可以运行 <code>git remote rm</code> 命令：</p><pre class="language-none"><code class="language-none">$ git remote rm phub$ git remoteorigin</code></pre><h2 id="打标签"><a href="#打标签" class="headerlink" title="打标签"></a>打标签</h2><p>Git 可以对某一时间点上的版本打上标签。人们在发布某个软件版本（比如 v1.0 等等）的时候，经常这么做。</p><h3 id="列显已有的标签"><a href="#列显已有的标签" class="headerlink" title="列显已有的标签"></a>列显已有的标签</h3><p>（下面用的 Git 自身项目仓库）列出现有标签的命令非常简单，直接运行 <code>git tag</code> 即可：</p><pre class="language-none"><code class="language-none">$ git taggitgui-0.10.0gitgui-0.10.1</code></pre><p>显示的标签按字母顺序排列，所以标签的先后并不表示重要程度的轻重。</p><p>我们可以用特定的搜索模式列出符合条件的标签。如果你只对 1.4.2 系列的版本感兴趣，可以运行下面的命令：</p><pre class="language-none"><code class="language-none">$ git tag -l v2.9.*v2.9.0v2.9.0-rc0v2.9.0-rc1v2.9.0-rc2v2.9.1v2.9.2v2.9.3v2.9.4v2.9.5</code></pre><h3 id="新建标签"><a href="#新建标签" class="headerlink" title="新建标签"></a>新建标签</h3><p>Git 使用的标签有两种类型：轻量级的（lightweight）和含附注的（annotated）。轻量级标签就像是个不会变化的分支，实际上它就是个指向特定提交对象的引用。而含附注标签，实际上是存储在仓库中的一个独立对象，它有自身的校验和信息，包含着标签的名字，电子邮件地址和日期，以及标签说明，标签本身也允许使用 GNU Privacy Guard (GPG) 来签署或验证。一般我们都建议使用含附注型的标签，以便保留相关信息；当然，如果只是临时性加注标签，或者不需要旁注额外信息，用轻量级标签也没问题。</p><h4 id="含附注的标签"><a href="#含附注的标签" class="headerlink" title="含附注的标签"></a>含附注的标签</h4><p>创建一个含附注类型的标签非常简单，用 <code>-a</code> （译注：取 <code>annotated</code> 的首字母）指定标签名字即可：</p><pre class="language-none"><code class="language-none">$ git tag -a v1.4 -m &#39;my version 1.4&#39;$ git tagv0.1v1.3v1.4</code></pre><p>而 <code>-m</code> 选项则指定了对应的标签说明，Git 会将此说明一同保存在标签对象中。如果没有给出该选项，Git 会启动文本编辑软件供你输入标签说明。</p><p>可以使用 <code>git show</code> 命令查看相应标签的版本信息，并连同显示打标签时的提交对象。</p><h4 id="签署标签"><a href="#签署标签" class="headerlink" title="签署标签"></a>签署标签</h4><p>如果你有自己的私钥，还可以用 GPG 来签署标签，只需要把之前的 <code>-a</code> 改为 <code>-s</code> （译注： 取 <code>signed</code> 的首字母）即可：</p><pre class="language-none"><code class="language-none">$ git tag -s v1.5 -m &#39;my signed 1.5 tag&#39;You need a passphrase to unlock the secret key foruser: &quot;Scott Chacon &lt;schacon@gee-mail.com&gt;&quot;1024-bit DSA key, ID F721C45A, created 2009-02-09</code></pre><h4 id="轻量级标签"><a href="#轻量级标签" class="headerlink" title="轻量级标签"></a>轻量级标签</h4><p>轻量级标签实际上就是一个保存着对应提交对象的校验和信息的文件。要创建这样的标签，一个 <code>-a</code>，<code>-s</code> 或 <code>-m</code> 选项都不用，直接给出标签名字即可：</p><pre class="language-none"><code class="language-none">$ git tag v1.4-lw$ git tagv0.1v1.3v1.4v1.4-lw</code></pre><h4 id="验证标签"><a href="#验证标签" class="headerlink" title="验证标签"></a>验证标签</h4><p>可以使用 <code>git tag -v [tag-name]</code> （译注：取 <code>verify</code> 的首字母）的方式验证已经签署的标签。此命令会调用 GPG 来验证签名，所以你需要有签署者的公钥，存放在 keyring 中，才能验证：</p><pre class="language-none"><code class="language-none">$ git tag -v v1.4.2.1</code></pre><h3 id="后期加注标签"><a href="#后期加注标签" class="headerlink" title="后期加注标签"></a>后期加注标签</h3><p>你甚至可以在后期对早先的某次提交加注标签。比如在下面展示的提交历史中：</p><pre class="language-none"><code class="language-none">$ git log --pretty&#x3D;onelinea11c575af93aacd1eb019fa00c46cfdd55415314 (origin&#x2F;feature&#x2F;test) update qwe.txt.dd186697004a318be67fdafb6577dfda16a077e8 ceshis72adbf074a6037d61e0c28cf6e4de542d1b7e7d1 qwecd2830cfbf553e77c1889ab3163e37ad31f10970 test</code></pre><p>我们忘了在提交 “ceshis” 后为此项目打上版本号 v1.2，没关系，现在也能做。只要在打标签的时候跟上对应提交对象的校验和（或前几位字符）即可：</p><pre class="language-none"><code class="language-none">$ git tag -a v1.1 dd186697$ git tagv1.1</code></pre><h3 id="分享标签"><a href="#分享标签" class="headerlink" title="分享标签"></a>分享标签</h3><p>默认情况下，<code>git push</code> 并不会把标签传送到远端服务器上，只有通过显式命令才能分享标签到远端仓库。其命令格式如同推送分支，运行 <code>git push origin [tagname]</code> 即可：</p><pre class="language-none"><code class="language-none">$ git push origin v1.1</code></pre><p>如果要一次推送所有本地新增的标签上去，可以使用 <code>--tags</code> 选项：</p><pre class="language-none"><code class="language-none">$ git push origin --tags</code></pre>]]></content>
    
    
    <summary type="html">介绍几个最基本的，也是最常用的 Git 命令，以后绝大多数时间里用到的也就是这几个命令。使用这些命令，你就能初始化一个新的代码仓库，做一些适当配置；开始或停止跟踪某些文件；暂存或提交某些更新。我们还会展示如何让 Git 忽略某些文件，或是名称符合特定模式的文件；如何既快且容易地撤消犯下的小错误；如何浏览项目的更新历史，查看某两次更新之间的差异；以及如何从远程仓库拉数据下来或者推数据上去。</summary>
    
    
    
    <category term="git" scheme="https://zzugzj.github.io/categories/git/"/>
    
    
    <category term="学习笔记" scheme="https://zzugzj.github.io/tags/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    
    <category term="git" scheme="https://zzugzj.github.io/tags/git/"/>
    
  </entry>
  
</feed>
